{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 🔍 Sistemas de Equações Lineares: O Detetive da Matemática\n",
        "\n",
        "## *Módulo 5 - Álgebra Linear para IA*\n",
        "\n",
        "### Pedro Nunes Guth\n",
        "\n",
        "---\n",
        "\n",
        "Bora resolver uns mistérios matemáticos! 🕵️‍♂️\n",
        "\n",
        "Tá, mas o que é um sistema de equações lineares? Imagina que você vai no açougue e compra 2kg de carne e 3kg de frango por R$ 50. No dia seguinte, compra 1kg de carne e 2kg de frango por R$ 30. Pergunta: quanto custa o kg de cada um?\n",
        "\n",
        "É exatamente isso que vamos resolver hoje! E o melhor: vamos ver como isso se conecta diretamente com regressão linear e machine learning. Liiindo! 🚀"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🎯 O Que Vamos Aprender Hoje\n",
        "\n",
        "Nos módulos anteriores, aprendemos sobre:\n",
        "- **Módulo 1**: Escalares, vetores e matrizes\n",
        "- **Módulo 2**: Operações com vetores (produto escalar)\n",
        "- **Módulo 3**: Multiplicação de matrizes\n",
        "- **Módulo 4**: NumPy na prática\n",
        "\n",
        "Hoje vamos usar TUDO isso para:\n",
        "\n",
        "1. **Entender sistemas de equações lineares**\n",
        "2. **Representar sistemas como Ax = b**\n",
        "3. **Resolver sistemas com NumPy**\n",
        "4. **Conectar com regressão linear**\n",
        "5. **Ver casos práticos de ML**\n",
        "\n",
        "**Dica do Pedro**: Sistemas lineares são a base de QUASE TUDO em machine learning. Desde regressão até redes neurais, tudo passa por aqui!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup inicial - importando as bibliotecas que vamos usar\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.datasets import make_regression\n",
        "import seaborn as sns\n",
        "\n",
        "# Configurações para gráficos mais bonitos\n",
        "plt.style.use('seaborn-v0_8')\n",
        "plt.rcParams['figure.figsize'] = (10, 6)\n",
        "plt.rcParams['font.size'] = 12\n",
        "\n",
        "print(\"🚀 Bibliotecas carregadas! Bora resolver uns sistemas!\")\n",
        "print(f\"NumPy versão: {np.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🧮 Fundamentos: O Que É Um Sistema Linear?\n",
        "\n",
        "Tá, vamos começar do básico. Um **sistema de equações lineares** é um conjunto de equações onde cada uma é uma combinação linear de variáveis.\n",
        "\n",
        "### Exemplo Clássico:\n",
        "\n",
        "$$\\begin{cases}\n",
        "2x + 3y = 50 \\\\\n",
        "1x + 2y = 30\n",
        "\\end{cases}$$\n",
        "\n",
        "Onde:\n",
        "- $x$ = preço do kg de carne\n",
        "- $y$ = preço do kg de frango\n",
        "\n",
        "### Representação Matricial:\n",
        "\n",
        "Podemos escrever isso como: $\\mathbf{A}\\mathbf{x} = \\mathbf{b}$\n",
        "\n",
        "$$\\begin{bmatrix}\n",
        "2 & 3 \\\\\n",
        "1 & 2\n",
        "\\end{bmatrix}\n",
        "\\begin{bmatrix}\n",
        "x \\\\\n",
        "y\n",
        "\\end{bmatrix}\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "50 \\\\\n",
        "30\n",
        "\\end{bmatrix}$$\n",
        "\n",
        "Onde:\n",
        "- $\\mathbf{A}$ = matriz dos coeficientes\n",
        "- $\\mathbf{x}$ = vetor das variáveis (o que queremos descobrir)\n",
        "- $\\mathbf{b}$ = vetor dos resultados\n",
        "\n",
        "**Dica do Pedro**: Lembra da multiplicação de matrizes do Módulo 3? É exatamente isso que está acontecendo aqui! A primeira linha de A multiplicada por x nos dá a primeira equação."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos criar nosso primeiro sistema linear\n",
        "# Sistema: 2x + 3y = 50, x + 2y = 30\n",
        "\n",
        "# Matriz A (coeficientes)\n",
        "A = np.array([\n",
        "    [2, 3],  # Primeira equação: 2x + 3y\n",
        "    [1, 2]   # Segunda equação: x + 2y\n",
        "])\n",
        "\n",
        "# Vetor b (resultados)\n",
        "b = np.array([50, 30])\n",
        "\n",
        "print(\"Matriz A (coeficientes):\")\n",
        "print(A)\n",
        "print(\"\\nVetor b (resultados):\")\n",
        "print(b)\n",
        "\n",
        "# Vamos verificar se nossa representação está correta\n",
        "print(\"\\nVerificação: Ax = b\")\n",
        "print(f\"Dimensões: A = {A.shape}, b = {b.shape}\")\n",
        "print(\"Perfeito! Podemos multiplicar A por um vetor x de tamanho 2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🔧 Resolvendo Sistemas: Os Métodos\n",
        "\n",
        "Existem várias formas de resolver um sistema $\\mathbf{A}\\mathbf{x} = \\mathbf{b}$:\n",
        "\n",
        "### 1. Método da Inversa (quando possível):\n",
        "$$\\mathbf{x} = \\mathbf{A}^{-1}\\mathbf{b}$$\n",
        "\n",
        "### 2. Método de Eliminação de Gauss\n",
        "Transformamos a matriz em escalonada\n",
        "\n",
        "### 3. Decomposição LU\n",
        "Fatoramos A = LU\n",
        "\n",
        "### 4. Numpy.linalg.solve() (O mais prático!)\n",
        "Usa algoritmos otimizados internamente\n",
        "\n",
        "**Por que não usar sempre a inversa?**\n",
        "- Nem sempre existe\n",
        "- É computacionalmente cara\n",
        "- Problemas numéricos com matrizes mal condicionadas\n",
        "\n",
        "**Dica do Pedro**: O `np.linalg.solve()` é como ter um mecânico expert que escolhe a melhor ferramenta automaticamente. Use ele!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Método 1: Usando np.linalg.solve() (RECOMENDADO)\n",
        "x_solve = np.linalg.solve(A, b)\n",
        "print(\"🎯 Solução usando np.linalg.solve():\")\n",
        "print(f\"x = {x_solve[0]:.2f} (preço da carne)\")\n",
        "print(f\"y = {x_solve[1]:.2f} (preço do frango)\")\n",
        "\n",
        "# Método 2: Usando a inversa (só para comparar)\n",
        "A_inv = np.linalg.inv(A)\n",
        "x_inv = A_inv @ b  # Lembra do @ do Módulo 4?\n",
        "print(\"\\n🔄 Solução usando a inversa:\")\n",
        "print(f\"x = {x_inv[0]:.2f}\")\n",
        "print(f\"y = {x_inv[1]:.2f}\")\n",
        "\n",
        "# Verificação: Ax deve ser igual a b\n",
        "verificacao = A @ x_solve\n",
        "print(\"\\n✅ Verificação (A @ x):\")\n",
        "print(f\"Resultado: {verificacao}\")\n",
        "print(f\"Original b: {b}\")\n",
        "print(f\"Diferença: {np.abs(verificacao - b)}\")\n",
        "\n",
        "print(\"\\n🎉 Liiindo! A carne custa R$ 10,00/kg e o frango R$ 10,00/kg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 📊 Visualizando Sistemas Lineares\n",
        "\n",
        "Cada equação linear em 2D representa uma **reta**. A solução do sistema é onde essas retas se cruzam!\n",
        "\n",
        "Para nossa equação $ax + by = c$, podemos reescrever como:\n",
        "$$y = \\frac{c - ax}{b}$$\n",
        "\n",
        "Vamos visualizar nosso sistema:\n",
        "- Equação 1: $2x + 3y = 50$ → $y = \\frac{50 - 2x}{3}$\n",
        "- Equação 2: $x + 2y = 30$ → $y = \\frac{30 - x}{2}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizando o sistema de equações\n",
        "x_range = np.linspace(0, 30, 100)\n",
        "\n",
        "# Equação 1: 2x + 3y = 50 -> y = (50 - 2x) / 3\n",
        "y1 = (50 - 2*x_range) / 3\n",
        "\n",
        "# Equação 2: x + 2y = 30 -> y = (30 - x) / 2\n",
        "y2 = (30 - x_range) / 2\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.plot(x_range, y1, 'b-', linewidth=2, label='2x + 3y = 50 (Equação 1)')\n",
        "plt.plot(x_range, y2, 'r-', linewidth=2, label='x + 2y = 30 (Equação 2)')\n",
        "\n",
        "# Marcando a solução\n",
        "plt.plot(x_solve[0], x_solve[1], 'go', markersize=10, label=f'Solução: ({x_solve[0]:.1f}, {x_solve[1]:.1f})')\n",
        "\n",
        "plt.xlabel('x (Preço da carne - R$/kg)')\n",
        "plt.ylabel('y (Preço do frango - R$/kg)')\n",
        "plt.title('Sistema de Equações Lineares: Onde as Retas se Encontram! 🎯')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.xlim(0, 25)\n",
        "plt.ylim(0, 20)\n",
        "\n",
        "# Anotação explicativa\n",
        "plt.annotate('Ponto de interseção\\n= Solução do sistema', \n",
        "             xy=(x_solve[0], x_solve[1]), \n",
        "             xytext=(15, 15),\n",
        "             arrowprops=dict(arrowstyle='->', color='green', lw=2),\n",
        "             fontsize=12, ha='center')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"🎨 Cada linha representa uma equação. O ponto verde é nossa solução!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🔗 Conexão com Regressão Linear\n",
        "\n",
        "Agora vem a parte MAIS IMPORTANTE: como isso se conecta com machine learning?\n",
        "\n",
        "### Regressão Linear é um Sistema Linear!\n",
        "\n",
        "Quando fazemos regressão linear, queremos encontrar a reta que melhor se ajusta aos dados:\n",
        "$$y = \\beta_0 + \\beta_1 x$$\n",
        "\n",
        "Com múltiplas features:\n",
        "$$y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + ... + \\beta_n x_n$$\n",
        "\n",
        "### Método dos Mínimos Quadrados:\n",
        "\n",
        "Para encontrar os coeficientes $\\boldsymbol{\\beta}$, resolvemos:\n",
        "$$\\boldsymbol{\\beta} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}$$\n",
        "\n",
        "Ou de forma equivalente, o sistema:\n",
        "$$\\mathbf{X}^T\\mathbf{X}\\boldsymbol{\\beta} = \\mathbf{X}^T\\mathbf{y}$$\n",
        "\n",
        "**Dica do Pedro**: Lembra da transposta que vamos ver no Módulo 7? Ela aparece aqui! E vamos usar tudo que aprendemos sobre multiplicação de matrizes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos criar um exemplo de regressão linear como sistema linear\n",
        "np.random.seed(42)\n",
        "\n",
        "# Gerando dados sintéticos\n",
        "n_samples = 100\n",
        "X = np.random.randn(n_samples, 2)  # 2 features\n",
        "true_coeffs = np.array([3, -2])   # Coeficientes verdadeiros\n",
        "true_intercept = 1                # Intercepto verdadeiro\n",
        "\n",
        "# y = 1 + 3*x1 - 2*x2 + ruído\n",
        "y = true_intercept + X @ true_coeffs + 0.1 * np.random.randn(n_samples)\n",
        "\n",
        "print(\"📊 Dados gerados:\")\n",
        "print(f\"Samples: {n_samples}\")\n",
        "print(f\"Features: {X.shape[1]}\")\n",
        "print(f\"Coeficientes verdadeiros: {true_coeffs}\")\n",
        "print(f\"Intercepto verdadeiro: {true_intercept}\")\n",
        "\n",
        "# Adicionando coluna de 1s para o intercepto (bias)\n",
        "X_with_bias = np.column_stack([np.ones(n_samples), X])\n",
        "print(f\"\\nX com bias: {X_with_bias.shape}\")\n",
        "print(\"Primeira linha (exemplo):\", X_with_bias[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Resolvendo a regressão como sistema linear\n",
        "# Método 1: Fórmula dos mínimos quadrados\n",
        "XtX = X_with_bias.T @ X_with_bias  # X^T @ X\n",
        "Xty = X_with_bias.T @ y            # X^T @ y\n",
        "\n",
        "# Resolvendo o sistema: (X^T @ X) @ beta = X^T @ y\n",
        "beta_sistema = np.linalg.solve(XtX, Xty)\n",
        "\n",
        "print(\"🔍 Resolvendo regressão como sistema linear:\")\n",
        "print(f\"Intercepto estimado: {beta_sistema[0]:.3f} (verdadeiro: {true_intercept})\")\n",
        "print(f\"Coef 1 estimado: {beta_sistema[1]:.3f} (verdadeiro: {true_coeffs[0]})\")\n",
        "print(f\"Coef 2 estimado: {beta_sistema[2]:.3f} (verdadeiro: {true_coeffs[1]})\")\n",
        "\n",
        "# Método 2: Usando sklearn para comparar\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "print(\"\\n🤖 Usando sklearn LinearRegression:\")\n",
        "print(f\"Intercepto: {model.intercept_:.3f}\")\n",
        "print(f\"Coeficientes: {model.coef_}\")\n",
        "\n",
        "print(\"\\n✅ Os resultados são praticamente idênticos! Liiindo!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🎨 Visualizando a Regressão\n",
        "\n",
        "Vamos visualizar como nossa regressão linear se comporta. Com 2 features, nossa função é:\n",
        "$$y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2$$\n",
        "\n",
        "Isso representa um **plano** no espaço 3D!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualização 3D da regressão linear\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "fig = plt.figure(figsize=(15, 5))\n",
        "\n",
        "# Subplot 1: Scatter plot dos dados reais vs preditos\n",
        "ax1 = fig.add_subplot(131)\n",
        "y_pred = X_with_bias @ beta_sistema\n",
        "ax1.scatter(y, y_pred, alpha=0.6, color='blue')\n",
        "ax1.plot([y.min(), y.max()], [y.min(), y.max()], 'r--', lw=2)\n",
        "ax1.set_xlabel('y real')\n",
        "ax1.set_ylabel('y predito')\n",
        "ax1.set_title('Real vs Predito')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Subplot 2: Resíduos\n",
        "ax2 = fig.add_subplot(132)\n",
        "residuos = y - y_pred\n",
        "ax2.scatter(y_pred, residuos, alpha=0.6, color='green')\n",
        "ax2.axhline(y=0, color='r', linestyle='--')\n",
        "ax2.set_xlabel('y predito')\n",
        "ax2.set_ylabel('Resíduos')\n",
        "ax2.set_title('Análise de Resíduos')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# Subplot 3: Comparação dos coeficientes\n",
        "ax3 = fig.add_subplot(133)\n",
        "labels = ['Intercepto', 'Coef 1', 'Coef 2']\n",
        "verdadeiros = [true_intercept, true_coeffs[0], true_coeffs[1]]\n",
        "estimados = beta_sistema\n",
        "\n",
        "x_pos = np.arange(len(labels))\n",
        "width = 0.35\n",
        "\n",
        "ax3.bar(x_pos - width/2, verdadeiros, width, label='Verdadeiros', alpha=0.8)\n",
        "ax3.bar(x_pos + width/2, estimados, width, label='Estimados', alpha=0.8)\n",
        "ax3.set_xlabel('Parâmetros')\n",
        "ax3.set_ylabel('Valores')\n",
        "ax3.set_title('Coeficientes: Real vs Estimado')\n",
        "ax3.set_xticks(x_pos)\n",
        "ax3.set_xticklabels(labels)\n",
        "ax3.legend()\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Calculando métricas\n",
        "mse = np.mean(residuos**2)\n",
        "r2 = 1 - np.sum(residuos**2) / np.sum((y - np.mean(y))**2)\n",
        "\n",
        "print(f\"📈 Métricas do modelo:\")\n",
        "print(f\"MSE: {mse:.4f}\")\n",
        "print(f\"R²: {r2:.4f}\")\n",
        "print(f\"RMSE: {np.sqrt(mse):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🌟 Tipos de Sistemas Lineares\n",
        "\n",
        "Nem todo sistema linear tem solução única! Existem 3 casos:\n",
        "\n",
        "### 1. Sistema Determinado (Solução Única)\n",
        "- Número de equações = número de variáveis\n",
        "- Matriz A é invertível (det(A) ≠ 0)\n",
        "- **Exemplo**: Nosso problema do açougue\n",
        "\n",
        "### 2. Sistema Indeterminado (Infinitas Soluções)\n",
        "- Equações são linearmente dependentes\n",
        "- det(A) = 0, mas o sistema é consistente\n",
        "\n",
        "### 3. Sistema Impossível (Sem Solução)\n",
        "- Equações contraditórias\n",
        "- det(A) = 0 e sistema inconsistente\n",
        "\n",
        "**Dica do Pedro**: Em machine learning, geralmente temos mais dados que parâmetros (sistema sobredeterminado), então usamos mínimos quadrados para encontrar a \"melhor\" solução."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exemplos dos diferentes tipos de sistemas\n",
        "\n",
        "print(\"🔍 Analisando diferentes tipos de sistemas:\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Sistema 1: Determinado (solução única)\n",
        "A1 = np.array([[2, 3], [1, 2]])\n",
        "b1 = np.array([50, 30])\n",
        "det1 = np.linalg.det(A1)\n",
        "print(f\"\\n1️⃣ Sistema Determinado:\")\n",
        "print(f\"Determinante: {det1:.3f}\")\n",
        "print(f\"Status: {'Invertível' if abs(det1) > 1e-10 else 'Singular'}\")\n",
        "if abs(det1) > 1e-10:\n",
        "    sol1 = np.linalg.solve(A1, b1)\n",
        "    print(f\"Solução: x = {sol1[0]:.2f}, y = {sol1[1]:.2f}\")\n",
        "\n",
        "# Sistema 2: Indeterminado (infinitas soluções)\n",
        "A2 = np.array([[2, 4], [1, 2]])  # Segunda linha = primeira/2\n",
        "b2 = np.array([10, 5])           # b2[1] = b2[0]/2 também\n",
        "det2 = np.linalg.det(A2)\n",
        "print(f\"\\n2️⃣ Sistema Indeterminado:\")\n",
        "print(f\"Determinante: {det2:.3f}\")\n",
        "print(f\"Status: Infinitas soluções (equações dependentes)\")\n",
        "print(f\"Equação 1: 2x + 4y = 10\")\n",
        "print(f\"Equação 2: 1x + 2y = 5 (é a equação 1 dividida por 2!)\")\n",
        "\n",
        "# Sistema 3: Impossível (sem solução)\n",
        "A3 = np.array([[2, 4], [1, 2]])  # Mesma matriz A2\n",
        "b3 = np.array([10, 6])           # Mas b3[1] ≠ b3[0]/2\n",
        "det3 = np.linalg.det(A3)\n",
        "print(f\"\\n3️⃣ Sistema Impossível:\")\n",
        "print(f\"Determinante: {det3:.3f}\")\n",
        "print(f\"Status: Sem solução (inconsistente)\")\n",
        "print(f\"Equação 1: 2x + 4y = 10\")\n",
        "print(f\"Equação 2: 1x + 2y = 6 (contraditória!)\")\n",
        "print(f\"Se 2x + 4y = 10, então x + 2y = 5, não 6!\")\n",
        "\n",
        "# Testando solução do sistema impossível\n",
        "try:\n",
        "    sol3 = np.linalg.solve(A3, b3)\n",
        "    print(f\"Solução encontrada: {sol3}\")\n",
        "except np.linalg.LinAlgError as e:\n",
        "    print(f\"❌ Erro: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 📈 Sistemas Lineares em Machine Learning\n",
        "\n",
        "Vamos ver onde mais os sistemas lineares aparecem em ML:\n",
        "\n",
        "### 1. **Regressão Linear** ✅ (já vimos)\n",
        "$$\\mathbf{X}^T\\mathbf{X}\\boldsymbol{\\beta} = \\mathbf{X}^T\\mathbf{y}$$\n",
        "\n",
        "### 2. **Redes Neurais** (cada camada)\n",
        "$$\\mathbf{h} = \\mathbf{W}\\mathbf{x} + \\mathbf{b}$$\n",
        "\n",
        "### 3. **Principal Component Analysis (PCA)**\n",
        "$$\\mathbf{C}\\mathbf{v} = \\lambda\\mathbf{v}$$ (autovetores - Módulo 10)\n",
        "\n",
        "### 4. **Support Vector Machines (SVM)**\n",
        "Problema de otimização quadrática\n",
        "\n",
        "### 5. **Sistemas de Recomendação**\n",
        "Fatorização de matrizes\n",
        "\n",
        "**Dica do Pedro**: Praticamente todo algoritmo de ML tem sistema linear no coração. Dominar isso é fundamental!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exemplo prático: Sistema de recomendação simples\n",
        "# Vamos usar sistemas lineares para completar uma matriz de ratings\n",
        "\n",
        "print(\"🎬 Sistema de Recomendação com Álgebra Linear\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Criando uma matriz de ratings (usuários x filmes)\n",
        "# NaN representa ratings não observados\n",
        "ratings = np.array([\n",
        "    [5, 4, np.nan, 2],     # Usuário 1\n",
        "    [4, np.nan, 3, 3],     # Usuário 2  \n",
        "    [np.nan, 5, 4, 1],     # Usuário 3\n",
        "    [2, 3, 4, np.nan]      # Usuário 4\n",
        "])\n",
        "\n",
        "filmes = ['Ação', 'Romance', 'Comédia', 'Terror']\n",
        "usuarios = ['Alice', 'Bob', 'Carol', 'Dave']\n",
        "\n",
        "print(\"Matriz de Ratings (NaN = não avaliado):\")\n",
        "for i, usuario in enumerate(usuarios):\n",
        "    print(f\"{usuario:6s}: {ratings[i]}\")\n",
        "\n",
        "# Vamos usar um método simples: média dos vizinhos\n",
        "# Para cada rating faltante, vamos resolver um sistema linear\n",
        "# baseado na similaridade com outros usuários\n",
        "\n",
        "ratings_filled = ratings.copy()\n",
        "\n",
        "# Encontrando posições com NaN\n",
        "nan_positions = np.where(np.isnan(ratings))\n",
        "print(f\"\\nPositions com ratings faltantes: {len(nan_positions[0])}\")\n",
        "\n",
        "# Preenchendo com a média dos ratings conhecidos para começar\n",
        "for i, j in zip(nan_positions[0], nan_positions[1]):\n",
        "    # Média dos ratings conhecidos do usuário\n",
        "    user_ratings = ratings[i, ~np.isnan(ratings[i])]\n",
        "    # Média dos ratings conhecidos do filme\n",
        "    movie_ratings = ratings[~np.isnan(ratings[:, j]), j]\n",
        "    \n",
        "    if len(user_ratings) > 0 and len(movie_ratings) > 0:\n",
        "        predicted_rating = (np.mean(user_ratings) + np.mean(movie_ratings)) / 2\n",
        "    elif len(user_ratings) > 0:\n",
        "        predicted_rating = np.mean(user_ratings)\n",
        "    elif len(movie_ratings) > 0:\n",
        "        predicted_rating = np.mean(movie_ratings)\n",
        "    else:\n",
        "        predicted_rating = 3.0  # Default\n",
        "    \n",
        "    ratings_filled[i, j] = predicted_rating\n",
        "    print(f\"Predição para {usuarios[i]} - {filmes[j]}: {predicted_rating:.2f}\")\n",
        "\n",
        "print(\"\\nMatriz Completa:\")\n",
        "for i, usuario in enumerate(usuarios):\n",
        "    print(f\"{usuario:6s}: {ratings_filled[i]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🧠 Exercício Prático 1: Problema do Negócio\n",
        "\n",
        "**Cenário**: Você trabalha numa lanchonete e precisa descobrir o preço individual dos ingredientes.\n",
        "\n",
        "**Dados**:\n",
        "- Combo 1: 2 hambúrgueres + 1 batata + 3 refrigerantes = R$ 35\n",
        "- Combo 2: 1 hambúrguer + 2 batatas + 2 refrigerantes = R$ 28  \n",
        "- Combo 3: 3 hambúrgueres + 1 batata + 1 refrigerante = R$ 32\n",
        "\n",
        "**Desafio**: Encontre o preço de cada item usando sistemas lineares!\n",
        "\n",
        "**Dica do Pedro**: Monte a matriz A com os coeficientes e o vetor b com os preços totais. Depois é só resolver!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🎯 EXERCÍCIO 1: Complete o código abaixo\n",
        "\n",
        "print(\"🍔 Exercício: Descobrindo preços da lanchonete\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# TODO: Monte a matriz A (coeficientes)\n",
        "# Linha 1: 2 hambúrgueres + 1 batata + 3 refrigerantes\n",
        "# Linha 2: 1 hambúrguer + 2 batatas + 2 refrigerantes  \n",
        "# Linha 3: 3 hambúrgueres + 1 batata + 1 refrigerante\n",
        "A_lanchonete = np.array([\n",
        "    # COMPLETE AQUI\n",
        "    [2, 1, 3],  # Combo 1\n",
        "    [1, 2, 2],  # Combo 2\n",
        "    [3, 1, 1]   # Combo 3\n",
        "])\n",
        "\n",
        "# TODO: Monte o vetor b (preços totais)\n",
        "b_lanchonete = np.array([35, 28, 32])\n",
        "\n",
        "# TODO: Resolva o sistema\n",
        "precos = np.linalg.solve(A_lanchonete, b_lanchonete)\n",
        "\n",
        "print(\"Resultados:\")\n",
        "print(f\"🍔 Hambúrguer: R$ {precos[0]:.2f}\")\n",
        "print(f\"🍟 Batata: R$ {precos[1]:.2f}\")\n",
        "print(f\"🥤 Refrigerante: R$ {precos[2]:.2f}\")\n",
        "\n",
        "# Verificação\n",
        "print(\"\\n✅ Verificação:\")\n",
        "combos = ['Combo 1', 'Combo 2', 'Combo 3']\n",
        "for i, combo in enumerate(combos):\n",
        "    calculado = A_lanchonete[i] @ precos\n",
        "    original = b_lanchonete[i]\n",
        "    print(f\"{combo}: R$ {calculado:.2f} (esperado: R$ {original:.2f})\")\n",
        "\n",
        "print(\"\\n🎉 Exercício concluído!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🚀 Exercício Prático 2: Regressão Linear Manual\n",
        "\n",
        "Agora vamos implementar regressão linear do zero usando apenas sistemas lineares!\n",
        "\n",
        "**Objetivo**: Criar uma classe `RegressaoLinearManual` que:\n",
        "1. Resolve o sistema $\\mathbf{X}^T\\mathbf{X}\\boldsymbol{\\beta} = \\mathbf{X}^T\\mathbf{y}$\n",
        "2. Calcula métricas (R², MSE)\n",
        "3. Faz predições\n",
        "\n",
        "**Dica do Pedro**: Lembra de adicionar a coluna de 1s para o intercepto!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🎯 EXERCÍCIO 2: Implemente a classe RegressaoLinearManual\n",
        "\n",
        "class RegressaoLinearManual:\n",
        "    def __init__(self):\n",
        "        self.coeficientes = None\n",
        "        self.intercepto = None\n",
        "        self.fitted = False\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        Treina o modelo resolvendo o sistema linear\n",
        "        X: features (n_samples, n_features)\n",
        "        y: target (n_samples,)\n",
        "        \"\"\"\n",
        "        # TODO: Adicione coluna de 1s para o intercepto\n",
        "        X_com_bias = np.column_stack([np.ones(X.shape[0]), X])\n",
        "        \n",
        "        # TODO: Calcule X^T @ X e X^T @ y\n",
        "        XtX = X_com_bias.T @ X_com_bias\n",
        "        Xty = X_com_bias.T @ y\n",
        "        \n",
        "        # TODO: Resolva o sistema linear\n",
        "        beta = np.linalg.solve(XtX, Xty)\n",
        "        \n",
        "        # TODO: Separe intercepto e coeficientes\n",
        "        self.intercepto = beta[0]\n",
        "        self.coeficientes = beta[1:]\n",
        "        self.fitted = True\n",
        "        \n",
        "        return self\n",
        "    \n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Faz predições\n",
        "        \"\"\"\n",
        "        if not self.fitted:\n",
        "            raise ValueError(\"Modelo não foi treinado ainda!\")\n",
        "        \n",
        "        # TODO: Calcule as predições\n",
        "        return self.intercepto + X @ self.coeficientes\n",
        "    \n",
        "    def score(self, X, y):\n",
        "        \"\"\"\n",
        "        Calcula R²\n",
        "        \"\"\"\n",
        "        y_pred = self.predict(X)\n",
        "        ss_res = np.sum((y - y_pred) ** 2)\n",
        "        ss_tot = np.sum((y - np.mean(y)) ** 2)\n",
        "        return 1 - (ss_res / ss_tot)\n",
        "\n",
        "# Testando nossa implementação\n",
        "print(\"🧪 Testando RegressaoLinearManual\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "# Gerando dados de teste\n",
        "np.random.seed(42)\n",
        "X_test = np.random.randn(100, 2)\n",
        "y_test = 1 + 2*X_test[:, 0] - 3*X_test[:, 1] + 0.1*np.random.randn(100)\n",
        "\n",
        "# Nossa implementação\n",
        "modelo_manual = RegressaoLinearManual()\n",
        "modelo_manual.fit(X_test, y_test)\n",
        "\n",
        "# Sklearn para comparar\n",
        "modelo_sklearn = LinearRegression()\n",
        "modelo_sklearn.fit(X_test, y_test)\n",
        "\n",
        "print(\"Comparação dos resultados:\")\n",
        "print(f\"Intercepto - Manual: {modelo_manual.intercepto:.4f}, Sklearn: {modelo_sklearn.intercept_:.4f}\")\n",
        "print(f\"Coef 1 - Manual: {modelo_manual.coeficientes[0]:.4f}, Sklearn: {modelo_sklearn.coef_[0]:.4f}\")\n",
        "print(f\"Coef 2 - Manual: {modelo_manual.coeficientes[1]:.4f}, Sklearn: {modelo_sklearn.coef_[1]:.4f}\")\n",
        "print(f\"R² - Manual: {modelo_manual.score(X_test, y_test):.4f}, Sklearn: {modelo_sklearn.score(X_test, y_test):.4f}\")\n",
        "\n",
        "print(\"\\n✅ Implementação perfeita! Resultados idênticos ao sklearn!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 📊 Performance e Estabilidade Numérica\n",
        "\n",
        "Nem todos os sistemas são fáceis de resolver. Alguns problemas importantes:\n",
        "\n",
        "### 1. **Matrizes Mal Condicionadas**\n",
        "- Pequenas mudanças nos dados causam grandes mudanças na solução\n",
        "- **Número de condição** alto: $\\kappa(A) = \\frac{\\lambda_{max}}{\\lambda_{min}}$\n",
        "\n",
        "### 2. **Overfitting em Regressão**\n",
        "- Muitas features, poucos dados\n",
        "- $\\mathbf{X}^T\\mathbf{X}$ pode ser singular\n",
        "\n",
        "### 3. **Soluções**:\n",
        "- **Regularização** (Ridge, Lasso)\n",
        "- **Decomposição SVD** (Módulo 9)\n",
        "- **Pseudo-inversa** para sistemas sobredeterminados\n",
        "\n",
        "**Dica do Pedro**: Em problemas reais, sempre verifique o número de condição da matriz!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Demonstrando problemas de estabilidade numérica\n",
        "print(\"⚠️ Analisando Estabilidade Numérica\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "# Matriz bem condicionada\n",
        "A_boa = np.array([[4, 1], [1, 3]])\n",
        "cond_boa = np.linalg.cond(A_boa)\n",
        "\n",
        "# Matriz mal condicionada (quase singular)\n",
        "A_ruim = np.array([[1, 1], [1, 1.0001]])\n",
        "cond_ruim = np.linalg.cond(A_ruim)\n",
        "\n",
        "print(f\"Matriz bem condicionada:\")\n",
        "print(f\"Número de condição: {cond_boa:.2f}\")\n",
        "print(f\"Status: {'Boa' if cond_boa < 100 else 'Ruim'}\")\n",
        "\n",
        "print(f\"\\nMatriz mal condicionada:\")\n",
        "print(f\"Número de condição: {cond_ruim:.2e}\")\n",
        "print(f\"Status: {'Boa' if cond_ruim < 100 else 'Ruim - CUIDADO!'}\")\n",
        "\n",
        "# Testando sensibilidade a ruído\n",
        "b_original = np.array([5, 2])\n",
        "b_com_ruido = b_original + 0.001 * np.random.randn(2)\n",
        "\n",
        "# Soluções para matriz bem condicionada\n",
        "x_boa_original = np.linalg.solve(A_boa, b_original)\n",
        "x_boa_ruido = np.linalg.solve(A_boa, b_com_ruido)\n",
        "\n",
        "# Soluções para matriz mal condicionada\n",
        "x_ruim_original = np.linalg.solve(A_ruim, b_original)\n",
        "x_ruim_ruido = np.linalg.solve(A_ruim, b_com_ruido)\n",
        "\n",
        "print(f\"\\n📊 Sensibilidade ao ruído:\")\n",
        "print(f\"Matriz boa - Mudança na solução: {np.linalg.norm(x_boa_original - x_boa_ruido):.6f}\")\n",
        "print(f\"Matriz ruim - Mudança na solução: {np.linalg.norm(x_ruim_original - x_ruim_ruido):.6f}\")\n",
        "\n",
        "print(\"\\n💡 Conclusão: Matrizes mal condicionadas amplificam pequenos erros!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🔮 Diagrama: Fluxo dos Sistemas Lineares em ML\n",
        "\n",
        "Vamos visualizar como os sistemas lineares se conectam com diferentes áreas de machine learning:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criando um diagrama conceitual\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "diagrama_mermaid = \"\"\"\n",
        "```mermaid\n",
        "graph TD\n",
        "    A[Sistema Linear Ax = b] --> B[Regressão Linear]\n",
        "    A --> C[Redes Neurais]\n",
        "    A --> D[PCA/SVD]\n",
        "    A --> E[SVM]\n",
        "    \n",
        "    B --> B1[X'X β = X'y]\n",
        "    B --> B2[Mínimos Quadrados]\n",
        "    \n",
        "    C --> C1[Wx + b = h]\n",
        "    C --> C2[Camadas Lineares]\n",
        "    \n",
        "    D --> D1[Cv = λv]\n",
        "    D --> D2[Autovetores]\n",
        "    \n",
        "    E --> E1[Otimização Quadrática]\n",
        "    E --> E2[Hiperplanos]\n",
        "    \n",
        "    F[Dados] --> A\n",
        "    A --> G[Solução]\n",
        "    G --> H[Predições/Insights]\n",
        "```\n",
        "\"\"\"\n",
        "\n",
        "display(Markdown(diagrama_mermaid))\n",
        "\n",
        "print(\"🎯 Fluxo dos Sistemas Lineares em Machine Learning\")\n",
        "print(\"Praticamente todo algoritmo de ML usa sistemas lineares!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🎨 Visualização Final: Comparando Métodos de Solução\n",
        "\n",
        "Vamos comparar diferentes métodos para resolver sistemas lineares em termos de tempo de execução:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "# Comparando métodos de solução\n",
        "print(\"⚡ Comparação de Performance dos Métodos\")\n",
        "print(\"=\"*45)\n",
        "\n",
        "# Testando com diferentes tamanhos de matriz\n",
        "tamanhos = [10, 50, 100, 200, 500]\n",
        "tempos_solve = []\n",
        "tempos_inv = []\n",
        "\n",
        "for n in tamanhos:\n",
        "    # Gerando matriz aleatória bem condicionada\n",
        "    np.random.seed(42)\n",
        "    A = np.random.randn(n, n) + n * np.eye(n)  # Adicionando diagonal para estabilidade\n",
        "    b = np.random.randn(n)\n",
        "    \n",
        "    # Método 1: np.linalg.solve\n",
        "    start = time.time()\n",
        "    for _ in range(10):  # Múltiplas execuções para média\n",
        "        x1 = np.linalg.solve(A, b)\n",
        "    tempo_solve = (time.time() - start) / 10\n",
        "    tempos_solve.append(tempo_solve)\n",
        "    \n",
        "    # Método 2: Inversa\n",
        "    start = time.time()\n",
        "    for _ in range(10):\n",
        "        A_inv = np.linalg.inv(A)\n",
        "        x2 = A_inv @ b\n",
        "    tempo_inv = (time.time() - start) / 10\n",
        "    tempos_inv.append(tempo_inv)\n",
        "    \n",
        "    print(f\"n={n:3d}: solve={tempo_solve*1000:.2f}ms, inv={tempo_inv*1000:.2f}ms, ratio={tempo_inv/tempo_solve:.1f}x\")\n",
        "\n",
        "# Visualização\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(tamanhos, [t*1000 for t in tempos_solve], 'bo-', label='np.linalg.solve', linewidth=2)\n",
        "plt.plot(tamanhos, [t*1000 for t in tempos_inv], 'ro-', label='Inversa + mult', linewidth=2)\n",
        "plt.xlabel('Tamanho da matriz (n×n)')\n",
        "plt.ylabel('Tempo (ms)')\n",
        "plt.title('Comparação de Performance')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.yscale('log')\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "ratios = [inv/solve for inv, solve in zip(tempos_inv, tempos_solve)]\n",
        "plt.bar(range(len(tamanhos)), ratios, color='orange', alpha=0.7)\n",
        "plt.xlabel('Tamanho da matriz')\n",
        "plt.ylabel('Razão (tempo_inv / tempo_solve)')\n",
        "plt.title('Quanto a Inversa é Mais Lenta')\n",
        "plt.xticks(range(len(tamanhos)), tamanhos)\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.subplot(2, 2, 3)\n",
        "# Complexidade teórica\n",
        "n_teorico = np.array(tamanhos)\n",
        "o_n3 = (n_teorico/tamanhos[0])**3 * tempos_solve[0]\n",
        "plt.plot(tamanhos, [t*1000 for t in tempos_solve], 'bo-', label='Tempo real', linewidth=2)\n",
        "plt.plot(tamanhos, [t*1000 for t in o_n3], 'g--', label='O(n³) teórico', linewidth=2)\n",
        "plt.xlabel('Tamanho da matriz (n×n)')\n",
        "plt.ylabel('Tempo (ms)')\n",
        "plt.title('Complexidade Algoritmo: O(n³)')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.yscale('log')\n",
        "\n",
        "plt.subplot(2, 2, 4)\n",
        "# Eficiência relativa\n",
        "eficiencia = [tempos_solve[0]/t for t in tempos_solve]\n",
        "plt.plot(tamanhos, eficiencia, 'mo-', linewidth=2, markersize=8)\n",
        "plt.xlabel('Tamanho da matriz (n×n)')\n",
        "plt.ylabel('Eficiência relativa')\n",
        "plt.title('Eficiência vs Tamanho')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n📈 Conclusões:\")\n",
        "print(\"1. np.linalg.solve é sempre mais rápido que calcular inversa\")\n",
        "print(\"2. A diferença aumenta com o tamanho da matriz\")\n",
        "print(\"3. Complexidade é O(n³) para ambos, mas solve tem constante menor\")\n",
        "print(\"4. Para matrizes grandes, a diferença pode ser significativa!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🚀 Preparando para os Próximos Módulos\n",
        "\n",
        "Agora que dominamos sistemas lineares, vamos nos preparar para o que vem pela frente:\n",
        "\n",
        "### **Módulo 6 - Transformações Lineares** 🔄\n",
        "- Como matrizes transformam vetores\n",
        "- Rotações, reflexões, escalas\n",
        "- Importância para representação de dados\n",
        "\n",
        "### **Módulo 7 - Inversa e Transposta** ↩️\n",
        "- Quando existe inversa?\n",
        "- Propriedades da transposta\n",
        "- Aplicações práticas\n",
        "\n",
        "### **Conexões que vamos ver**:\n",
        "- **Transformações**: $\\mathbf{y} = \\mathbf{A}\\mathbf{x}$ (próximo módulo)\n",
        "- **Inversa**: Resolver $\\mathbf{A}\\mathbf{x} = \\mathbf{b}$ → $\\mathbf{x} = \\mathbf{A}^{-1}\\mathbf{b}$\n",
        "- **SVD**: Decomposição para sistemas mal condicionados\n",
        "\n",
        "**Dica do Pedro**: Sistemas lineares são a fundação. Agora vamos ver como as matrizes podem transformar o espaço!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preview do próximo módulo: transformações lineares\n",
        "print(\"🔮 Preview: Módulo 6 - Transformações Lineares\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Exemplo simples de transformação\n",
        "# Matriz de rotação de 45 graus\n",
        "theta = np.pi/4  # 45 graus\n",
        "matriz_rotacao = np.array([\n",
        "    [np.cos(theta), -np.sin(theta)],\n",
        "    [np.sin(theta), np.cos(theta)]\n",
        "])\n",
        "\n",
        "# Vetor original\n",
        "v_original = np.array([1, 0])\n",
        "\n",
        "# Aplicando transformação\n",
        "v_transformado = matriz_rotacao @ v_original\n",
        "\n",
        "print(f\"Vetor original: {v_original}\")\n",
        "print(f\"Matriz de rotação 45°:\")\n",
        "print(matriz_rotacao)\n",
        "print(f\"Vetor após rotação: {v_transformado}\")\n",
        "\n",
        "# Visualização rápida\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.arrow(0, 0, v_original[0], v_original[1], head_width=0.1, head_length=0.1, fc='blue', ec='blue', linewidth=3, label='Original')\n",
        "plt.arrow(0, 0, v_transformado[0], v_transformado[1], head_width=0.1, head_length=0.1, fc='red', ec='red', linewidth=3, label='Rotacionado 45°')\n",
        "plt.xlim(-1.5, 1.5)\n",
        "plt.ylim(-1.5, 1.5)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.axhline(y=0, color='k', linewidth=0.5)\n",
        "plt.axvline(x=0, color='k', linewidth=0.5)\n",
        "plt.legend()\n",
        "plt.title('Preview: Transformação Linear (Rotação)')\n",
        "plt.axis('equal')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n🎯 No próximo módulo vamos entender:\")\n",
        "print(\"• Como matrizes transformam vetores\")\n",
        "print(\"• Rotações, reflexões, escalas\")\n",
        "print(\"• Por que isso é importante para IA\")\n",
        "print(\"\\nAté lá! 🚀\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 📝 Resumo do Módulo 5\n",
        "\n",
        "### **O Que Aprendemos Hoje** ✅\n",
        "\n",
        "1. **Sistemas de Equações Lineares**\n",
        "   - Representação matricial: $\\mathbf{A}\\mathbf{x} = \\mathbf{b}$\n",
        "   - Tipos: determinado, indeterminado, impossível\n",
        "\n",
        "2. **Métodos de Solução**\n",
        "   - `np.linalg.solve()` (recomendado)\n",
        "   - Inversa (quando necessário)\n",
        "   - Considerações de estabilidade numérica\n",
        "\n",
        "3. **Conexão com Machine Learning**\n",
        "   - Regressão linear como sistema linear\n",
        "   - Mínimos quadrados: $\\mathbf{X}^T\\mathbf{X}\\boldsymbol{\\beta} = \\mathbf{X}^T\\mathbf{y}$\n",
        "   - Aplicações em ML\n",
        "\n",
        "4. **Implementação Prática**\n",
        "   - Regressão linear do zero\n",
        "   - Sistema de recomendação simples\n",
        "   - Análise de performance\n",
        "\n",
        "### **Conceitos-Chave** 🔑\n",
        "- **Sistema Linear**: Conjunto de equações lineares\n",
        "- **Matriz de Coeficientes**: A no sistema Ax = b\n",
        "- **Mínimos Quadrados**: Método para ajuste de modelos\n",
        "- **Número de Condição**: Medida de estabilidade numérica\n",
        "\n",
        "### **Próximos Passos** 🚀\n",
        "- **Módulo 6**: Transformações Lineares\n",
        "- **Módulo 7**: Inversa e Transposta\n",
        "- **Módulo 9**: SVD para sistemas mal condicionados\n",
        "\n",
        "**Dica Final do Pedro**: Sistemas lineares são o coração da IA moderna. Dominando isso, você entende 80% dos algoritmos de machine learning. Liiindo! 🎉\n",
        "\n",
        "---\n",
        "\n",
        "**🎯 Missão Cumprida!** Agora você sabe resolver problemas reais usando álgebra linear e entende como isso se conecta com machine learning. Bora para as transformações lineares! 🚀"
      ]
    }
  ]
}