{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üéØ Matrizes em Python: NumPai de Todos\n\n## M√≥dulo 4: √Ålgebra Linear para IA\n\n**Por: Pedro Nunes Guth**\n\n---\n\nBora colocar a m√£o na massa! üöÄ Nos m√≥dulos anteriores voc√™ aprendeu a teoria por tr√°s de escalares, vetores e matrizes. Agora chegou a hora de fazer a m√°gica acontecer com Python e NumPy!\n\nT√°, mas por que NumPy? Simples: √© o **pai de todos** quando se trata de computa√ß√£o num√©rica em Python. √â como se fosse o motor V8 do seu carro - voc√™ pode at√© n√£o ver, mas √© ele que faz tudo funcionar liindamente!\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/algebra-linear-para-ia-modulo-04_img_01.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìö O que vamos aprender?\n\nNeste notebook, voc√™ vai dominar:\n\n- ‚úÖ Cria√ß√£o eficiente de vetores e matrizes\n- ‚úÖ Manipula√ß√£o e indexa√ß√£o avan√ßada\n- ‚úÖ Opera√ß√µes matem√°ticas otimizadas\n- ‚úÖ Broadcasting: a m√°gica por tr√°s das opera√ß√µes\n- ‚úÖ Performance: NumPy vs Python puro\n\n```mermaid\ngraph TD\n    A[Python Lists] -->|Lento e Ineficiente| B[Problemas de Performance]\n    C[NumPy Arrays] -->|R√°pido e Otimizado| D[Opera√ß√µes Vetorizadas]\n    D --> E[Machine Learning Eficiente]\n    E --> F[IA de Alto Performance]\n```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Primeiro, vamos importar nosso NumPai de todos! üéâ\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "# Configura√ß√µes para visualiza√ß√£o\n",
        "plt.rcParams['figure.figsize'] = (10, 6)\n",
        "np.set_printoptions(precision=3, suppress=True)\n",
        "\n",
        "print(\"üéØ NumPy vers√£o:\", np.__version__)\n",
        "print(\"üí™ Pronto para dominar as matrizes!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Se√ß√£o 1: Criando Vetores - Os Blocos Fundamentais\n\nLembra dos vetores que vimos no M√≥dulo 1? Agora vamos criar eles na pr√°tica! Um vetor em NumPy √© como uma fila de n√∫meros organizados, tipo aquela fila do p√£o de a√ß√∫car - cada posi√ß√£o tem seu valor espec√≠fico.\n\nMatematicamente, um vetor $\\vec{v}$ pode ser representado como:\n\n$$\\vec{v} = \\begin{pmatrix} v_1 \\\\ v_2 \\\\ \\vdots \\\\ v_n \\end{pmatrix}$$\n\n**Dica do Pedro:** NumPy arrays s√£o MUITO mais eficientes que listas Python. √â como comparar uma Ferrari com uma carro√ßa! üèéÔ∏è"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# V√°rias formas de criar vetores\n",
        "\n",
        "# 1. A partir de uma lista Python\n",
        "vetor_lista = np.array([1, 2, 3, 4, 5])\n",
        "print(\"Vetor da lista:\", vetor_lista)\n",
        "print(\"Tipo:\", type(vetor_lista))\n",
        "print(\"Shape (formato):\", vetor_lista.shape)\n",
        "print(\"Dimens√µes:\", vetor_lista.ndim)\n",
        "print()\n",
        "\n",
        "# 2. Usando fun√ß√µes especiais do NumPy\n",
        "zeros = np.zeros(5)  # Vetor de zeros\n",
        "ones = np.ones(5)    # Vetor de uns\n",
        "range_vec = np.arange(0, 10, 2)  # De 0 a 10, pulando de 2 em 2\n",
        "linspace_vec = np.linspace(0, 1, 5)  # 5 pontos entre 0 e 1\n",
        "\n",
        "print(\"Zeros:\", zeros)\n",
        "print(\"Ones:\", ones)\n",
        "print(\"Range:\", range_vec)\n",
        "print(\"Linspace:\", linspace_vec)\n",
        "print()\n",
        "\n",
        "# 3. Vetores aleat√≥rios (muito usados em IA!)\n",
        "np.random.seed(42)  # Para resultados reproduz√≠veis\n",
        "random_vec = np.random.random(5)  # Entre 0 e 1\n",
        "normal_vec = np.random.normal(0, 1, 5)  # Distribui√ß√£o normal\n",
        "\n",
        "print(\"Random:\", random_vec)\n",
        "print(\"Normal:\", normal_vec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üî¢ Se√ß√£o 2: Matrizes - O Poder dos Dados Organizados\n\nAgora vamos para as matrizes! Lembra do M√≥dulo 1 onde vimos que uma matriz √© como uma tabela de n√∫meros? √â exatamente isso que vamos criar aqui.\n\nUma matriz $A$ de dimens√£o $m \\times n$ √© representada como:\n\n$$A = \\begin{pmatrix}\na_{11} & a_{12} & \\cdots & a_{1n} \\\\\na_{21} & a_{22} & \\cdots & a_{2n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\na_{m1} & a_{m2} & \\cdots & a_{mn}\n\\end{pmatrix}$$\n\n**Dica do Pedro:** Pense numa matriz como uma planilha do Excel - linhas e colunas organizadas perfeitamente! üìä"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criando matrizes de diferentes formas\n",
        "\n",
        "# 1. A partir de listas aninhadas\n",
        "matriz_2x3 = np.array([[1, 2, 3], \n",
        "                       [4, 5, 6]])\n",
        "print(\"Matriz 2x3:\")\n",
        "print(matriz_2x3)\n",
        "print(\"Shape:\", matriz_2x3.shape)\n",
        "print(\"Dimens√µes:\", matriz_2x3.ndim)\n",
        "print()\n",
        "\n",
        "# 2. Matrizes especiais\n",
        "matriz_zeros = np.zeros((3, 4))  # 3 linhas, 4 colunas\n",
        "matriz_ones = np.ones((2, 5))\n",
        "matriz_identidade = np.eye(4)  # Matriz identidade 4x4\n",
        "matriz_diagonal = np.diag([1, 2, 3, 4])  # Matriz diagonal\n",
        "\n",
        "print(\"Matriz de zeros (3x4):\")\n",
        "print(matriz_zeros)\n",
        "print()\n",
        "\n",
        "print(\"Matriz identidade (4x4):\")\n",
        "print(matriz_identidade)\n",
        "print()\n",
        "\n",
        "# 3. Reshaping - mudando o formato\n",
        "vetor_original = np.arange(12)\n",
        "matriz_3x4 = vetor_original.reshape(3, 4)\n",
        "matriz_2x6 = vetor_original.reshape(2, 6)\n",
        "\n",
        "print(\"Vetor original:\", vetor_original)\n",
        "print(\"\\nReshape para 3x4:\")\n",
        "print(matriz_3x4)\n",
        "print(\"\\nReshape para 2x6:\")\n",
        "print(matriz_2x6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Indexa√ß√£o e Slicing - Navegando pela Matriz\n\nT√°, mas como acessar elementos espec√≠ficos da matriz? √â como encontrar um assento espec√≠fico no est√°dio do Maracan√£ - voc√™ precisa da setor (linha) e da cadeira (coluna)!\n\nA indexa√ß√£o em NumPy usa a nota√ß√£o: `array[linha, coluna]`\n\n**Dica do Pedro:** Lembre-se que Python come√ßa contando do 0, n√£o do 1! √â como andar de elevador - t√©rreo √© 0! üè¢"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criando uma matriz para demonstrar indexa√ß√£o\n",
        "matriz_demo = np.array([[10, 20, 30, 40],\n",
        "                        [50, 60, 70, 80],\n",
        "                        [90, 100, 110, 120]])\n",
        "\n",
        "print(\"Matriz original:\")\n",
        "print(matriz_demo)\n",
        "print()\n",
        "\n",
        "# Acessando elementos individuais\n",
        "print(\"Elemento [0,0]:\", matriz_demo[0, 0])  # Primeiro elemento\n",
        "print(\"Elemento [1,2]:\", matriz_demo[1, 2])  # Segunda linha, terceira coluna\n",
        "print(\"√öltimo elemento:\", matriz_demo[-1, -1])  # √çndices negativos!\n",
        "print()\n",
        "\n",
        "# Slicing - pegando peda√ßos da matriz\n",
        "print(\"Primeira linha completa:\", matriz_demo[0, :])  # : significa \"todos\"\n",
        "print(\"Segunda coluna completa:\", matriz_demo[:, 1])\n",
        "print(\"Submatriz 2x2 do canto superior esquerdo:\")\n",
        "print(matriz_demo[0:2, 0:2])\n",
        "print()\n",
        "\n",
        "# Indexa√ß√£o avan√ßada\n",
        "linhas_desejadas = [0, 2]  # Primeira e terceira linha\n",
        "colunas_desejadas = [1, 3]  # Segunda e quarta coluna\n",
        "print(\"Submatriz com linhas [0,2] e colunas [1,3]:\")\n",
        "print(matriz_demo[np.ix_(linhas_desejadas, colunas_desejadas)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚ö° Se√ß√£o 3: Opera√ß√µes Matem√°ticas - Revendo os Conceitos\n\nAgora vamos implementar na pr√°tica as opera√ß√µes que vimos no M√≥dulo 2 (vetores) e M√≥dulo 3 (matrizes)!\n\n### Produto Escalar (Dot Product)\nLembra da f√≥rmula do produto escalar? Para dois vetores $\\vec{a}$ e $\\vec{b}$:\n\n$$\\vec{a} \\cdot \\vec{b} = \\sum_{i=1}^{n} a_i b_i = a_1b_1 + a_2b_2 + \\cdots + a_nb_n$$\n\n### Multiplica√ß√£o de Matrizes\nPara matrizes $A_{m \\times k}$ e $B_{k \\times n}$, o elemento $(i,j)$ do produto √©:\n\n$$C_{ij} = \\sum_{k=1}^{K} A_{ik} B_{kj}$$\n\n**Dica do Pedro:** NumPy faz tudo isso numa velocidade absurda usando otimiza√ß√µes em C! √â magia pura! ‚ú®"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Opera√ß√µes com vetores (revisando M√≥dulo 2)\n",
        "vetor_a = np.array([1, 2, 3])\n",
        "vetor_b = np.array([4, 5, 6])\n",
        "\n",
        "print(\"Vetor A:\", vetor_a)\n",
        "print(\"Vetor B:\", vetor_b)\n",
        "print()\n",
        "\n",
        "# Opera√ß√µes b√°sicas\n",
        "soma = vetor_a + vetor_b\n",
        "subtracao = vetor_a - vetor_b\n",
        "multiplicacao_elemento = vetor_a * vetor_b  # Element-wise!\n",
        "\n",
        "print(\"Soma:\", soma)\n",
        "print(\"Subtra√ß√£o:\", subtracao)\n",
        "print(\"Mult. elemento a elemento:\", multiplicacao_elemento)\n",
        "print()\n",
        "\n",
        "# Produto escalar (DOT PRODUCT) - super importante para IA!\n",
        "produto_escalar = np.dot(vetor_a, vetor_b)\n",
        "# Ou pode usar o operador @\n",
        "produto_escalar_2 = vetor_a @ vetor_b\n",
        "\n",
        "print(\"Produto escalar:\", produto_escalar)\n",
        "print(\"Usando @:\", produto_escalar_2)\n",
        "print()\n",
        "\n",
        "# Norma do vetor (comprimento)\n",
        "norma_a = np.linalg.norm(vetor_a)\n",
        "print(f\"Norma do vetor A: {norma_a:.3f}\")\n",
        "\n",
        "# Similaridade por cosseno (muito usado em IA!)\n",
        "similaridade = produto_escalar / (np.linalg.norm(vetor_a) * np.linalg.norm(vetor_b))\n",
        "print(f\"Similaridade por cosseno: {similaridade:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Opera√ß√µes com matrizes (revisando M√≥dulo 3)\n",
        "matriz_A = np.array([[1, 2], \n",
        "                     [3, 4]])\n",
        "\n",
        "matriz_B = np.array([[5, 6], \n",
        "                     [7, 8]])\n",
        "\n",
        "print(\"Matriz A:\")\n",
        "print(matriz_A)\n",
        "print(\"\\nMatriz B:\")\n",
        "print(matriz_B)\n",
        "print()\n",
        "\n",
        "# Opera√ß√µes elemento a elemento\n",
        "soma_matrizes = matriz_A + matriz_B\n",
        "mult_elemento = matriz_A * matriz_B\n",
        "\n",
        "print(\"Soma das matrizes:\")\n",
        "print(soma_matrizes)\n",
        "print(\"\\nMultiplica√ß√£o elemento a elemento:\")\n",
        "print(mult_elemento)\n",
        "print()\n",
        "\n",
        "# MULTIPLICA√á√ÉO DE MATRIZES (a verdadeira!)\n",
        "produto_matricial = np.dot(matriz_A, matriz_B)\n",
        "# Ou usando @\n",
        "produto_matricial_2 = matriz_A @ matriz_B\n",
        "\n",
        "print(\"Produto matricial (A √ó B):\")\n",
        "print(produto_matricial)\n",
        "print(\"\\nUsando @:\")\n",
        "print(produto_matricial_2)\n",
        "\n",
        "# Verificando se s√£o iguais\n",
        "print(\"\\nS√£o iguais?\", np.array_equal(produto_matricial, produto_matricial_2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üé® Visualizando Matrizes\n\nUma imagem vale mais que mil palavras! Vamos visualizar nossas matrizes para entender melhor o que est√° acontecendo.\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/algebra-linear-para-ia-modulo-04_img_02.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criando uma matriz interessante para visualizar\n",
        "x = np.linspace(-2, 2, 50)\n",
        "y = np.linspace(-2, 2, 50)\n",
        "X, Y = np.meshgrid(x, y)\n",
        "Z = np.sin(X) * np.cos(Y)  # Fun√ß√£o matem√°tica bonita!\n",
        "\n",
        "# Criando subplots\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "# Heatmap da matriz\n",
        "im1 = axes[0].imshow(Z, cmap='viridis', extent=[-2, 2, -2, 2])\n",
        "axes[0].set_title('Heatmap da Matriz')\n",
        "axes[0].set_xlabel('X')\n",
        "axes[0].set_ylabel('Y')\n",
        "plt.colorbar(im1, ax=axes[0])\n",
        "\n",
        "# Gr√°fico 3D (representa√ß√£o de superf√≠cie)\n",
        "im2 = axes[1].contour(X, Y, Z, levels=20)\n",
        "axes[1].set_title('Contorno da Matriz')\n",
        "axes[1].set_xlabel('X')\n",
        "axes[1].set_ylabel('Y')\n",
        "\n",
        "# Uma matriz simples\n",
        "matriz_simples = np.random.rand(10, 10)\n",
        "im3 = axes[2].imshow(matriz_simples, cmap='hot')\n",
        "axes[2].set_title('Matriz Aleat√≥ria 10x10')\n",
        "plt.colorbar(im3, ax=axes[2])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Liiiindo! Agora voc√™ pode VER as matrizes! üé®\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÄ Broadcasting - A M√°gica do NumPy\n\nBroadcasting √© o superpoder do NumPy! √â como ele consegue fazer opera√ß√µes entre arrays de tamanhos diferentes. √â tipo aquele amigo que sempre se adapta a qualquer situa√ß√£o! üòÑ\n\n**Regras do Broadcasting:**\n1. Se os arrays t√™m dimens√µes diferentes, o menor √© \"esticado\"\n2. Se as dimens√µes n√£o s√£o compat√≠veis, d√° erro\n3. O resultado tem o tamanho do maior array\n\n```mermaid\ngraph LR\n    A[Array 3x3] -->|Broadcasting| C[Resultado 3x3]\n    B[Array 1x3] -->|Broadcasting| C\n    D[Escalar] -->|Broadcasting| A\n```\n\n**Dica do Pedro:** Broadcasting √© fundamental para efici√™ncia em IA - evita loops desnecess√°rios! üèÉ‚Äç‚ôÇÔ∏èüí®"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exemplos de Broadcasting\n",
        "\n",
        "# 1. Escalar com matriz\n",
        "matriz = np.array([[1, 2, 3],\n",
        "                   [4, 5, 6],\n",
        "                   [7, 8, 9]])\n",
        "\n",
        "escalar = 10\n",
        "resultado_escalar = matriz + escalar  # Soma 10 a cada elemento!\n",
        "\n",
        "print(\"Matriz original:\")\n",
        "print(matriz)\n",
        "print(\"\\nMatriz + 10 (broadcasting):\")\n",
        "print(resultado_escalar)\n",
        "print()\n",
        "\n",
        "# 2. Vetor com matriz\n",
        "vetor_linha = np.array([10, 20, 30])  # Shape: (3,)\n",
        "resultado_vetor = matriz + vetor_linha  # Soma o vetor a cada linha!\n",
        "\n",
        "print(\"Vetor:\", vetor_linha)\n",
        "print(\"\\nMatriz + Vetor (broadcasting):\")\n",
        "print(resultado_vetor)\n",
        "print()\n",
        "\n",
        "# 3. Exemplo mais complexo\n",
        "matriz_2d = np.ones((4, 3))\n",
        "vetor_coluna = np.array([[1], [2], [3], [4]])  # Shape: (4, 1)\n",
        "vetor_linha_2 = np.array([10, 20, 30])  # Shape: (3,)\n",
        "\n",
        "# Broadcasting m√°gico!\n",
        "resultado_complexo = matriz_2d + vetor_coluna + vetor_linha_2\n",
        "\n",
        "print(\"Broadcasting complexo:\")\n",
        "print(\"Matriz 4x3 + Vetor coluna 4x1 + Vetor linha 1x3\")\n",
        "print(resultado_complexo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚ö° Performance - Por que NumPy √© T√£o R√°pido?\n\nVamos fazer um teste pr√°tico! NumPy √© implementado em C e usa **opera√ß√µes vetorizadas**. √â como comparar um carro de F√≥rmula 1 com uma carro√ßa!\n\n**Dica do Pedro:** Em IA, performance √© CRUCIAL. Uma opera√ß√£o que demora 1 segundo pode demorar horas quando repetida milh√µes de vezes! ‚è±Ô∏è"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Teste de performance: Python puro vs NumPy\n",
        "\n",
        "# Criando dados grandes\n",
        "tamanho = 1000000  # 1 milh√£o de elementos\n",
        "lista_python_1 = list(range(tamanho))\n",
        "lista_python_2 = list(range(tamanho, 2*tamanho))\n",
        "\n",
        "array_numpy_1 = np.arange(tamanho)\n",
        "array_numpy_2 = np.arange(tamanho, 2*tamanho)\n",
        "\n",
        "print(f\"Testando com {tamanho:,} elementos\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Teste 1: Soma com Python puro\n",
        "inicio = time.time()\n",
        "resultado_python = [a + b for a, b in zip(lista_python_1, lista_python_2)]\n",
        "tempo_python = time.time() - inicio\n",
        "\n",
        "print(f\"Python puro: {tempo_python:.4f} segundos\")\n",
        "\n",
        "# Teste 2: Soma com NumPy\n",
        "inicio = time.time()\n",
        "resultado_numpy = array_numpy_1 + array_numpy_2\n",
        "tempo_numpy = time.time() - inicio\n",
        "\n",
        "print(f\"NumPy:       {tempo_numpy:.4f} segundos\")\n",
        "\n",
        "# Calculando o speedup\n",
        "speedup = tempo_python / tempo_numpy\n",
        "print(f\"\\nüöÄ NumPy √© {speedup:.1f}x mais r√°pido!\")\n",
        "\n",
        "# Verificando se os resultados s√£o iguais\n",
        "print(f\"\\nResultados iguais? {np.array_equal(resultado_python, resultado_numpy)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Gr√°fico de Performance\n\nVamos visualizar como a performance varia com o tamanho dos dados:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Testando diferentes tamanhos\n",
        "tamanhos = [1000, 5000, 10000, 50000, 100000, 500000]\n",
        "tempos_python = []\n",
        "tempos_numpy = []\n",
        "\n",
        "for tam in tamanhos:\n",
        "    # Dados de teste\n",
        "    lista_1 = list(range(tam))\n",
        "    lista_2 = list(range(tam, 2*tam))\n",
        "    array_1 = np.arange(tam)\n",
        "    array_2 = np.arange(tam, 2*tam)\n",
        "    \n",
        "    # Teste Python\n",
        "    inicio = time.time()\n",
        "    _ = [a + b for a, b in zip(lista_1, lista_2)]\n",
        "    tempos_python.append(time.time() - inicio)\n",
        "    \n",
        "    # Teste NumPy\n",
        "    inicio = time.time()\n",
        "    _ = array_1 + array_2\n",
        "    tempos_numpy.append(time.time() - inicio)\n",
        "\n",
        "# Plotando os resultados\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(tamanhos, tempos_python, 'ro-', label='Python Puro', linewidth=2)\n",
        "plt.plot(tamanhos, tempos_numpy, 'bo-', label='NumPy', linewidth=2)\n",
        "plt.xlabel('Tamanho dos Arrays')\n",
        "plt.ylabel('Tempo (segundos)')\n",
        "plt.title('Compara√ß√£o de Performance')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "speedups = [p/n for p, n in zip(tempos_python, tempos_numpy)]\n",
        "plt.bar(range(len(tamanhos)), speedups, color='green', alpha=0.7)\n",
        "plt.xlabel('Tamanho dos Arrays')\n",
        "plt.ylabel('Speedup (vezes mais r√°pido)')\n",
        "plt.title('Acelera√ß√£o do NumPy')\n",
        "plt.xticks(range(len(tamanhos)), [f'{t//1000}k' for t in tamanhos])\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"NumPy n√£o √© brincadeira! Olha essa performance! üöÄ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Aplica√ß√µes Pr√°ticas para IA\n\nAgora vamos ver como essas opera√ß√µes se conectam com Intelig√™ncia Artificial! Lembra que estamos construindo a base para entender redes neurais?\n\n### Exemplo 1: Camada Linear de uma Rede Neural\n\nUma camada linear faz exatamente a multiplica√ß√£o que vimos no M√≥dulo 3:\n\n$$\\vec{y} = W \\vec{x} + \\vec{b}$$\n\nOnde:\n- $W$ √© a matriz de pesos\n- $\\vec{x}$ √© o vetor de entrada\n- $\\vec{b}$ √© o vetor de bias\n- $\\vec{y}$ √© a sa√≠da\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/algebra-linear-para-ia-modulo-04_img_03.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simulando uma camada linear simples\n",
        "\n",
        "# Par√¢metros da camada\n",
        "entrada_dim = 4  # 4 features de entrada\n",
        "saida_dim = 3    # 3 neur√¥nios na sa√≠da\n",
        "\n",
        "# Inicializando pesos aleat√≥rios (como numa rede neural real!)\n",
        "np.random.seed(42)\n",
        "W = np.random.randn(saida_dim, entrada_dim) * 0.5  # Matriz de pesos\n",
        "b = np.random.randn(saida_dim) * 0.1               # Vetor de bias\n",
        "\n",
        "print(\"Matriz de pesos W (3x4):\")\n",
        "print(W)\n",
        "print(\"\\nVetor de bias b:\")\n",
        "print(b)\n",
        "print()\n",
        "\n",
        "# Entrada exemplo (poderia ser uma imagem processada, texto, etc.)\n",
        "x = np.array([1.0, 2.0, -0.5, 3.0])\n",
        "print(\"Entrada x:\", x)\n",
        "\n",
        "# Opera√ß√£o da camada linear: y = Wx + b\n",
        "y = W @ x + b  # Aqui est√° a m√°gica!\n",
        "\n",
        "print(\"\\nSa√≠da y = Wx + b:\")\n",
        "print(y)\n",
        "\n",
        "# Em redes neurais, geralmente aplicamos uma fun√ß√£o de ativa√ß√£o\n",
        "# Exemplo: ReLU (Rectified Linear Unit)\n",
        "y_relu = np.maximum(0, y)  # ReLU: max(0, x)\n",
        "print(\"\\nAp√≥s ReLU:\")\n",
        "print(y_relu)\n",
        "\n",
        "print(\"\\nüß† Parab√©ns! Voc√™ acabou de implementar uma camada neural!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exemplo 2: Calculando Similaridades (Base para Sistemas de Recomenda√ß√£o)\n\nVamos usar o produto escalar do M√≥dulo 2 para calcular similaridades entre usu√°rios:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sistema de recomenda√ß√£o simples usando similaridade por cosseno\n",
        "\n",
        "# Matriz de prefer√™ncias: cada linha √© um usu√°rio, cada coluna √© um filme\n",
        "# Valores de 1-5 (nota que o usu√°rio daria)\n",
        "preferencias = np.array([\n",
        "    [5, 3, 0, 1, 4],  # Usu√°rio 1\n",
        "    [3, 1, 0, 2, 3],  # Usu√°rio 2  \n",
        "    [4, 3, 0, 1, 5],  # Usu√°rio 3\n",
        "    [3, 3, 0, 5, 4],  # Usu√°rio 4\n",
        "    [0, 0, 0, 2, 0],  # Usu√°rio 5\n",
        "])\n",
        "\n",
        "filmes = ['Vingadores', 'Romance', 'Terror', 'Com√©dia', 'Fic√ß√£o']\n",
        "usuarios = ['Ana', 'Bruno', 'Carlos', 'Diana', 'Eduardo']\n",
        "\n",
        "print(\"Matriz de Prefer√™ncias:\")\n",
        "print(\"Usu√°rios x Filmes\")\n",
        "print(preferencias)\n",
        "print()\n",
        "\n",
        "# Calculando similaridade entre todos os usu√°rios\n",
        "def similaridade_cosseno(u1, u2):\n",
        "    \"\"\"Calcula similaridade por cosseno entre dois vetores\"\"\"\n",
        "    dot_product = np.dot(u1, u2)\n",
        "    norma_u1 = np.linalg.norm(u1)\n",
        "    norma_u2 = np.linalg.norm(u2)\n",
        "    \n",
        "    if norma_u1 == 0 or norma_u2 == 0:\n",
        "        return 0\n",
        "    \n",
        "    return dot_product / (norma_u1 * norma_u2)\n",
        "\n",
        "# Matriz de similaridades\n",
        "n_usuarios = len(usuarios)\n",
        "matriz_similaridade = np.zeros((n_usuarios, n_usuarios))\n",
        "\n",
        "for i in range(n_usuarios):\n",
        "    for j in range(n_usuarios):\n",
        "        matriz_similaridade[i, j] = similaridade_cosseno(preferencias[i], preferencias[j])\n",
        "\n",
        "print(\"Matriz de Similaridade:\")\n",
        "print(matriz_similaridade.round(3))\n",
        "print()\n",
        "\n",
        "# Encontrando usu√°rios mais similares √† Ana (usu√°rio 0)\n",
        "ana_similaridades = matriz_similaridade[0, 1:]  # Excluindo ela mesma\n",
        "usuario_mais_similar = np.argmax(ana_similaridades) + 1  # +1 porque pulamos Ana\n",
        "\n",
        "print(f\"Usu√°rio mais similar √† Ana: {usuarios[usuario_mais_similar]}\")\n",
        "print(f\"Similaridade: {ana_similaridades[usuario_mais_similar-1]:.3f}\")\n",
        "\n",
        "print(\"\\nüé¨ Sistema de recomenda√ß√£o b√°sico funcionando!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üèãÔ∏è Exerc√≠cio Pr√°tico 1: Construindo uma Mini Rede Neural\n\nAgora √© sua vez! Vamos construir uma rede neural simples para classificar se um n√∫mero √© positivo ou negativo.\n\n**Sua miss√£o:**\n1. Criar dados de treino\n2. Implementar forward pass\n3. Calcular a acur√°cia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# EXERC√çCIO 1: Complete o c√≥digo abaixo\n",
        "\n",
        "# 1. Criar dados de treino\n",
        "np.random.seed(42)\n",
        "X = np.random.randn(100, 1)  # 100 amostras, 1 feature\n",
        "y = (X > 0).astype(int).flatten()  # 1 se positivo, 0 se negativo\n",
        "\n",
        "print(\"Primeiros 10 exemplos:\")\n",
        "for i in range(10):\n",
        "    print(f\"X[{i}] = {X[i,0]:.3f} -> y[{i}] = {y[i]}\")\n",
        "print()\n",
        "\n",
        "# 2. Par√¢metros da rede neural\n",
        "# TODO: Complete os par√¢metros\n",
        "W1 = np.random.randn(5, 1) * 0.5   # Primeira camada: 1 -> 5 neur√¥nios\n",
        "b1 = np.zeros(5)                   # Bias primeira camada\n",
        "W2 = np.random.randn(1, 5) * 0.5   # Segunda camada: 5 -> 1 neur√¥nio\n",
        "b2 = np.zeros(1)                   # Bias segunda camada\n",
        "\n",
        "def sigmoid(x):\n",
        "    \"\"\"Fun√ß√£o sigmoide\"\"\"\n",
        "    return 1 / (1 + np.exp(-np.clip(x, -500, 500)))  # Clip para evitar overflow\n",
        "\n",
        "def forward_pass(X):\n",
        "    \"\"\"Forward pass da rede neural\"\"\"\n",
        "    # TODO: Implemente o forward pass\n",
        "    # Dica: z1 = X @ W1.T + b1, a1 = relu(z1), z2 = a1 @ W2.T + b2, a2 = sigmoid(z2)\n",
        "    \n",
        "    z1 = X @ W1.T + b1                    # Primeira camada linear\n",
        "    a1 = np.maximum(0, z1)               # ReLU\n",
        "    z2 = a1 @ W2.T + b2                  # Segunda camada linear  \n",
        "    a2 = sigmoid(z2)                     # Sigmoide (probabilidade)\n",
        "    \n",
        "    return a2\n",
        "\n",
        "# 3. Fazer predi√ß√µes\n",
        "predictions = forward_pass(X)\n",
        "predicted_classes = (predictions > 0.5).astype(int).flatten()\n",
        "\n",
        "# 4. Calcular acur√°cia\n",
        "accuracy = np.mean(predicted_classes == y)\n",
        "print(f\"Acur√°cia: {accuracy:.2%}\")\n",
        "\n",
        "# Mostrar alguns resultados\n",
        "print(\"\\nPrimeiras 10 predi√ß√µes:\")\n",
        "for i in range(10):\n",
        "    prob = predictions[i, 0]\n",
        "    pred = predicted_classes[i]\n",
        "    real = y[i]\n",
        "    status = \"‚úì\" if pred == real else \"‚úó\"\n",
        "    print(f\"X={X[i,0]:6.3f} | Prob={prob:.3f} | Pred={pred} | Real={real} {status}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üé≤ Exerc√≠cio Pr√°tico 2: An√°lise de Componentes Principais (Prepara√ß√£o para M√≥dulo 10)\n\nVamos ter um gostinho do que vem no M√≥dulo 10! Use NumPy para fazer uma an√°lise simples de dados.\n\n**Sua miss√£o:**\n1. Gerar dados 2D correlacionados\n2. Calcular matriz de covari√¢ncia\n3. Visualizar os dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# EXERC√çCIO 2: An√°lise explorat√≥ria com NumPy\n",
        "\n",
        "# 1. Gerar dados correlacionados\n",
        "np.random.seed(42)\n",
        "n_samples = 200\n",
        "\n",
        "# TODO: Complete o c√≥digo para gerar dados correlacionados\n",
        "# Dica: Use uma transforma√ß√£o linear para criar correla√ß√£o\n",
        "\n",
        "# Dados base (n√£o correlacionados)\n",
        "data_base = np.random.randn(n_samples, 2)\n",
        "\n",
        "# Matriz de transforma√ß√£o para criar correla√ß√£o\n",
        "transform_matrix = np.array([[2, 1.5],\n",
        "                            [0.5, 1]])\n",
        "\n",
        "# Aplicar transforma√ß√£o\n",
        "data_transformed = data_base @ transform_matrix.T\n",
        "\n",
        "print(\"Forma dos dados:\", data_transformed.shape)\n",
        "print(\"Primeiras 5 amostras:\")\n",
        "print(data_transformed[:5])\n",
        "print()\n",
        "\n",
        "# 2. Calcular estat√≠sticas\n",
        "# TODO: Calcule m√©dia, desvio padr√£o e matriz de covari√¢ncia\n",
        "\n",
        "media = np.mean(data_transformed, axis=0)\n",
        "desvio = np.std(data_transformed, axis=0)\n",
        "cov_matrix = np.cov(data_transformed.T)\n",
        "\n",
        "print(\"M√©dia:\", media)\n",
        "print(\"Desvio padr√£o:\", desvio)\n",
        "print(\"\\nMatriz de Covari√¢ncia:\")\n",
        "print(cov_matrix)\n",
        "print(f\"\\nCorrela√ß√£o entre X e Y: {cov_matrix[0,1] / (desvio[0] * desvio[1]):.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. Visualizar os dados\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "# Dados originais\n",
        "axes[0].scatter(data_base[:, 0], data_base[:, 1], alpha=0.6, c='blue')\n",
        "axes[0].set_title('Dados Originais (N√£o Correlacionados)')\n",
        "axes[0].set_xlabel('X')\n",
        "axes[0].set_ylabel('Y')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "axes[0].axis('equal')\n",
        "\n",
        "# Dados transformados\n",
        "axes[1].scatter(data_transformed[:, 0], data_transformed[:, 1], alpha=0.6, c='red')\n",
        "axes[1].set_title('Dados Transformados (Correlacionados)')\n",
        "axes[1].set_xlabel('X')\n",
        "axes[1].set_ylabel('Y')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "# Matriz de covari√¢ncia como heatmap\n",
        "im = axes[2].imshow(cov_matrix, cmap='RdBu', center=0)\n",
        "axes[2].set_title('Matriz de Covari√¢ncia')\n",
        "axes[2].set_xticks([0, 1])\n",
        "axes[2].set_yticks([0, 1])\n",
        "axes[2].set_xticklabels(['X', 'Y'])\n",
        "axes[2].set_yticklabels(['X', 'Y'])\n",
        "\n",
        "# Adicionando valores na matriz\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        axes[2].text(j, i, f'{cov_matrix[i,j]:.2f}', \n",
        "                    ha='center', va='center', fontsize=12, color='white')\n",
        "\n",
        "plt.colorbar(im, ax=axes[2])\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üéØ √ìtimo trabalho! Voc√™ acabou de fazer uma an√°lise explorat√≥ria completa!\")\n",
        "print(\"No M√≥dulo 10, vamos aprofundar isso com PCA e autovetores! üöÄ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîß Fun√ß√µes √öteis do NumPy para IA\n\nAntes de terminar, vamos ver algumas fun√ß√µes que voc√™ VAI usar muito em projetos de IA:\n\n**Dica do Pedro:** Salve esta c√©lula como refer√™ncia! S√£o as fun√ß√µes que mais uso no dia a dia! üìå"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cheat Sheet: Fun√ß√µes essenciais do NumPy para IA\n",
        "\n",
        "print(\"üéØ CHEAT SHEET NUMPY PARA IA\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "# 1. Cria√ß√£o de arrays\n",
        "print(\"\\n1. CRIA√á√ÉO:\")\n",
        "print(\"np.zeros((3,3))     - Matriz de zeros\")\n",
        "print(\"np.ones((3,3))      - Matriz de uns\")\n",
        "print(\"np.eye(3)           - Matriz identidade\")\n",
        "print(\"np.random.randn(3,3) - N√∫meros aleat√≥rios (normal)\")\n",
        "print(\"np.arange(10)       - Sequ√™ncia [0,1,2...9]\")\n",
        "print(\"np.linspace(0,1,5)  - 5 pontos entre 0 e 1\")\n",
        "\n",
        "# 2. Opera√ß√µes matem√°ticas\n",
        "print(\"\\n2. OPERA√á√ïES:\")\n",
        "print(\"a @ b               - Multiplica√ß√£o de matrizes\")\n",
        "print(\"np.dot(a, b)        - Produto escalar/matricial\")\n",
        "print(\"np.linalg.norm(a)   - Norma do vetor\")\n",
        "print(\"np.sum(a, axis=0)   - Soma por colunas\")\n",
        "print(\"np.mean(a, axis=1)  - M√©dia por linhas\")\n",
        "print(\"np.max(a), np.min(a) - M√°ximo e m√≠nimo\")\n",
        "\n",
        "# 3. Manipula√ß√£o de forma\n",
        "print(\"\\n3. MANIPULA√á√ÉO:\")\n",
        "print(\"a.reshape(2, 3)     - Mudar formato\")\n",
        "print(\"a.T                 - Transposta\")\n",
        "print(\"a.flatten()         - Achatar array\")\n",
        "print(\"np.concatenate()    - Juntar arrays\")\n",
        "print(\"np.split()          - Dividir arrays\")\n",
        "\n",
        "# 4. Fun√ß√µes para IA\n",
        "print(\"\\n4. ESPEC√çFICAS PARA IA:\")\n",
        "print(\"np.argmax(a)        - √çndice do maior elemento\")\n",
        "print(\"np.where(condition) - √çndices onde condi√ß√£o √© True\")\n",
        "print(\"np.clip(a, min, max) - Limitar valores\")\n",
        "print(\"np.exp(a)           - Exponencial (softmax, sigmoid)\")\n",
        "print(\"np.log(a)           - Logaritmo (loss functions)\")\n",
        "\n",
        "# Exemplos pr√°ticos\n",
        "print(\"\\n\\nüî• EXEMPLOS PR√ÅTICOS:\")\n",
        "print(\"=\"*30)\n",
        "\n",
        "# Softmax (muito usado em classifica√ß√£o!)\n",
        "logits = np.array([2.0, 1.0, 0.1])\n",
        "exp_logits = np.exp(logits)\n",
        "softmax = exp_logits / np.sum(exp_logits)\n",
        "print(f\"Softmax: {logits} -> {softmax.round(3)}\")\n",
        "\n",
        "# One-hot encoding\n",
        "classes = np.array([0, 1, 2, 1, 0])\n",
        "n_classes = 3\n",
        "one_hot = np.eye(n_classes)[classes]\n",
        "print(f\"\\nOne-hot: {classes}\")\n",
        "print(one_hot)\n",
        "\n",
        "# Normaliza√ß√£o (muito importante!)\n",
        "data = np.random.randn(5, 3)\n",
        "normalized = (data - np.mean(data, axis=0)) / np.std(data, axis=0)\n",
        "print(f\"\\nNormaliza√ß√£o - antes m√©dia: {np.mean(data, axis=0).round(3)}\")\n",
        "print(f\"Depois m√©dia: {np.mean(normalized, axis=0).round(3)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Resumo e Pr√≥ximos Passos\n\nParab√©ns! üéâ Voc√™ acabou de dominar o NumPy - a base de TUDO em IA com Python!\n\n### O que voc√™ aprendeu:\n\n‚úÖ **Cria√ß√£o eficiente** de vetores e matrizes  \n‚úÖ **Opera√ß√µes matem√°ticas** otimizadas (produtos escalar e matricial)  \n‚úÖ **Broadcasting** - a m√°gica do NumPy  \n‚úÖ **Performance** - Por que NumPy √© essencial  \n‚úÖ **Aplica√ß√µes pr√°ticas** em IA (redes neurais, sistemas de recomenda√ß√£o)  \n\n### Conex√µes com outros m√≥dulos:\n\n```mermaid\ngraph TD\n    A[M√≥dulo 1-3: Teoria] --> B[M√≥dulo 4: NumPy - ATUAL]\n    B --> C[M√≥dulo 5: Sistemas Lineares]\n    B --> D[M√≥dulo 6: Transforma√ß√µes]\n    B --> E[M√≥dulo 7: Inversa/Transposta]\n    B --> F[M√≥dulo 8: Determinante]\n    B --> G[M√≥dulo 9: SVD]\n    B --> H[M√≥dulo 10: PCA/Autovetores]\n```\n\n### Pr√≥ximo m√≥dulo:\n**M√≥dulo 5: Sistemas de Equa√ß√µes Lineares** - Vamos resolver problemas reais usando as ferramentas que voc√™ acabou de aprender!\n\n**Dica do Pedro Final:** Pratique! Crie seus pr√≥prios arrays, experimente com diferentes opera√ß√µes. NumPy √© como andar de bicicleta - quanto mais voc√™ pratica, mais natural fica! üö¥‚Äç‚ôÇÔ∏è\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/algebra-linear-para-ia-modulo-04_img_04.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n\n## üìö Recursos Extras\n\n**Para se aprofundar:**\n- Documenta√ß√£o oficial do NumPy\n- NumPy User Guide\n- Curso \"√Ålgebra Linear para IA\" - M√≥dulos seguintes\n\n**At√© o pr√≥ximo m√≥dulo!** üöÄ\n\n*Pedro Nunes Guth - Expert em IA e Matem√°tica*"
      ]
    }
  ]
}