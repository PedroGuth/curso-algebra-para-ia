{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸ¯ Matrizes em Python: NumPai de Todos\n\n## MÃ³dulo 4: Ãlgebra Linear para IA\n\n**Por: Pedro Nunes Guth**\n\n---\n\nBora colocar a mÃ£o na massa! ğŸš€ Nos mÃ³dulos anteriores vocÃª aprendeu a teoria por trÃ¡s de escalares, vetores e matrizes. Agora chegou a hora de fazer a mÃ¡gica acontecer com Python e NumPy!\n\nTÃ¡, mas por que NumPy? Simples: Ã© o **pai de todos** quando se trata de computaÃ§Ã£o numÃ©rica em Python. Ã‰ como se fosse o motor V8 do seu carro - vocÃª pode atÃ© nÃ£o ver, mas Ã© ele que faz tudo funcionar liindamente!\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/algebra-linear-para-ia-modulo-04_img_01.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“š O que vamos aprender?\n\nNeste notebook, vocÃª vai dominar:\n\n- âœ… CriaÃ§Ã£o eficiente de vetores e matrizes\n- âœ… ManipulaÃ§Ã£o e indexaÃ§Ã£o avanÃ§ada\n- âœ… OperaÃ§Ãµes matemÃ¡ticas otimizadas\n- âœ… Broadcasting: a mÃ¡gica por trÃ¡s das operaÃ§Ãµes\n- âœ… Performance: NumPy vs Python puro\n\n```mermaid\ngraph TD\n    A[Python Lists] -->|Lento e Ineficiente| B[Problemas de Performance]\n    C[NumPy Arrays] -->|RÃ¡pido e Otimizado| D[OperaÃ§Ãµes Vetorizadas]\n    D --> E[Machine Learning Eficiente]\n    E --> F[IA de Alto Performance]\n```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Primeiro, vamos importar nosso NumPai de todos! ğŸ‰\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "# ConfiguraÃ§Ãµes para visualizaÃ§Ã£o\n",
        "plt.rcParams['figure.figsize'] = (10, 6)\n",
        "np.set_printoptions(precision=3, suppress=True)\n",
        "\n",
        "print(\"ğŸ¯ NumPy versÃ£o:\", np.__version__)\n",
        "print(\"ğŸ’ª Pronto para dominar as matrizes!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¯ SeÃ§Ã£o 1: Criando Vetores - Os Blocos Fundamentais\n\nLembra dos vetores que vimos no MÃ³dulo 1? Agora vamos criar eles na prÃ¡tica! Um vetor em NumPy Ã© como uma fila de nÃºmeros organizados, tipo aquela fila do pÃ£o de aÃ§Ãºcar - cada posiÃ§Ã£o tem seu valor especÃ­fico.\n\nMatematicamente, um vetor $\\vec{v}$ pode ser representado como:\n\n$$\\vec{v} = \\begin{pmatrix} v_1 \\\\ v_2 \\\\ \\vdots \\\\ v_n \\end{pmatrix}$$\n\n**Dica do Pedro:** NumPy arrays sÃ£o MUITO mais eficientes que listas Python. Ã‰ como comparar uma Ferrari com uma carroÃ§a! ğŸï¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# VÃ¡rias formas de criar vetores\n",
        "\n",
        "# 1. A partir de uma lista Python\n",
        "vetor_lista = np.array([1, 2, 3, 4, 5])\n",
        "print(\"Vetor da lista:\", vetor_lista)\n",
        "print(\"Tipo:\", type(vetor_lista))\n",
        "print(\"Shape (formato):\", vetor_lista.shape)\n",
        "print(\"DimensÃµes:\", vetor_lista.ndim)\n",
        "print()\n",
        "\n",
        "# 2. Usando funÃ§Ãµes especiais do NumPy\n",
        "zeros = np.zeros(5)  # Vetor de zeros\n",
        "ones = np.ones(5)    # Vetor de uns\n",
        "range_vec = np.arange(0, 10, 2)  # De 0 a 10, pulando de 2 em 2\n",
        "linspace_vec = np.linspace(0, 1, 5)  # 5 pontos entre 0 e 1\n",
        "\n",
        "print(\"Zeros:\", zeros)\n",
        "print(\"Ones:\", ones)\n",
        "print(\"Range:\", range_vec)\n",
        "print(\"Linspace:\", linspace_vec)\n",
        "print()\n",
        "\n",
        "# 3. Vetores aleatÃ³rios (muito usados em IA!)\n",
        "np.random.seed(42)  # Para resultados reproduzÃ­veis\n",
        "random_vec = np.random.random(5)  # Entre 0 e 1\n",
        "normal_vec = np.random.normal(0, 1, 5)  # DistribuiÃ§Ã£o normal\n",
        "\n",
        "print(\"Random:\", random_vec)\n",
        "print(\"Normal:\", normal_vec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ”¢ SeÃ§Ã£o 2: Matrizes - O Poder dos Dados Organizados\n\nAgora vamos para as matrizes! Lembra do MÃ³dulo 1 onde vimos que uma matriz Ã© como uma tabela de nÃºmeros? Ã‰ exatamente isso que vamos criar aqui.\n\nUma matriz $A$ de dimensÃ£o $m \\times n$ Ã© representada como:\n\n$$A = \\begin{pmatrix}\na_{11} & a_{12} & \\cdots & a_{1n} \\\\\na_{21} & a_{22} & \\cdots & a_{2n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\na_{m1} & a_{m2} & \\cdots & a_{mn}\n\\end{pmatrix}$$\n\n**Dica do Pedro:** Pense numa matriz como uma planilha do Excel - linhas e colunas organizadas perfeitamente! ğŸ“Š"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criando matrizes de diferentes formas\n",
        "\n",
        "# 1. A partir de listas aninhadas\n",
        "matriz_2x3 = np.array([[1, 2, 3], \n",
        "                       [4, 5, 6]])\n",
        "print(\"Matriz 2x3:\")\n",
        "print(matriz_2x3)\n",
        "print(\"Shape:\", matriz_2x3.shape)\n",
        "print(\"DimensÃµes:\", matriz_2x3.ndim)\n",
        "print()\n",
        "\n",
        "# 2. Matrizes especiais\n",
        "matriz_zeros = np.zeros((3, 4))  # 3 linhas, 4 colunas\n",
        "matriz_ones = np.ones((2, 5))\n",
        "matriz_identidade = np.eye(4)  # Matriz identidade 4x4\n",
        "matriz_diagonal = np.diag([1, 2, 3, 4])  # Matriz diagonal\n",
        "\n",
        "print(\"Matriz de zeros (3x4):\")\n",
        "print(matriz_zeros)\n",
        "print()\n",
        "\n",
        "print(\"Matriz identidade (4x4):\")\n",
        "print(matriz_identidade)\n",
        "print()\n",
        "\n",
        "# 3. Reshaping - mudando o formato\n",
        "vetor_original = np.arange(12)\n",
        "matriz_3x4 = vetor_original.reshape(3, 4)\n",
        "matriz_2x6 = vetor_original.reshape(2, 6)\n",
        "\n",
        "print(\"Vetor original:\", vetor_original)\n",
        "print(\"\\nReshape para 3x4:\")\n",
        "print(matriz_3x4)\n",
        "print(\"\\nReshape para 2x6:\")\n",
        "print(matriz_2x6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¯ IndexaÃ§Ã£o e Slicing - Navegando pela Matriz\n\nTÃ¡, mas como acessar elementos especÃ­ficos da matriz? Ã‰ como encontrar um assento especÃ­fico no estÃ¡dio do MaracanÃ£ - vocÃª precisa da setor (linha) e da cadeira (coluna)!\n\nA indexaÃ§Ã£o em NumPy usa a notaÃ§Ã£o: `array[linha, coluna]`\n\n**Dica do Pedro:** Lembre-se que Python comeÃ§a contando do 0, nÃ£o do 1! Ã‰ como andar de elevador - tÃ©rreo Ã© 0! ğŸ¢"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criando uma matriz para demonstrar indexaÃ§Ã£o\n",
        "matriz_demo = np.array([[10, 20, 30, 40],\n",
        "                        [50, 60, 70, 80],\n",
        "                        [90, 100, 110, 120]])\n",
        "\n",
        "print(\"Matriz original:\")\n",
        "print(matriz_demo)\n",
        "print()\n",
        "\n",
        "# Acessando elementos individuais\n",
        "print(\"Elemento [0,0]:\", matriz_demo[0, 0])  # Primeiro elemento\n",
        "print(\"Elemento [1,2]:\", matriz_demo[1, 2])  # Segunda linha, terceira coluna\n",
        "print(\"Ãšltimo elemento:\", matriz_demo[-1, -1])  # Ãndices negativos!\n",
        "print()\n",
        "\n",
        "# Slicing - pegando pedaÃ§os da matriz\n",
        "print(\"Primeira linha completa:\", matriz_demo[0, :])  # : significa \"todos\"\n",
        "print(\"Segunda coluna completa:\", matriz_demo[:, 1])\n",
        "print(\"Submatriz 2x2 do canto superior esquerdo:\")\n",
        "print(matriz_demo[0:2, 0:2])\n",
        "print()\n",
        "\n",
        "# IndexaÃ§Ã£o avanÃ§ada\n",
        "linhas_desejadas = [0, 2]  # Primeira e terceira linha\n",
        "colunas_desejadas = [1, 3]  # Segunda e quarta coluna\n",
        "print(\"Submatriz com linhas [0,2] e colunas [1,3]:\")\n",
        "print(matriz_demo[np.ix_(linhas_desejadas, colunas_desejadas)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## âš¡ SeÃ§Ã£o 3: OperaÃ§Ãµes MatemÃ¡ticas - Revendo os Conceitos\n\nAgora vamos implementar na prÃ¡tica as operaÃ§Ãµes que vimos no MÃ³dulo 2 (vetores) e MÃ³dulo 3 (matrizes)!\n\n### Produto Escalar (Dot Product)\nLembra da fÃ³rmula do produto escalar? Para dois vetores $\\vec{a}$ e $\\vec{b}$:\n\n$$\\vec{a} \\cdot \\vec{b} = \\sum_{i=1}^{n} a_i b_i = a_1b_1 + a_2b_2 + \\cdots + a_nb_n$$\n\n### MultiplicaÃ§Ã£o de Matrizes\nPara matrizes $A_{m \\times k}$ e $B_{k \\times n}$, o elemento $(i,j)$ do produto Ã©:\n\n$$C_{ij} = \\sum_{k=1}^{K} A_{ik} B_{kj}$$\n\n**Dica do Pedro:** NumPy faz tudo isso numa velocidade absurda usando otimizaÃ§Ãµes em C! Ã‰ magia pura! âœ¨"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# OperaÃ§Ãµes com vetores (revisando MÃ³dulo 2)\n",
        "vetor_a = np.array([1, 2, 3])\n",
        "vetor_b = np.array([4, 5, 6])\n",
        "\n",
        "print(\"Vetor A:\", vetor_a)\n",
        "print(\"Vetor B:\", vetor_b)\n",
        "print()\n",
        "\n",
        "# OperaÃ§Ãµes bÃ¡sicas\n",
        "soma = vetor_a + vetor_b\n",
        "subtracao = vetor_a - vetor_b\n",
        "multiplicacao_elemento = vetor_a * vetor_b  # Element-wise!\n",
        "\n",
        "print(\"Soma:\", soma)\n",
        "print(\"SubtraÃ§Ã£o:\", subtracao)\n",
        "print(\"Mult. elemento a elemento:\", multiplicacao_elemento)\n",
        "print()\n",
        "\n",
        "# Produto escalar (DOT PRODUCT) - super importante para IA!\n",
        "produto_escalar = np.dot(vetor_a, vetor_b)\n",
        "# Ou pode usar o operador @\n",
        "produto_escalar_2 = vetor_a @ vetor_b\n",
        "\n",
        "print(\"Produto escalar:\", produto_escalar)\n",
        "print(\"Usando @:\", produto_escalar_2)\n",
        "print()\n",
        "\n",
        "# Norma do vetor (comprimento)\n",
        "norma_a = np.linalg.norm(vetor_a)\n",
        "print(f\"Norma do vetor A: {norma_a:.3f}\")\n",
        "\n",
        "# Similaridade por cosseno (muito usado em IA!)\n",
        "similaridade = produto_escalar / (np.linalg.norm(vetor_a) * np.linalg.norm(vetor_b))\n",
        "print(f\"Similaridade por cosseno: {similaridade:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# OperaÃ§Ãµes com matrizes (revisando MÃ³dulo 3)\n",
        "matriz_A = np.array([[1, 2], \n",
        "                     [3, 4]])\n",
        "\n",
        "matriz_B = np.array([[5, 6], \n",
        "                     [7, 8]])\n",
        "\n",
        "print(\"Matriz A:\")\n",
        "print(matriz_A)\n",
        "print(\"\\nMatriz B:\")\n",
        "print(matriz_B)\n",
        "print()\n",
        "\n",
        "# OperaÃ§Ãµes elemento a elemento\n",
        "soma_matrizes = matriz_A + matriz_B\n",
        "mult_elemento = matriz_A * matriz_B\n",
        "\n",
        "print(\"Soma das matrizes:\")\n",
        "print(soma_matrizes)\n",
        "print(\"\\nMultiplicaÃ§Ã£o elemento a elemento:\")\n",
        "print(mult_elemento)\n",
        "print()\n",
        "\n",
        "# MULTIPLICAÃ‡ÃƒO DE MATRIZES (a verdadeira!)\n",
        "produto_matricial = np.dot(matriz_A, matriz_B)\n",
        "# Ou usando @\n",
        "produto_matricial_2 = matriz_A @ matriz_B\n",
        "\n",
        "print(\"Produto matricial (A Ã— B):\")\n",
        "print(produto_matricial)\n",
        "print(\"\\nUsando @:\")\n",
        "print(produto_matricial_2)\n",
        "\n",
        "# Verificando se sÃ£o iguais\n",
        "print(\"\\nSÃ£o iguais?\", np.array_equal(produto_matricial, produto_matricial_2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¨ Visualizando Matrizes\n\nUma imagem vale mais que mil palavras! Vamos visualizar nossas matrizes para entender melhor o que estÃ¡ acontecendo.\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/algebra-linear-para-ia-modulo-04_img_02.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criando uma matriz interessante para visualizar\n",
        "x = np.linspace(-2, 2, 50)\n",
        "y = np.linspace(-2, 2, 50)\n",
        "X, Y = np.meshgrid(x, y)\n",
        "Z = np.sin(X) * np.cos(Y)  # FunÃ§Ã£o matemÃ¡tica bonita!\n",
        "\n",
        "# Criando subplots\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "# Heatmap da matriz\n",
        "im1 = axes[0].imshow(Z, cmap='viridis', extent=[-2, 2, -2, 2])\n",
        "axes[0].set_title('Heatmap da Matriz')\n",
        "axes[0].set_xlabel('X')\n",
        "axes[0].set_ylabel('Y')\n",
        "plt.colorbar(im1, ax=axes[0])\n",
        "\n",
        "# GrÃ¡fico 3D (representaÃ§Ã£o de superfÃ­cie)\n",
        "im2 = axes[1].contour(X, Y, Z, levels=20)\n",
        "axes[1].set_title('Contorno da Matriz')\n",
        "axes[1].set_xlabel('X')\n",
        "axes[1].set_ylabel('Y')\n",
        "\n",
        "# Uma matriz simples\n",
        "matriz_simples = np.random.rand(10, 10)\n",
        "im3 = axes[2].imshow(matriz_simples, cmap='hot')\n",
        "axes[2].set_title('Matriz AleatÃ³ria 10x10')\n",
        "plt.colorbar(im3, ax=axes[2])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Liiiindo! Agora vocÃª pode VER as matrizes! ğŸ¨\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸš€ Broadcasting - A MÃ¡gica do NumPy\n\nBroadcasting Ã© o superpoder do NumPy! Ã‰ como ele consegue fazer operaÃ§Ãµes entre arrays de tamanhos diferentes. Ã‰ tipo aquele amigo que sempre se adapta a qualquer situaÃ§Ã£o! ğŸ˜„\n\n**Regras do Broadcasting:**\n1. Se os arrays tÃªm dimensÃµes diferentes, o menor Ã© \"esticado\"\n2. Se as dimensÃµes nÃ£o sÃ£o compatÃ­veis, dÃ¡ erro\n3. O resultado tem o tamanho do maior array\n\n```mermaid\ngraph LR\n    A[Array 3x3] -->|Broadcasting| C[Resultado 3x3]\n    B[Array 1x3] -->|Broadcasting| C\n    D[Escalar] -->|Broadcasting| A\n```\n\n**Dica do Pedro:** Broadcasting Ã© fundamental para eficiÃªncia em IA - evita loops desnecessÃ¡rios! ğŸƒâ€â™‚ï¸ğŸ’¨"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exemplos de Broadcasting\n",
        "\n",
        "# 1. Escalar com matriz\n",
        "matriz = np.array([[1, 2, 3],\n",
        "                   [4, 5, 6],\n",
        "                   [7, 8, 9]])\n",
        "\n",
        "escalar = 10\n",
        "resultado_escalar = matriz + escalar  # Soma 10 a cada elemento!\n",
        "\n",
        "print(\"Matriz original:\")\n",
        "print(matriz)\n",
        "print(\"\\nMatriz + 10 (broadcasting):\")\n",
        "print(resultado_escalar)\n",
        "print()\n",
        "\n",
        "# 2. Vetor com matriz\n",
        "vetor_linha = np.array([10, 20, 30])  # Shape: (3,)\n",
        "resultado_vetor = matriz + vetor_linha  # Soma o vetor a cada linha!\n",
        "\n",
        "print(\"Vetor:\", vetor_linha)\n",
        "print(\"\\nMatriz + Vetor (broadcasting):\")\n",
        "print(resultado_vetor)\n",
        "print()\n",
        "\n",
        "# 3. Exemplo mais complexo\n",
        "matriz_2d = np.ones((4, 3))\n",
        "vetor_coluna = np.array([[1], [2], [3], [4]])  # Shape: (4, 1)\n",
        "vetor_linha_2 = np.array([10, 20, 30])  # Shape: (3,)\n",
        "\n",
        "# Broadcasting mÃ¡gico!\n",
        "resultado_complexo = matriz_2d + vetor_coluna + vetor_linha_2\n",
        "\n",
        "print(\"Broadcasting complexo:\")\n",
        "print(\"Matriz 4x3 + Vetor coluna 4x1 + Vetor linha 1x3\")\n",
        "print(resultado_complexo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## âš¡ Performance - Por que NumPy Ã© TÃ£o RÃ¡pido?\n\nVamos fazer um teste prÃ¡tico! NumPy Ã© implementado em C e usa **operaÃ§Ãµes vetorizadas**. Ã‰ como comparar um carro de FÃ³rmula 1 com uma carroÃ§a!\n\n**Dica do Pedro:** Em IA, performance Ã© CRUCIAL. Uma operaÃ§Ã£o que demora 1 segundo pode demorar horas quando repetida milhÃµes de vezes! â±ï¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Teste de performance: Python puro vs NumPy\n",
        "\n",
        "# Criando dados grandes\n",
        "tamanho = 1000000  # 1 milhÃ£o de elementos\n",
        "lista_python_1 = list(range(tamanho))\n",
        "lista_python_2 = list(range(tamanho, 2*tamanho))\n",
        "\n",
        "array_numpy_1 = np.arange(tamanho)\n",
        "array_numpy_2 = np.arange(tamanho, 2*tamanho)\n",
        "\n",
        "print(f\"Testando com {tamanho:,} elementos\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Teste 1: Soma com Python puro\n",
        "inicio = time.time()\n",
        "resultado_python = [a + b for a, b in zip(lista_python_1, lista_python_2)]\n",
        "tempo_python = time.time() - inicio\n",
        "\n",
        "print(f\"Python puro: {tempo_python:.4f} segundos\")\n",
        "\n",
        "# Teste 2: Soma com NumPy\n",
        "inicio = time.time()\n",
        "resultado_numpy = array_numpy_1 + array_numpy_2\n",
        "tempo_numpy = time.time() - inicio\n",
        "\n",
        "print(f\"NumPy:       {tempo_numpy:.4f} segundos\")\n",
        "\n",
        "# Calculando o speedup\n",
        "speedup = tempo_python / tempo_numpy\n",
        "print(f\"\\nğŸš€ NumPy Ã© {speedup:.1f}x mais rÃ¡pido!\")\n",
        "\n",
        "# Verificando se os resultados sÃ£o iguais\n",
        "print(f\"\\nResultados iguais? {np.array_equal(resultado_python, resultado_numpy)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“Š GrÃ¡fico de Performance\n\nVamos visualizar como a performance varia com o tamanho dos dados:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Testando diferentes tamanhos\n",
        "tamanhos = [1000, 5000, 10000, 50000, 100000, 500000]\n",
        "tempos_python = []\n",
        "tempos_numpy = []\n",
        "\n",
        "for tam in tamanhos:\n",
        "    # Dados de teste\n",
        "    lista_1 = list(range(tam))\n",
        "    lista_2 = list(range(tam, 2*tam))\n",
        "    array_1 = np.arange(tam)\n",
        "    array_2 = np.arange(tam, 2*tam)\n",
        "    \n",
        "    # Teste Python\n",
        "    inicio = time.time()\n",
        "    _ = [a + b for a, b in zip(lista_1, lista_2)]\n",
        "    tempos_python.append(time.time() - inicio)\n",
        "    \n",
        "    # Teste NumPy\n",
        "    inicio = time.time()\n",
        "    _ = array_1 + array_2\n",
        "    tempos_numpy.append(time.time() - inicio)\n",
        "\n",
        "# Plotando os resultados\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(tamanhos, tempos_python, 'ro-', label='Python Puro', linewidth=2)\n",
        "plt.plot(tamanhos, tempos_numpy, 'bo-', label='NumPy', linewidth=2)\n",
        "plt.xlabel('Tamanho dos Arrays')\n",
        "plt.ylabel('Tempo (segundos)')\n",
        "plt.title('ComparaÃ§Ã£o de Performance')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "speedups = [p/n for p, n in zip(tempos_python, tempos_numpy)]\n",
        "plt.bar(range(len(tamanhos)), speedups, color='green', alpha=0.7)\n",
        "plt.xlabel('Tamanho dos Arrays')\n",
        "plt.ylabel('Speedup (vezes mais rÃ¡pido)')\n",
        "plt.title('AceleraÃ§Ã£o do NumPy')\n",
        "plt.xticks(range(len(tamanhos)), [f'{t//1000}k' for t in tamanhos])\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"NumPy nÃ£o Ã© brincadeira! Olha essa performance! ğŸš€\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¯ AplicaÃ§Ãµes PrÃ¡ticas para IA\n\nAgora vamos ver como essas operaÃ§Ãµes se conectam com InteligÃªncia Artificial! Lembra que estamos construindo a base para entender redes neurais?\n\n### Exemplo 1: Camada Linear de uma Rede Neural\n\nUma camada linear faz exatamente a multiplicaÃ§Ã£o que vimos no MÃ³dulo 3:\n\n$$\\vec{y} = W \\vec{x} + \\vec{b}$$\n\nOnde:\n- $W$ Ã© a matriz de pesos\n- $\\vec{x}$ Ã© o vetor de entrada\n- $\\vec{b}$ Ã© o vetor de bias\n- $\\vec{y}$ Ã© a saÃ­da\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/algebra-linear-para-ia-modulo-04_img_03.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simulando uma camada linear simples\n",
        "\n",
        "# ParÃ¢metros da camada\n",
        "entrada_dim = 4  # 4 features de entrada\n",
        "saida_dim = 3    # 3 neurÃ´nios na saÃ­da\n",
        "\n",
        "# Inicializando pesos aleatÃ³rios (como numa rede neural real!)\n",
        "np.random.seed(42)\n",
        "W = np.random.randn(saida_dim, entrada_dim) * 0.5  # Matriz de pesos\n",
        "b = np.random.randn(saida_dim) * 0.1               # Vetor de bias\n",
        "\n",
        "print(\"Matriz de pesos W (3x4):\")\n",
        "print(W)\n",
        "print(\"\\nVetor de bias b:\")\n",
        "print(b)\n",
        "print()\n",
        "\n",
        "# Entrada exemplo (poderia ser uma imagem processada, texto, etc.)\n",
        "x = np.array([1.0, 2.0, -0.5, 3.0])\n",
        "print(\"Entrada x:\", x)\n",
        "\n",
        "# OperaÃ§Ã£o da camada linear: y = Wx + b\n",
        "y = W @ x + b  # Aqui estÃ¡ a mÃ¡gica!\n",
        "\n",
        "print(\"\\nSaÃ­da y = Wx + b:\")\n",
        "print(y)\n",
        "\n",
        "# Em redes neurais, geralmente aplicamos uma funÃ§Ã£o de ativaÃ§Ã£o\n",
        "# Exemplo: ReLU (Rectified Linear Unit)\n",
        "y_relu = np.maximum(0, y)  # ReLU: max(0, x)\n",
        "print(\"\\nApÃ³s ReLU:\")\n",
        "print(y_relu)\n",
        "\n",
        "print(\"\\nğŸ§  ParabÃ©ns! VocÃª acabou de implementar uma camada neural!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exemplo 2: Calculando Similaridades (Base para Sistemas de RecomendaÃ§Ã£o)\n\nVamos usar o produto escalar do MÃ³dulo 2 para calcular similaridades entre usuÃ¡rios:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sistema de recomendaÃ§Ã£o simples usando similaridade por cosseno\n",
        "\n",
        "# Matriz de preferÃªncias: cada linha Ã© um usuÃ¡rio, cada coluna Ã© um filme\n",
        "# Valores de 1-5 (nota que o usuÃ¡rio daria)\n",
        "preferencias = np.array([\n",
        "    [5, 3, 0, 1, 4],  # UsuÃ¡rio 1\n",
        "    [3, 1, 0, 2, 3],  # UsuÃ¡rio 2  \n",
        "    [4, 3, 0, 1, 5],  # UsuÃ¡rio 3\n",
        "    [3, 3, 0, 5, 4],  # UsuÃ¡rio 4\n",
        "    [0, 0, 0, 2, 0],  # UsuÃ¡rio 5\n",
        "])\n",
        "\n",
        "filmes = ['Vingadores', 'Romance', 'Terror', 'ComÃ©dia', 'FicÃ§Ã£o']\n",
        "usuarios = ['Ana', 'Bruno', 'Carlos', 'Diana', 'Eduardo']\n",
        "\n",
        "print(\"Matriz de PreferÃªncias:\")\n",
        "print(\"UsuÃ¡rios x Filmes\")\n",
        "print(preferencias)\n",
        "print()\n",
        "\n",
        "# Calculando similaridade entre todos os usuÃ¡rios\n",
        "def similaridade_cosseno(u1, u2):\n",
        "    \"\"\"Calcula similaridade por cosseno entre dois vetores\"\"\"\n",
        "    dot_product = np.dot(u1, u2)\n",
        "    norma_u1 = np.linalg.norm(u1)\n",
        "    norma_u2 = np.linalg.norm(u2)\n",
        "    \n",
        "    if norma_u1 == 0 or norma_u2 == 0:\n",
        "        return 0\n",
        "    \n",
        "    return dot_product / (norma_u1 * norma_u2)\n",
        "\n",
        "# Matriz de similaridades\n",
        "n_usuarios = len(usuarios)\n",
        "matriz_similaridade = np.zeros((n_usuarios, n_usuarios))\n",
        "\n",
        "for i in range(n_usuarios):\n",
        "    for j in range(n_usuarios):\n",
        "        matriz_similaridade[i, j] = similaridade_cosseno(preferencias[i], preferencias[j])\n",
        "\n",
        "print(\"Matriz de Similaridade:\")\n",
        "print(matriz_similaridade.round(3))\n",
        "print()\n",
        "\n",
        "# Encontrando usuÃ¡rios mais similares Ã  Ana (usuÃ¡rio 0)\n",
        "ana_similaridades = matriz_similaridade[0, 1:]  # Excluindo ela mesma\n",
        "usuario_mais_similar = np.argmax(ana_similaridades) + 1  # +1 porque pulamos Ana\n",
        "\n",
        "print(f\"UsuÃ¡rio mais similar Ã  Ana: {usuarios[usuario_mais_similar]}\")\n",
        "print(f\"Similaridade: {ana_similaridades[usuario_mais_similar-1]:.3f}\")\n",
        "\n",
        "print(\"\\nğŸ¬ Sistema de recomendaÃ§Ã£o bÃ¡sico funcionando!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ‹ï¸ ExercÃ­cio PrÃ¡tico 1: Construindo uma Mini Rede Neural\n\nAgora Ã© sua vez! Vamos construir uma rede neural simples para classificar se um nÃºmero Ã© positivo ou negativo.\n\n**Sua missÃ£o:**\n1. Criar dados de treino\n2. Implementar forward pass\n3. Calcular a acurÃ¡cia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# EXERCÃCIO 1: Complete o cÃ³digo abaixo\n",
        "\n",
        "# 1. Criar dados de treino\n",
        "np.random.seed(42)\n",
        "X = np.random.randn(100, 1)  # 100 amostras, 1 feature\n",
        "y = (X > 0).astype(int).flatten()  # 1 se positivo, 0 se negativo\n",
        "\n",
        "print(\"Primeiros 10 exemplos:\")\n",
        "for i in range(10):\n",
        "    print(f\"X[{i}] = {X[i,0]:.3f} -> y[{i}] = {y[i]}\")\n",
        "print()\n",
        "\n",
        "# 2. ParÃ¢metros da rede neural\n",
        "# TODO: Complete os parÃ¢metros\n",
        "W1 = np.random.randn(5, 1) * 0.5   # Primeira camada: 1 -> 5 neurÃ´nios\n",
        "b1 = np.zeros(5)                   # Bias primeira camada\n",
        "W2 = np.random.randn(1, 5) * 0.5   # Segunda camada: 5 -> 1 neurÃ´nio\n",
        "b2 = np.zeros(1)                   # Bias segunda camada\n",
        "\n",
        "def sigmoid(x):\n",
        "    \"\"\"FunÃ§Ã£o sigmoide\"\"\"\n",
        "    return 1 / (1 + np.exp(-np.clip(x, -500, 500)))  # Clip para evitar overflow\n",
        "\n",
        "def forward_pass(X):\n",
        "    \"\"\"Forward pass da rede neural\"\"\"\n",
        "    # TODO: Implemente o forward pass\n",
        "    # Dica: z1 = X @ W1.T + b1, a1 = relu(z1), z2 = a1 @ W2.T + b2, a2 = sigmoid(z2)\n",
        "    \n",
        "    z1 = X @ W1.T + b1                    # Primeira camada linear\n",
        "    a1 = np.maximum(0, z1)               # ReLU\n",
        "    z2 = a1 @ W2.T + b2                  # Segunda camada linear  \n",
        "    a2 = sigmoid(z2)                     # Sigmoide (probabilidade)\n",
        "    \n",
        "    return a2\n",
        "\n",
        "# 3. Fazer prediÃ§Ãµes\n",
        "predictions = forward_pass(X)\n",
        "predicted_classes = (predictions > 0.5).astype(int).flatten()\n",
        "\n",
        "# 4. Calcular acurÃ¡cia\n",
        "accuracy = np.mean(predicted_classes == y)\n",
        "print(f\"AcurÃ¡cia: {accuracy:.2%}\")\n",
        "\n",
        "# Mostrar alguns resultados\n",
        "print(\"\\nPrimeiras 10 prediÃ§Ãµes:\")\n",
        "for i in range(10):\n",
        "    prob = predictions[i, 0]\n",
        "    pred = predicted_classes[i]\n",
        "    real = y[i]\n",
        "    status = \"âœ“\" if pred == real else \"âœ—\"\n",
        "    print(f\"X={X[i,0]:6.3f} | Prob={prob:.3f} | Pred={pred} | Real={real} {status}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ² ExercÃ­cio PrÃ¡tico 2: AnÃ¡lise de Componentes Principais (PreparaÃ§Ã£o para MÃ³dulo 10)\n\nVamos ter um gostinho do que vem no MÃ³dulo 10! Use NumPy para fazer uma anÃ¡lise simples de dados.\n\n**Sua missÃ£o:**\n1. Gerar dados 2D correlacionados\n2. Calcular matriz de covariÃ¢ncia\n3. Visualizar os dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# EXERCÃCIO 2: AnÃ¡lise exploratÃ³ria com NumPy\n",
        "\n",
        "# 1. Gerar dados correlacionados\n",
        "np.random.seed(42)\n",
        "n_samples = 200\n",
        "\n",
        "# TODO: Complete o cÃ³digo para gerar dados correlacionados\n",
        "# Dica: Use uma transformaÃ§Ã£o linear para criar correlaÃ§Ã£o\n",
        "\n",
        "# Dados base (nÃ£o correlacionados)\n",
        "data_base = np.random.randn(n_samples, 2)\n",
        "\n",
        "# Matriz de transformaÃ§Ã£o para criar correlaÃ§Ã£o\n",
        "transform_matrix = np.array([[2, 1.5],\n",
        "                            [0.5, 1]])\n",
        "\n",
        "# Aplicar transformaÃ§Ã£o\n",
        "data_transformed = data_base @ transform_matrix.T\n",
        "\n",
        "print(\"Forma dos dados:\", data_transformed.shape)\n",
        "print(\"Primeiras 5 amostras:\")\n",
        "print(data_transformed[:5])\n",
        "print()\n",
        "\n",
        "# 2. Calcular estatÃ­sticas\n",
        "# TODO: Calcule mÃ©dia, desvio padrÃ£o e matriz de covariÃ¢ncia\n",
        "\n",
        "media = np.mean(data_transformed, axis=0)\n",
        "desvio = np.std(data_transformed, axis=0)\n",
        "cov_matrix = np.cov(data_transformed.T)\n",
        "\n",
        "print(\"MÃ©dia:\", media)\n",
        "print(\"Desvio padrÃ£o:\", desvio)\n",
        "print(\"\\nMatriz de CovariÃ¢ncia:\")\n",
        "print(cov_matrix)\n",
        "print(f\"\\nCorrelaÃ§Ã£o entre X e Y: {cov_matrix[0,1] / (desvio[0] * desvio[1]):.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. Visualizar os dados\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "# Dados originais\n",
        "axes[0].scatter(data_base[:, 0], data_base[:, 1], alpha=0.6, c='blue')\n",
        "axes[0].set_title('Dados Originais (NÃ£o Correlacionados)')\n",
        "axes[0].set_xlabel('X')\n",
        "axes[0].set_ylabel('Y')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "axes[0].axis('equal')\n",
        "\n",
        "# Dados transformados\n",
        "axes[1].scatter(data_transformed[:, 0], data_transformed[:, 1], alpha=0.6, c='red')\n",
        "axes[1].set_title('Dados Transformados (Correlacionados)')\n",
        "axes[1].set_xlabel('X')\n",
        "axes[1].set_ylabel('Y')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "# Matriz de covariÃ¢ncia como heatmap\n",
        "im = axes[2].imshow(cov_matrix, cmap='RdBu', center=0)\n",
        "axes[2].set_title('Matriz de CovariÃ¢ncia')\n",
        "axes[2].set_xticks([0, 1])\n",
        "axes[2].set_yticks([0, 1])\n",
        "axes[2].set_xticklabels(['X', 'Y'])\n",
        "axes[2].set_yticklabels(['X', 'Y'])\n",
        "\n",
        "# Adicionando valores na matriz\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        axes[2].text(j, i, f'{cov_matrix[i,j]:.2f}', \n",
        "                    ha='center', va='center', fontsize=12, color='white')\n",
        "\n",
        "plt.colorbar(im, ax=axes[2])\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"ğŸ¯ Ã“timo trabalho! VocÃª acabou de fazer uma anÃ¡lise exploratÃ³ria completa!\")\n",
        "print(\"No MÃ³dulo 10, vamos aprofundar isso com PCA e autovetores! ğŸš€\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ”§ FunÃ§Ãµes Ãšteis do NumPy para IA\n\nAntes de terminar, vamos ver algumas funÃ§Ãµes que vocÃª VAI usar muito em projetos de IA:\n\n**Dica do Pedro:** Salve esta cÃ©lula como referÃªncia! SÃ£o as funÃ§Ãµes que mais uso no dia a dia! ğŸ“Œ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cheat Sheet: FunÃ§Ãµes essenciais do NumPy para IA\n",
        "\n",
        "print(\"ğŸ¯ CHEAT SHEET NUMPY PARA IA\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "# 1. CriaÃ§Ã£o de arrays\n",
        "print(\"\\n1. CRIAÃ‡ÃƒO:\")\n",
        "print(\"np.zeros((3,3))     - Matriz de zeros\")\n",
        "print(\"np.ones((3,3))      - Matriz de uns\")\n",
        "print(\"np.eye(3)           - Matriz identidade\")\n",
        "print(\"np.random.randn(3,3) - NÃºmeros aleatÃ³rios (normal)\")\n",
        "print(\"np.arange(10)       - SequÃªncia [0,1,2...9]\")\n",
        "print(\"np.linspace(0,1,5)  - 5 pontos entre 0 e 1\")\n",
        "\n",
        "# 2. OperaÃ§Ãµes matemÃ¡ticas\n",
        "print(\"\\n2. OPERAÃ‡Ã•ES:\")\n",
        "print(\"a @ b               - MultiplicaÃ§Ã£o de matrizes\")\n",
        "print(\"np.dot(a, b)        - Produto escalar/matricial\")\n",
        "print(\"np.linalg.norm(a)   - Norma do vetor\")\n",
        "print(\"np.sum(a, axis=0)   - Soma por colunas\")\n",
        "print(\"np.mean(a, axis=1)  - MÃ©dia por linhas\")\n",
        "print(\"np.max(a), np.min(a) - MÃ¡ximo e mÃ­nimo\")\n",
        "\n",
        "# 3. ManipulaÃ§Ã£o de forma\n",
        "print(\"\\n3. MANIPULAÃ‡ÃƒO:\")\n",
        "print(\"a.reshape(2, 3)     - Mudar formato\")\n",
        "print(\"a.T                 - Transposta\")\n",
        "print(\"a.flatten()         - Achatar array\")\n",
        "print(\"np.concatenate()    - Juntar arrays\")\n",
        "print(\"np.split()          - Dividir arrays\")\n",
        "\n",
        "# 4. FunÃ§Ãµes para IA\n",
        "print(\"\\n4. ESPECÃFICAS PARA IA:\")\n",
        "print(\"np.argmax(a)        - Ãndice do maior elemento\")\n",
        "print(\"np.where(condition) - Ãndices onde condiÃ§Ã£o Ã© True\")\n",
        "print(\"np.clip(a, min, max) - Limitar valores\")\n",
        "print(\"np.exp(a)           - Exponencial (softmax, sigmoid)\")\n",
        "print(\"np.log(a)           - Logaritmo (loss functions)\")\n",
        "\n",
        "# Exemplos prÃ¡ticos\n",
        "print(\"\\n\\nğŸ”¥ EXEMPLOS PRÃTICOS:\")\n",
        "print(\"=\"*30)\n",
        "\n",
        "# Softmax (muito usado em classificaÃ§Ã£o!)\n",
        "logits = np.array([2.0, 1.0, 0.1])\n",
        "exp_logits = np.exp(logits)\n",
        "softmax = exp_logits / np.sum(exp_logits)\n",
        "print(f\"Softmax: {logits} -> {softmax.round(3)}\")\n",
        "\n",
        "# One-hot encoding\n",
        "classes = np.array([0, 1, 2, 1, 0])\n",
        "n_classes = 3\n",
        "one_hot = np.eye(n_classes)[classes]\n",
        "print(f\"\\nOne-hot: {classes}\")\n",
        "print(one_hot)\n",
        "\n",
        "# NormalizaÃ§Ã£o (muito importante!)\n",
        "data = np.random.randn(5, 3)\n",
        "normalized = (data - np.mean(data, axis=0)) / np.std(data, axis=0)\n",
        "print(f\"\\nNormalizaÃ§Ã£o - antes mÃ©dia: {np.mean(data, axis=0).round(3)}\")\n",
        "print(f\"Depois mÃ©dia: {np.mean(normalized, axis=0).round(3)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¯ Resumo e PrÃ³ximos Passos\n\nParabÃ©ns! ğŸ‰ VocÃª acabou de dominar o NumPy - a base de TUDO em IA com Python!\n\n### O que vocÃª aprendeu:\n\nâœ… **CriaÃ§Ã£o eficiente** de vetores e matrizes  \nâœ… **OperaÃ§Ãµes matemÃ¡ticas** otimizadas (produtos escalar e matricial)  \nâœ… **Broadcasting** - a mÃ¡gica do NumPy  \nâœ… **Performance** - Por que NumPy Ã© essencial  \nâœ… **AplicaÃ§Ãµes prÃ¡ticas** em IA (redes neurais, sistemas de recomendaÃ§Ã£o)  \n\n### ConexÃµes com outros mÃ³dulos:\n\n```mermaid\ngraph TD\n    A[MÃ³dulo 1-3: Teoria] --> B[MÃ³dulo 4: NumPy - ATUAL]\n    B --> C[MÃ³dulo 5: Sistemas Lineares]\n    B --> D[MÃ³dulo 6: TransformaÃ§Ãµes]\n    B --> E[MÃ³dulo 7: Inversa/Transposta]\n    B --> F[MÃ³dulo 8: Determinante]\n    B --> G[MÃ³dulo 9: SVD]\n    B --> H[MÃ³dulo 10: PCA/Autovetores]\n```\n\n### PrÃ³ximo mÃ³dulo:\n**MÃ³dulo 5: Sistemas de EquaÃ§Ãµes Lineares** - Vamos resolver problemas reais usando as ferramentas que vocÃª acabou de aprender!\n\n**Dica do Pedro Final:** Pratique! Crie seus prÃ³prios arrays, experimente com diferentes operaÃ§Ãµes. NumPy Ã© como andar de bicicleta - quanto mais vocÃª pratica, mais natural fica! ğŸš´â€â™‚ï¸\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/algebra-linear-para-ia-modulo-04_img_04.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n\n## ğŸ“š Recursos Extras\n\n**Para se aprofundar:**\n- DocumentaÃ§Ã£o oficial do NumPy\n- NumPy User Guide\n- Curso \"Ãlgebra Linear para IA\" - MÃ³dulos seguintes\n\n**AtÃ© o prÃ³ximo mÃ³dulo!** ğŸš€\n\n*Pedro Nunes Guth - Expert em IA e MatemÃ¡tica*"
      ]
    }
  ]
}