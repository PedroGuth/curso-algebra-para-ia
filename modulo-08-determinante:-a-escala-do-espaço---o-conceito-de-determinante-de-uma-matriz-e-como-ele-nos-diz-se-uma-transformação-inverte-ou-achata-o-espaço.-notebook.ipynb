{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üéØ Determinante: A Escala do Espa√ßo\n## Como uma matriz pode esticar, encolher ou virar o mundo de cabe√ßa pra baixo!\n\n**Pedro Nunes Guth - √Ålgebra Linear para IA - M√≥dulo 8**\n\n---\n\nFala, pessoal! Bora descobrir um dos conceitos mais **lindos** da √°lgebra linear: o **determinante**! üöÄ\n\nImagina que voc√™ tem uma caixa de sapato e aplica uma transforma√ß√£o nela. O determinante te diz:\n- Se a caixa ficou maior ou menor\n- Se ela virou do avesso\n- Se ela foi completamente achatada\n\nT√°, mas por que isso importa pra IA? Porque toda vez que seus dados passam por uma camada de rede neural, eles est√£o sendo transformados no espa√ßo. E o determinante nos conta a **hist√≥ria** dessa transforma√ß√£o!\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/algebra-linear-para-ia-modulo-08_img_01.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup inicial - Importando nossas ferramentas\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Polygon\n",
        "import seaborn as sns\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configura√ß√µes visuais\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "plt.rcParams['figure.figsize'] = (10, 8)\n",
        "plt.rcParams['font.size'] = 12\n",
        "\n",
        "print(\"üîß Ferramentas carregadas! Bora descobrir o determinante!\")\n",
        "print(f\"üì¶ NumPy vers√£o: {np.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ü§î T√°, mas o que √© o Determinante?\n\nO **determinante** √© um n√∫mero que resume o **efeito** de uma transforma√ß√£o linear no espa√ßo. Pensa assim:\n\nüè† **Analogia da Casa**: Imagina que sua matriz √© como um **filtro m√°gico** que voc√™ aplica na sua casa:\n- Se o determinante √© **2**, sua casa fica **2x maior** em √°rea/volume\n- Se √© **0.5**, ela fica com **metade** do tamanho\n- Se √© **0**, ela vira uma **linha** ou **ponto** (achatou!)\n- Se √© **negativo**, ela vira **do avesso** (como uma meia!)\n\n### A Matem√°tica por Tr√°s\n\nPara uma matriz 2x2, o determinante √© calculado assim:\n\n$$\\det\\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix} = ad - bc$$\n\nPara uma matriz 3x3:\n\n$$\\det\\begin{pmatrix} a & b & c \\\\ d & e & f \\\\ g & h & i \\end{pmatrix} = a(ei - fh) - b(di - fg) + c(dh - eg)$$\n\n**Dica do Pedro**: Memoriza a f√≥rmula 2x2! √â super √∫til e aparece direto em problemas de IA! üí°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos criar algumas matrizes e calcular seus determinantes\n",
        "def mostrar_determinante(matriz, nome):\n",
        "    \"\"\"Fun√ß√£o para mostrar matriz e seu determinante de forma organizada\"\"\"\n",
        "    det = np.linalg.det(matriz)\n",
        "    print(f\"\\nüéØ {nome}:\")\n",
        "    print(f\"Matriz:\\n{matriz}\")\n",
        "    print(f\"Determinante: {det:.3f}\")\n",
        "    \n",
        "    # Interpretando o resultado\n",
        "    if abs(det) < 1e-10:\n",
        "        print(\"üìè Resultado: ACHATOU! A transforma√ß√£o destr√≥i dimens√µes\")\n",
        "    elif det > 1:\n",
        "        print(f\"üìà Resultado: AUMENTOU {det:.2f}x o tamanho\")\n",
        "    elif det > 0:\n",
        "        print(f\"üìâ Resultado: DIMINUIU para {det:.2f} do tamanho original\")\n",
        "    else:\n",
        "        print(f\"üîÑ Resultado: INVERTEU e mudou para {abs(det):.2f}x o tamanho\")\n",
        "    \n",
        "    return det\n",
        "\n",
        "# Exemplos pr√°ticos\n",
        "print(\"üîç Vamos analisar diferentes tipos de matrizes:\\n\")\n",
        "\n",
        "# Matriz identidade (n√£o muda nada)\n",
        "identidade = np.array([[1, 0], [0, 1]])\n",
        "mostrar_determinante(identidade, \"Matriz Identidade\")\n",
        "\n",
        "# Matriz que dobra o tamanho\n",
        "dobra = np.array([[2, 0], [0, 1]])\n",
        "mostrar_determinante(dobra, \"Dobra na horizontal\")\n",
        "\n",
        "# Matriz que achata (determinante 0)\n",
        "achata = np.array([[1, 1], [2, 2]])\n",
        "mostrar_determinante(achata, \"Matriz que achata\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìê Visualizando Transforma√ß√µes: O Show das Formas\n\nLembra das **transforma√ß√µes lineares** do M√≥dulo 6? Agora vamos ver como o determinante se relaciona com elas!\n\nVamos pegar um **quadrado unit√°rio** (nosso protagonista) e aplicar diferentes transforma√ß√µes. O determinante nos diz exatamente como a **√°rea** desse quadrado muda!\n\n```mermaid\ngraph LR\n    A[Quadrado Original] --> B[Aplicar Matriz]\n    B --> C[Forma Transformada]\n    C --> D[Determinante = Nova √Årea]\n    \n    style A fill:#e1f5fe\n    style B fill:#fff3e0\n    style C fill:#f3e5f5\n    style D fill:#e8f5e8\n```\n\n**Dica do Pedro**: O determinante √© como um **medidor de impacto** da transforma√ß√£o! Negativo = virou, Zero = achatou, Maior que 1 = cresceu! üéØ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualizar_transformacao(matriz, titulo):\n",
        "    \"\"\"Visualiza como uma matriz transforma um quadrado unit√°rio\"\"\"\n",
        "    \n",
        "    # Definindo o quadrado unit√°rio (4 pontos)\n",
        "    quadrado_original = np.array([[0, 1, 1, 0, 0],  # x coordinates\n",
        "                                  [0, 0, 1, 1, 0]])  # y coordinates\n",
        "    \n",
        "    # Aplicando a transforma√ß√£o\n",
        "    quadrado_transformado = matriz @ quadrado_original\n",
        "    \n",
        "    # Calculando o determinante\n",
        "    det = np.linalg.det(matriz)\n",
        "    \n",
        "    # Criando o gr√°fico\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "    \n",
        "    # Quadrado original\n",
        "    ax1.plot(quadrado_original[0], quadrado_original[1], 'b-', linewidth=3, label='Original')\n",
        "    ax1.fill(quadrado_original[0], quadrado_original[1], alpha=0.3, color='blue')\n",
        "    ax1.set_title('üü¶ Quadrado Original\\n(√Årea = 1)', fontsize=14)\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    ax1.set_xlim(-3, 3)\n",
        "    ax1.set_ylim(-3, 3)\n",
        "    ax1.set_aspect('equal')\n",
        "    \n",
        "    # Forma transformada\n",
        "    ax2.plot(quadrado_transformado[0], quadrado_transformado[1], 'r-', linewidth=3, label='Transformado')\n",
        "    ax2.fill(quadrado_transformado[0], quadrado_transformado[1], alpha=0.3, color='red')\n",
        "    ax2.set_title(f'üîÑ Ap√≥s Transforma√ß√£o\\n(√Årea = |det| = {abs(det):.2f})', fontsize=14)\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "    ax2.set_xlim(-3, 3)\n",
        "    ax2.set_ylim(-3, 3)\n",
        "    ax2.set_aspect('equal')\n",
        "    \n",
        "    plt.suptitle(f'{titulo}\\nDeterminante = {det:.3f}', fontsize=16, y=1.02)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    return det\n",
        "\n",
        "# Vamos ver diferentes transforma√ß√µes em a√ß√£o!\n",
        "print(\"üé≠ Show das Transforma√ß√µes!\\n\")\n",
        "\n",
        "# Transforma√ß√£o que estica horizontalmente\n",
        "estica_x = np.array([[3, 0], [0, 1]])\n",
        "visualizar_transformacao(estica_x, \"Esticando 3x na horizontal\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Rota√ß√£o com mudan√ßa de escala\n",
        "theta = np.pi/4  # 45 graus\n",
        "escala = 2\n",
        "rotacao_escala = escala * np.array([[np.cos(theta), -np.sin(theta)], \n",
        "                                    [np.sin(theta), np.cos(theta)]])\n",
        "visualizar_transformacao(rotacao_escala, \"Rota√ß√£o 45¬∞ + Escala 2x\")\n",
        "\n",
        "# Cisalhamento (shear)\n",
        "cisalha = np.array([[1, 1], [0, 1]])\n",
        "visualizar_transformacao(cisalha, \"Cisalhamento horizontal\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîç O Determinante Zero: Quando Tudo Vira P√≥\n\nAgora vem a parte **mais importante**: quando o determinante √© **zero**! üò±\n\nüß† **Pensa assim**: Imagina que voc√™ tem uma **foto 3D** e aplica uma transforma√ß√£o que a transforma numa **foto 2D**. Perdeu uma dimens√£o, n√©? Isso √© exatamente o que acontece quando o determinante √© zero!\n\n### Por que isso √© importante para IA?\n\n- **Redes Neurais**: Se uma camada tem determinante zero, ela est√° \"perdendo informa√ß√£o\"\n- **Sistemas de Equa√ß√µes**: Determinante zero = sistema sem solu√ß√£o √∫nica (lembra do M√≥dulo 5?)\n- **Inversibilidade**: Se det = 0, a matriz **n√£o tem inversa** (conex√£o com M√≥dulo 7!)\n\nA f√≥rmula matem√°tica que conecta tudo:\n\n$$\\text{Se } \\det(A) = 0 \\Rightarrow A \\text{ n√£o √© invers√≠vel}$$\n\n$$\\text{Se } \\det(A) \\neq 0 \\Rightarrow A^{-1} \\text{ existe}$$\n\n**Dica do Pedro**: Determinante zero √© como um **sinal vermelho** na √°lgebra linear! Significa que algo importante foi perdido no caminho! üö®"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos ver o que acontece quando o determinante √© zero\n",
        "def analisar_determinante_zero():\n",
        "    \"\"\"An√°lise detalhada de matrizes com determinante zero\"\"\"\n",
        "    \n",
        "    print(\"üö® ALERTA: Investigando Determinantes Zero!\\n\")\n",
        "    \n",
        "    # Matriz com determinante zero (linhas proporcionais)\n",
        "    matriz_zero = np.array([[2, 4], [1, 2]])\n",
        "    \n",
        "    print(\"üìä Caso 1: Linhas Proporcionais\")\n",
        "    print(f\"Matriz:\\n{matriz_zero}\")\n",
        "    print(f\"Linha 1: {matriz_zero[0]}\")\n",
        "    print(f\"Linha 2: {matriz_zero[1]} (= 0.5 √ó Linha 1)\")\n",
        "    print(f\"Determinante: {np.linalg.det(matriz_zero):.10f}\")\n",
        "    \n",
        "    # Tentando calcular a inversa\n",
        "    try:\n",
        "        inversa = np.linalg.inv(matriz_zero)\n",
        "        print(\"‚úÖ Inversa calculada\")\n",
        "    except np.linalg.LinAlgError:\n",
        "        print(\"‚ùå ERRO: Matriz n√£o invers√≠vel (determinante zero!)\")\n",
        "    \n",
        "    # Visualizando o achatamento\n",
        "    print(\"\\nüéØ Vamos ver o achatamento visualmente:\")\n",
        "    visualizar_transformacao(matriz_zero, \"Transforma√ß√£o que Achata (det=0)\")\n",
        "    \n",
        "    return matriz_zero\n",
        "\n",
        "matriz_problema = analisar_determinante_zero()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîÑ Determinante Negativo: O Mundo Virado\n\nQuando o determinante √© **negativo**, algo muito interessante acontece: a transforma√ß√£o **inverte** a orienta√ß√£o do espa√ßo!\n\nü™û **Analogia do Espelho**: √â como se voc√™ olhasse no espelho - tudo fica \"do lado contr√°rio\". Na matem√°tica, chamamos isso de **invers√£o de orienta√ß√£o**.\n\n### O que isso significa na pr√°tica?\n\n- **Reflex√µes**: Espelhar uma imagem\n- **Invers√µes**: Virar um gr√°fico de cabe√ßa pra baixo\n- **Coordenadas**: Sistema destro vira canhoto (ou vice-versa)\n\nA matem√°tica por tr√°s:\n\n$$\\det(A) < 0 \\Rightarrow \\text{Transforma√ß√£o inverte orienta√ß√£o}$$\n$$|\\det(A)| = \\text{Fator de escala da √°rea/volume}$$\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/algebra-linear-para-ia-modulo-08_img_02.png)\n\n**Dica do Pedro**: O **sinal** do determinante te diz sobre orienta√ß√£o, o **valor absoluto** te diz sobre escala! S√£o duas informa√ß√µes em um n√∫mero s√≥! ü§Ø"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Explorando determinantes negativos\n",
        "def explorar_determinante_negativo():\n",
        "    \"\"\"An√°lise de transforma√ß√µes que invertem orienta√ß√£o\"\"\"\n",
        "    \n",
        "    print(\"üîÑ Explorando Determinantes Negativos\\n\")\n",
        "    \n",
        "    # Reflex√£o no eixo y\n",
        "    reflexao_y = np.array([[-1, 0], [0, 1]])\n",
        "    det_ref = visualizar_transformacao(reflexao_y, \"Reflex√£o no eixo Y\")\n",
        "    \n",
        "    print(f\"\\nüìä An√°lise da Reflex√£o:\")\n",
        "    print(f\"Determinante: {det_ref}\")\n",
        "    print(f\"√Årea: |{det_ref}| = {abs(det_ref)} (mant√©m o tamanho)\")\n",
        "    print(f\"Orienta√ß√£o: {'Invertida' if det_ref < 0 else 'Mantida'}\")\n",
        "    \n",
        "    return reflexao_y\n",
        "\n",
        "# Fun√ß√£o para mostrar a orienta√ß√£o com vetores\n",
        "def mostrar_orientacao(matriz, titulo):\n",
        "    \"\"\"Mostra como os vetores base s√£o transformados\"\"\"\n",
        "    \n",
        "    # Vetores base originais\n",
        "    e1 = np.array([1, 0])\n",
        "    e2 = np.array([0, 1])\n",
        "    \n",
        "    # Vetores transformados\n",
        "    e1_trans = matriz @ e1\n",
        "    e2_trans = matriz @ e2\n",
        "    \n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "    \n",
        "    # Vetores originais\n",
        "    ax1.arrow(0, 0, e1[0], e1[1], head_width=0.1, head_length=0.1, fc='red', ec='red', label='e1')\n",
        "    ax1.arrow(0, 0, e2[0], e2[1], head_width=0.1, head_length=0.1, fc='blue', ec='blue', label='e2')\n",
        "    ax1.set_title('Vetores Base Originais', fontsize=14)\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    ax1.set_xlim(-2, 2)\n",
        "    ax1.set_ylim(-2, 2)\n",
        "    ax1.legend()\n",
        "    ax1.set_aspect('equal')\n",
        "    \n",
        "    # Vetores transformados\n",
        "    ax2.arrow(0, 0, e1_trans[0], e1_trans[1], head_width=0.1, head_length=0.1, fc='red', ec='red', label='T(e1)')\n",
        "    ax2.arrow(0, 0, e2_trans[0], e2_trans[1], head_width=0.1, head_length=0.1, fc='blue', ec='blue', label='T(e2)')\n",
        "    ax2.set_title(f'Ap√≥s Transforma√ß√£o\\ndet = {np.linalg.det(matriz):.2f}', fontsize=14)\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "    ax2.set_xlim(-2, 2)\n",
        "    ax2.set_ylim(-2, 2)\n",
        "    ax2.legend()\n",
        "    ax2.set_aspect('equal')\n",
        "    \n",
        "    plt.suptitle(titulo, fontsize=16)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "reflexao = explorar_determinante_negativo()\n",
        "mostrar_orientacao(reflexao, \"Como a Reflex√£o Afeta os Vetores Base\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üßÆ Calculando Determinantes: Do 2x2 ao NxN\n\nAgora vamos ver como calcular determinantes de diferentes tamanhos. Spoiler: conforme a matriz cresce, a coisa complica! üòÖ\n\n### Matriz 2x2 (Moleza!)\n$$\\det\\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix} = ad - bc$$\n\n### Matriz 3x3 (Regra de Sarrus)\nAqui j√° precisamos de mais **malandragem**. Usamos expans√£o por cofatores:\n\n$$\\det(A) = \\sum_{j=1}^{n} (-1)^{i+j} a_{ij} M_{ij}$$\n\nOnde $M_{ij}$ √© o menor (determinante da matriz sem linha i e coluna j).\n\n### Matrizes Maiores\nPara matrizes grandes, usamos **algoritmos espertos** como:\n- **Decomposi√ß√£o LU**\n- **Elimina√ß√£o Gaussiana**\n- **M√©todos recursivos**\n\n**Dica do Pedro**: Na pr√°tica, deixa o NumPy fazer o trabalho pesado! Mas entender a teoria te faz um cientista de dados mais esperto! ü§ì"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Implementando c√°lculo de determinante do zero (educativo!)\n",
        "def det_2x2_manual(matriz):\n",
        "    \"\"\"Calcula determinante 2x2 manualmente\"\"\"\n",
        "    if matriz.shape != (2, 2):\n",
        "        raise ValueError(\"Matriz deve ser 2x2\")\n",
        "    \n",
        "    a, b = matriz[0, 0], matriz[0, 1]\n",
        "    c, d = matriz[1, 0], matriz[1, 1]\n",
        "    \n",
        "    det = a * d - b * c\n",
        "    \n",
        "    print(f\"üìê C√°lculo Manual 2x2:\")\n",
        "    print(f\"Matriz: [[{a}, {b}], [{c}, {d}]]\")\n",
        "    print(f\"det = ({a} √ó {d}) - ({b} √ó {c})\")\n",
        "    print(f\"det = {a*d} - {b*c} = {det}\")\n",
        "    \n",
        "    return det\n",
        "\n",
        "def det_3x3_manual(matriz):\n",
        "    \"\"\"Calcula determinante 3x3 por expans√£o de cofatores\"\"\"\n",
        "    if matriz.shape != (3, 3):\n",
        "        raise ValueError(\"Matriz deve ser 3x3\")\n",
        "    \n",
        "    # Expans√£o pela primeira linha\n",
        "    a = matriz[0, 0] * (matriz[1, 1] * matriz[2, 2] - matriz[1, 2] * matriz[2, 1])\n",
        "    b = matriz[0, 1] * (matriz[1, 0] * matriz[2, 2] - matriz[1, 2] * matriz[2, 0])\n",
        "    c = matriz[0, 2] * (matriz[1, 0] * matriz[2, 1] - matriz[1, 1] * matriz[2, 0])\n",
        "    \n",
        "    det = a - b + c\n",
        "    \n",
        "    print(f\"üìê C√°lculo Manual 3x3 (expans√£o pela 1¬™ linha):\")\n",
        "    print(f\"det = {matriz[0,0]}√ó(cofator) - {matriz[0,1]}√ó(cofator) + {matriz[0,2]}√ó(cofator)\")\n",
        "    print(f\"det = {a:.3f} - {b:.3f} + {c:.3f} = {det:.3f}\")\n",
        "    \n",
        "    return det\n",
        "\n",
        "# Testando nossas implementa√ß√µes\n",
        "print(\"üßÆ Vamos testar nossos c√°lculos manuais!\\n\")\n",
        "\n",
        "# Teste 2x2\n",
        "matriz_2x2 = np.array([[3, 2], [1, 4]])\n",
        "det_manual = det_2x2_manual(matriz_2x2)\n",
        "det_numpy = np.linalg.det(matriz_2x2)\n",
        "print(f\"NumPy: {det_numpy:.3f}\")\n",
        "print(f\"‚úÖ Conferindo: {abs(det_manual - det_numpy) < 1e-10}\\n\")\n",
        "\n",
        "# Teste 3x3\n",
        "matriz_3x3 = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 10]])\n",
        "det_manual_3x3 = det_3x3_manual(matriz_3x3)\n",
        "det_numpy_3x3 = np.linalg.det(matriz_3x3)\n",
        "print(f\"NumPy: {det_numpy_3x3:.3f}\")\n",
        "print(f\"‚úÖ Conferindo: {abs(det_manual_3x3 - det_numpy_3x3) < 1e-10}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comparando performance para matrizes grandes\n",
        "import time\n",
        "\n",
        "def benchmark_determinante():\n",
        "    \"\"\"Testa performance do c√°lculo de determinante\"\"\"\n",
        "    \n",
        "    tamanhos = [10, 50, 100, 200, 500]\n",
        "    tempos = []\n",
        "    \n",
        "    print(\"‚è±Ô∏è Benchmark: Calculando determinantes de matrizes grandes\\n\")\n",
        "    \n",
        "    for n in tamanhos:\n",
        "        # Criando matriz aleat√≥ria\n",
        "        matriz = np.random.randn(n, n)\n",
        "        \n",
        "        # Medindo tempo\n",
        "        start = time.time()\n",
        "        det = np.linalg.det(matriz)\n",
        "        tempo = time.time() - start\n",
        "        \n",
        "        tempos.append(tempo)\n",
        "        print(f\"Matriz {n}x{n}: {tempo:.6f}s (det = {det:.3e})\")\n",
        "    \n",
        "    # Plotando os resultados\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(tamanhos, tempos, 'bo-', linewidth=2, markersize=8)\n",
        "    plt.xlabel('Tamanho da Matriz (n√ón)')\n",
        "    plt.ylabel('Tempo (segundos)')\n",
        "    plt.title('‚è±Ô∏è Performance do C√°lculo de Determinante\\nComplexidade aproximada: O(n¬≥)')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.yscale('log')\n",
        "    \n",
        "    # Adicionando anota√ß√µes\n",
        "    for i, (x, y) in enumerate(zip(tamanhos, tempos)):\n",
        "        plt.annotate(f'{y:.4f}s', (x, y), textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    return tamanhos, tempos\n",
        "\n",
        "tamanhos, tempos = benchmark_determinante()\n",
        "print(f\"\\nüí° Dica do Pedro: Viu como o tempo cresce r√°pido? Por isso algoritmos eficientes s√£o importantes!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîó Conex√µes com IA: Onde o Determinante Aparece\n\nAgora vem a parte **mais massa**: onde o determinante aparece na pr√°tica da IA! ü§ñ\n\n### 1. **Redes Neurais e Jacobiano**\nO **determinante do Jacobiano** mede como uma rede neural \"estica\" ou \"comprime\" o espa√ßo de entrada:\n\n$$J = \\frac{\\partial f(x)}{\\partial x}, \\quad \\det(J) = \\text{\"volume scaling factor\"}$$\n\n### 2. **An√°lise de Componentes Principais (PCA)**\nNo **M√≥dulo 10**, vamos ver como o determinante da matriz de covari√¢ncia nos diz sobre a \"dispers√£o\" dos dados!\n\n### 3. **Modelos Generativos**\nEm **GANs** e **Normalizing Flows**, o determinante ajuda a calcular probabilidades:\n\n$$p_y(y) = p_x(f^{-1}(y)) \\left|\\det\\left(\\frac{\\partial f^{-1}}{\\partial y}\\right)\\right|$$\n\n### 4. **Regulariza√ß√£o**\nDeterminante pr√≥ximo de zero = **instabilidade num√©rica**!\n\n```mermaid\ngraph TD\n    A[Dados de Entrada] --> B[Transforma√ß√£o Linear]\n    B --> C[Determinante]\n    C --> D{Det ‚âà 0?}\n    D -->|Sim| E[‚ö†Ô∏è Problema!]\n    D -->|N√£o| F[‚úÖ Transforma√ß√£o OK]\n    E --> G[Regulariza√ß√£o]\n    F --> H[Pr√≥xima Camada]\n    G --> H\n```\n\n**Dica do Pedro**: O determinante √© como um **\"health check\"** das suas transforma√ß√µes! Sempre de olho nele! üëÄ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simulando uma situa√ß√£o real: an√°lise de estabilidade em redes neurais\n",
        "def simular_camada_neural():\n",
        "    \"\"\"Simula como o determinante pode indicar problemas em redes neurais\"\"\"\n",
        "    \n",
        "    print(\"üß† Simula√ß√£o: Analisando Estabilidade de Camadas Neurais\\n\")\n",
        "    \n",
        "    # Simulando pesos de diferentes camadas\n",
        "    camadas = {\n",
        "        \"Camada Saud√°vel\": np.random.randn(4, 4) * 0.5,\n",
        "        \"Camada Inst√°vel\": np.array([[1, 2, 3, 4], \n",
        "                                     [2, 4, 6, 8], \n",
        "                                     [0.5, 1, 1.5, 2], \n",
        "                                     [3, 6, 9, 12]]),\n",
        "        \"Camada Bem Condicionada\": np.eye(4) + 0.1 * np.random.randn(4, 4)\n",
        "    }\n",
        "    \n",
        "    resultados = []\n",
        "    \n",
        "    for nome, pesos in camadas.items():\n",
        "        det = np.linalg.det(pesos)\n",
        "        cond = np.linalg.cond(pesos)  # N√∫mero de condi√ß√£o\n",
        "        \n",
        "        print(f\"üìä {nome}:\")\n",
        "        print(f\"   Determinante: {det:.6f}\")\n",
        "        print(f\"   N√∫mero de Condi√ß√£o: {cond:.2f}\")\n",
        "        \n",
        "        # Diagn√≥stico\n",
        "        if abs(det) < 1e-6:\n",
        "            status = \"üö® CR√çTICO: Quase singular!\"\n",
        "        elif abs(det) < 0.01:\n",
        "            status = \"‚ö†Ô∏è ATEN√á√ÉO: Determinante muito pequeno\"\n",
        "        elif abs(det) > 100:\n",
        "            status = \"üìà INFO: Determinante muito grande\"\n",
        "        else:\n",
        "            status = \"‚úÖ OK: Determinante saud√°vel\"\n",
        "        \n",
        "        print(f\"   Status: {status}\\n\")\n",
        "        \n",
        "        resultados.append((nome, det, cond, status))\n",
        "    \n",
        "    return resultados\n",
        "\n",
        "# Exemplo pr√°tico: matriz de covari√¢ncia (pr√©via do que vem no PCA!)\n",
        "def analisar_covariancia():\n",
        "    \"\"\"Analisa determinante de matriz de covari√¢ncia\"\"\"\n",
        "    \n",
        "    print(\"üìà An√°lise de Covari√¢ncia (Pr√©via do PCA!)\\n\")\n",
        "    \n",
        "    # Gerando dados com diferentes correla√ß√µes\n",
        "    np.random.seed(42)\n",
        "    \n",
        "    # Dados independentes\n",
        "    dados_indep = np.random.randn(1000, 2)\n",
        "    cov_indep = np.cov(dados_indep.T)\n",
        "    \n",
        "    # Dados correlacionados\n",
        "    dados_corr = np.random.randn(1000, 2)\n",
        "    dados_corr[:, 1] = 0.8 * dados_corr[:, 0] + 0.2 * dados_corr[:, 1]\n",
        "    cov_corr = np.cov(dados_corr.T)\n",
        "    \n",
        "    print(f\"üîµ Dados Independentes:\")\n",
        "    print(f\"   Matriz de Covari√¢ncia:\\n{cov_indep}\")\n",
        "    print(f\"   Determinante: {np.linalg.det(cov_indep):.4f}\")\n",
        "    \n",
        "    print(f\"\\nüî¥ Dados Correlacionados:\")\n",
        "    print(f\"   Matriz de Covari√¢ncia:\\n{cov_corr}\")\n",
        "    print(f\"   Determinante: {np.linalg.det(cov_corr):.4f}\")\n",
        "    \n",
        "    print(f\"\\nüí° Interpreta√ß√£o:\")\n",
        "    print(f\"   Determinante menor = maior correla√ß√£o = menos \"informa√ß√£o √∫nica\"\")\n",
        "    \n",
        "    return cov_indep, cov_corr\n",
        "\n",
        "# Executando as an√°lises\n",
        "resultados_neural = simular_camada_neural()\n",
        "cov_indep, cov_corr = analisar_covariancia()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Exerc√≠cio Pr√°tico 1: Detetive do Determinante\n\nAgora √© sua vez de **investigar**! üïµÔ∏è‚Äç‚ôÇÔ∏è\n\nVoc√™ recebeu algumas matrizes misteriosas e precisa descobrir:\n1. Qual delas **inverte** o espa√ßo?\n2. Qual delas **achata** o espa√ßo?\n3. Qual delas **dobra** o tamanho?\n4. Qual delas √© **bem comportada**?\n\n**Instru√ß√µes:**\n- Calcule o determinante de cada matriz\n- Interprete o resultado\n- Visualize pelo menos 2 transforma√ß√µes\n- Explique o que cada uma faz geometricamente\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/algebra-linear-para-ia-modulo-08_img_03.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üéØ EXERC√çCIO 1: Complete o c√≥digo abaixo!\n",
        "\n",
        "# Matrizes misteriosas para investigar\n",
        "matrizes_misterio = {\n",
        "    \"Matriz A\": np.array([[2, 0], [0, 2]]),\n",
        "    \"Matriz B\": np.array([[1, 0], [0, -1]]),\n",
        "    \"Matriz C\": np.array([[3, 6], [1, 2]]),\n",
        "    \"Matriz D\": np.array([[1, 2], [3, 4]]),\n",
        "    \"Matriz E\": np.array([[0.5, 0], [0, 0.5]])\n",
        "}\n",
        "\n",
        "print(\"üïµÔ∏è‚Äç‚ôÇÔ∏è EXERC√çCIO: Detetive do Determinante!\\n\")\n",
        "print(\"Sua miss√£o: Investigar cada matriz e descobrir suas propriedades!\\n\")\n",
        "\n",
        "# TODO: Complete este c√≥digo!\n",
        "# 1. Para cada matriz, calcule o determinante\n",
        "# 2. Classifique cada matriz baseada no determinante\n",
        "# 3. Visualize pelo menos 2 transforma√ß√µes\n",
        "\n",
        "def investigar_matriz(matriz, nome):\n",
        "    \"\"\"Fun√ß√£o para investigar uma matriz - COMPLETE ESTA FUN√á√ÉO!\"\"\"\n",
        "    \n",
        "    # TODO: Calcular determinante\n",
        "    det = None  # Substitua por seu c√≥digo\n",
        "    \n",
        "    # TODO: Classificar a matriz\n",
        "    classificacao = \"\"  # Substitua por sua classifica√ß√£o\n",
        "    \n",
        "    # TODO: Interpreta√ß√£o geom√©trica\n",
        "    interpretacao = \"\"  # Explique o que a matriz faz\n",
        "    \n",
        "    print(f\"üîç {nome}:\")\n",
        "    print(f\"   Determinante: {det}\")\n",
        "    print(f\"   Classifica√ß√£o: {classificacao}\")\n",
        "    print(f\"   Interpreta√ß√£o: {interpretacao}\\n\")\n",
        "    \n",
        "    return det, classificacao\n",
        "\n",
        "# Execute sua investiga√ß√£o aqui!\n",
        "# for nome, matriz in matrizes_misterio.items():\n",
        "#     investigar_matriz(matriz, nome)\n",
        "\n",
        "print(\"üí° DICA: Lembre-se das regras:\")\n",
        "print(\"   - det > 0: Mant√©m orienta√ß√£o\")\n",
        "print(\"   - det < 0: Inverte orienta√ß√£o\")\n",
        "print(\"   - det = 0: Achata o espa√ßo\")\n",
        "print(\"   - |det| > 1: Aumenta √°rea\")\n",
        "print(\"   - |det| < 1: Diminui √°rea\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Exerc√≠cio Pr√°tico 2: Construtor de Transforma√ß√µes\n\nAgora voc√™ vai ser um **arquiteto do espa√ßo**! üèóÔ∏è\n\nSua miss√£o √© **construir** matrizes que fazem transforma√ß√µes espec√≠ficas:\n\n1. **Dobra** a √°rea mas mant√©m orienta√ß√£o\n2. **Inverte** horizontalmente e triplica a √°rea\n3. **Cisalha** o espa√ßo sem mudar a √°rea\n4. **Rotaciona** 90¬∞ e reduz √† metade\n\n**Desafio Extra**: Construa uma matriz que transforma um c√≠rculo em uma elipse espec√≠fica!\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/algebra-linear-para-ia-modulo-08_img_04.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üéØ EXERC√çCIO 2: Construtor de Transforma√ß√µes\n",
        "\n",
        "print(\"üèóÔ∏è EXERC√çCIO: Construtor de Transforma√ß√µes!\\n\")\n",
        "print(\"Construa matrizes para fazer transforma√ß√µes espec√≠ficas!\\n\")\n",
        "\n",
        "def construir_transformacao(descricao, matriz_construida):\n",
        "    \"\"\"Testa se a matriz constru√≠da atende aos requisitos\"\"\"\n",
        "    \n",
        "    det = np.linalg.det(matriz_construida)\n",
        "    \n",
        "    print(f\"üéØ {descricao}:\")\n",
        "    print(f\"   Sua matriz:\\n{matriz_construida}\")\n",
        "    print(f\"   Determinante: {det:.3f}\")\n",
        "    \n",
        "    # Visualizando a transforma√ß√£o\n",
        "    visualizar_transformacao(matriz_construida, descricao)\n",
        "    \n",
        "    return det\n",
        "\n",
        "# TODO: Complete as matrizes abaixo!\n",
        "\n",
        "# 1. Dobra a √°rea (det = 2) mas mant√©m orienta√ß√£o (det > 0)\n",
        "print(\"üìã Tarefa 1: Dobrar a √°rea mantendo orienta√ß√£o\")\n",
        "matriz_dobra = np.array([[1, 0], [0, 1]])  # TODO: Substitua por sua matriz!\n",
        "# construir_transformacao(\"Dobra √°rea\", matriz_dobra)\n",
        "\n",
        "# 2. Inverte horizontalmente e triplica √°rea (det = -3)\n",
        "print(\"\\nüìã Tarefa 2: Inverter horizontalmente e triplicar √°rea\")\n",
        "matriz_inverte_triplica = np.array([[1, 0], [0, 1]])  # TODO: Substitua!\n",
        "# construir_transformacao(\"Inverte e triplica\", matriz_inverte_triplica)\n",
        "\n",
        "# 3. Cisalha sem mudar √°rea (det = 1)\n",
        "print(\"\\nüìã Tarefa 3: Cisalhar mantendo √°rea\")\n",
        "matriz_cisalha = np.array([[1, 0], [0, 1]])  # TODO: Substitua!\n",
        "# construir_transformacao(\"Cisalha mantendo √°rea\", matriz_cisalha)\n",
        "\n",
        "# 4. Rotaciona 90¬∞ e reduz √† metade (det = -0.5)\n",
        "print(\"\\nüìã Tarefa 4: Rotacionar 90¬∞ e reduzir √† metade\")\n",
        "matriz_rota_reduz = np.array([[1, 0], [0, 1]])  # TODO: Substitua!\n",
        "# construir_transformacao(\"Rotaciona e reduz\", matriz_rota_reduz)\n",
        "\n",
        "print(\"\\nüí° DICAS:\")\n",
        "print(\"   - Para rota√ß√£o 90¬∞: cos(90¬∞)=0, sin(90¬∞)=1\")\n",
        "print(\"   - Para cisalhamento: use [[1, k], [0, 1]] ou [[1, 0], [k, 1]]\")\n",
        "print(\"   - Para invers√£o horizontal: [-1, 0] na primeira linha\")\n",
        "print(\"   - Para escalar: multiplique por fatores apropriados\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üåü Propriedades Especiais do Determinante\n\nAntes de finalizar, vamos ver algumas **propriedades massa** do determinante que v√£o te ajudar muito! üöÄ\n\n### As Regras de Ouro:\n\n1. **Multiplicatividade**: $\\det(AB) = \\det(A) \\cdot \\det(B)$\n2. **Inversa**: $\\det(A^{-1}) = \\frac{1}{\\det(A)}$\n3. **Transposta**: $\\det(A^T) = \\det(A)$\n4. **Escalar**: $\\det(kA) = k^n \\det(A)$ (para matriz n√ón)\n5. **Matriz Triangular**: $\\det = \\prod_{i} a_{ii}$ (produto da diagonal)\n\n### Por que isso √© importante?\n\nüß† **Conex√£o com Deep Learning**: Quando voc√™ comp√µe v√°rias transforma√ß√µes (como em redes neurais profundas), o determinante da composi√ß√£o √© o **produto** dos determinantes individuais!\n\n$$\\text{Se } f(x) = A_n A_{n-1} \\cdots A_1 x$$\n$$\\text{Ent√£o } \\det(f) = \\det(A_n) \\cdot \\det(A_{n-1}) \\cdots \\det(A_1)$$\n\nIsso explica problemas como **vanishing/exploding gradients**!\n\n**Dica do Pedro**: Essas propriedades s√£o **ferramentas poderosas** para simplificar c√°lculos complexos! üõ†Ô∏è"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Demonstrando as propriedades do determinante\n",
        "def demonstrar_propriedades():\n",
        "    \"\"\"Demonstra as principais propriedades do determinante\"\"\"\n",
        "    \n",
        "    print(\"üåü Demonstra√ß√£o: Propriedades do Determinante\\n\")\n",
        "    \n",
        "    # Criando matrizes de teste\n",
        "    np.random.seed(42)\n",
        "    A = np.random.randn(3, 3)\n",
        "    B = np.random.randn(3, 3)\n",
        "    k = 2.5\n",
        "    \n",
        "    print(\"üîß Matrizes de teste criadas!\\n\")\n",
        "    \n",
        "    # 1. Multiplicatividade\n",
        "    det_A = np.linalg.det(A)\n",
        "    det_B = np.linalg.det(B)\n",
        "    det_AB = np.linalg.det(A @ B)\n",
        "    produto = det_A * det_B\n",
        "    \n",
        "    print(f\"üìê 1. Multiplicatividade: det(AB) = det(A) √ó det(B)\")\n",
        "    print(f\"   det(A) = {det_A:.4f}\")\n",
        "    print(f\"   det(B) = {det_B:.4f}\")\n",
        "    print(f\"   det(A√óB) = {det_AB:.4f}\")\n",
        "    print(f\"   det(A) √ó det(B) = {produto:.4f}\")\n",
        "    print(f\"   ‚úÖ Diferen√ßa: {abs(det_AB - produto):.2e}\\n\")\n",
        "    \n",
        "    # 2. Transposta\n",
        "    det_A_T = np.linalg.det(A.T)\n",
        "    print(f\"üìê 2. Transposta: det(A^T) = det(A)\")\n",
        "    print(f\"   det(A) = {det_A:.4f}\")\n",
        "    print(f\"   det(A^T) = {det_A_T:.4f}\")\n",
        "    print(f\"   ‚úÖ Diferen√ßa: {abs(det_A - det_A_T):.2e}\\n\")\n",
        "    \n",
        "    # 3. Escalar\n",
        "    det_kA = np.linalg.det(k * A)\n",
        "    det_teorico = (k ** A.shape[0]) * det_A  # k^n * det(A)\n",
        "    print(f\"üìê 3. Multiplica√ß√£o por escalar: det(kA) = k^n √ó det(A)\")\n",
        "    print(f\"   k = {k}\")\n",
        "    print(f\"   n = {A.shape[0]} (dimens√£o da matriz)\")\n",
        "    print(f\"   det(kA) = {det_kA:.4f}\")\n",
        "    print(f\"   k^n √ó det(A) = {k}^{A.shape[0]} √ó {det_A:.4f} = {det_teorico:.4f}\")\n",
        "    print(f\"   ‚úÖ Diferen√ßa: {abs(det_kA - det_teorico):.2e}\\n\")\n",
        "    \n",
        "    # 4. Inversa (se existir)\n",
        "    if abs(det_A) > 1e-10:\n",
        "        A_inv = np.linalg.inv(A)\n",
        "        det_A_inv = np.linalg.det(A_inv)\n",
        "        teorico_inv = 1 / det_A\n",
        "        \n",
        "        print(f\"üìê 4. Inversa: det(A^-1) = 1/det(A)\")\n",
        "        print(f\"   det(A^-1) = {det_A_inv:.4f}\")\n",
        "        print(f\"   1/det(A) = 1/{det_A:.4f} = {teorico_inv:.4f}\")\n",
        "        print(f\"   ‚úÖ Diferen√ßa: {abs(det_A_inv - teorico_inv):.2e}\\n\")\n",
        "    \n",
        "    return A, B\n",
        "\n",
        "# Exemplo pr√°tico: Composi√ß√£o de transforma√ß√µes\n",
        "def exemplo_composicao():\n",
        "    \"\"\"Mostra como determinantes se comportam em composi√ß√µes\"\"\"\n",
        "    \n",
        "    print(\"üîó Exemplo Pr√°tico: Composi√ß√£o de Transforma√ß√µes\\n\")\n",
        "    \n",
        "    # Simulando camadas de uma rede neural\n",
        "    camada1 = np.array([[2, 0], [0, 0.5]])    # Escala: 2x horizontal, 0.5x vertical\n",
        "    camada2 = np.array([[0, -1], [1, 0]])     # Rota√ß√£o 90¬∞ + reflex√£o\n",
        "    camada3 = np.array([[1.5, 0], [0, 1.5]])  # Escala uniforme 1.5x\n",
        "    \n",
        "    # Calculando determinantes individuais\n",
        "    det1 = np.linalg.det(camada1)\n",
        "    det2 = np.linalg.det(camada2)\n",
        "    det3 = np.linalg.det(camada3)\n",
        "    \n",
        "    # Composi√ß√£o total\n",
        "    composicao = camada3 @ camada2 @ camada1\n",
        "    det_total = np.linalg.det(composicao)\n",
        "    produto_dets = det1 * det2 * det3\n",
        "    \n",
        "    print(f\"üéØ Transforma√ß√µes individuais:\")\n",
        "    print(f\"   Camada 1 (escala): det = {det1:.3f}\")\n",
        "    print(f\"   Camada 2 (rota√ß√£o): det = {det2:.3f}\")\n",
        "    print(f\"   Camada 3 (escala): det = {det3:.3f}\")\n",
        "    \n",
        "    print(f\"\\nüîó Composi√ß√£o total:\")\n",
        "    print(f\"   det(C3 √ó C2 √ó C1) = {det_total:.3f}\")\n",
        "    print(f\"   det(C1) √ó det(C2) √ó det(C3) = {produto_dets:.3f}\")\n",
        "    print(f\"   ‚úÖ Conferindo: {abs(det_total - produto_dets) < 1e-10}\")\n",
        "    \n",
        "    # Visualizando a transforma√ß√£o final\n",
        "    visualizar_transformacao(composicao, \"Composi√ß√£o das 3 Transforma√ß√µes\")\n",
        "    \n",
        "    return composicao\n",
        "\n",
        "A, B = demonstrar_propriedades()\n",
        "composicao_final = exemplo_composicao()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéì Resumo: O que Aprendemos sobre Determinantes\n\nParapapapap√°! ü•Å Chegamos ao final desta jornada pelo mundo dos **determinantes**! Vamos recapitular os **pontos-chave**:\n\n### üéØ **Conceitos Fundamentais**\n- **Determinante** = n√∫mero que mede o \"impacto\" de uma transforma√ß√£o\n- **Valor absoluto** = fator de escala da √°rea/volume\n- **Sinal** = orienta√ß√£o (positivo mant√©m, negativo inverte)\n- **Zero** = achatamento (perda de dimens√£o)\n\n### üîß **F√≥rmulas Essenciais**\n- **2√ó2**: $\\det = ad - bc$\n- **3√ó3**: Expans√£o por cofatores\n- **Propriedades**: $\\det(AB) = \\det(A)\\det(B)$\n\n### ü§ñ **Conex√µes com IA**\n- **Estabilidade** de redes neurais\n- **Jacobiano** em transforma√ß√µes\n- **PCA** e an√°lise de covari√¢ncia\n- **Modelos generativos** e normalizing flows\n\n### üöÄ **Preparando para os Pr√≥ximos M√≥dulos**\n- **M√≥dulo 9 (SVD)**: Determinante conecta com valores singulares\n- **M√≥dulo 10 (Autovetores)**: Determinante = produto dos autovalores\n\n```mermaid\ngraph TD\n    A[Determinante] --> B[Mede Transforma√ß√£o]\n    B --> C[Escala do Espa√ßo]\n    B --> D[Orienta√ß√£o]\n    B --> E[Inversibilidade]\n    \n    C --> F[IA: Jacobiano]\n    D --> G[IA: GANs]\n    E --> H[IA: Estabilidade]\n    \n    F --> I[Pr√≥ximo: SVD]\n    G --> J[Pr√≥ximo: PCA]\n    H --> K[Pr√≥ximo: Autovalores]\n    \n    style A fill:#ff6b6b\n    style I fill:#4ecdc4\n    style J fill:#4ecdc4\n    style K fill:#4ecdc4\n```\n\n**Dica Final do Pedro**: O determinante √© como o **\"DNA\"** de uma transforma√ß√£o - ele te conta tudo sobre o que ela faz com o espa√ßo! Use esse conhecimento para entender melhor seus modelos de IA! üß¨‚ú®\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/algebra-linear-para-ia-modulo-08_img_05.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# C√≥digo final: Resumo visual de todos os conceitos\n",
        "def resumo_visual_completo():\n",
        "    \"\"\"Cria um resumo visual de todos os conceitos do determinante\"\"\"\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "    fig.suptitle('üéì RESUMO: Determinantes e Transforma√ß√µes do Espa√ßo', fontsize=20, y=0.98)\n",
        "    \n",
        "    # Diferentes tipos de transforma√ß√µes\n",
        "    transformacoes = [\n",
        "        (np.array([[2, 0], [0, 1]]), \"Estica Horizontal\\ndet = 2\"),\n",
        "        (np.array([[-1, 0], [0, 1]]), \"Reflex√£o\\ndet = -1\"),\n",
        "        (np.array([[1, 1], [2, 2]]), \"Achatamento\\ndet = 0\"),\n",
        "        (np.array([[0.7, -0.7], [0.7, 0.7]]), \"Rota√ß√£o 45¬∞\\ndet = 1\"),\n",
        "        (np.array([[1, 0.5], [0, 1]]), \"Cisalhamento\\ndet = 1\"),\n",
        "        (np.array([[1.5, 0], [0, 1.5]]), \"Escala Uniforme\\ndet = 2.25\")\n",
        "    ]\n",
        "    \n",
        "    # Quadrado original\n",
        "    quadrado = np.array([[0, 1, 1, 0, 0], [0, 0, 1, 1, 0]])\n",
        "    \n",
        "    for i, (matriz, titulo) in enumerate(transformacoes):\n",
        "        ax = axes[i//3, i%3]\n",
        "        \n",
        "        # Aplicando transforma√ß√£o\n",
        "        transformado = matriz @ quadrado\n",
        "        det = np.linalg.det(matriz)\n",
        "        \n",
        "        # Plotando original (transparente)\n",
        "        ax.plot(quadrado[0], quadrado[1], 'b--', alpha=0.3, linewidth=1, label='Original')\n",
        "        ax.fill(quadrado[0], quadrado[1], alpha=0.1, color='blue')\n",
        "        \n",
        "        # Plotando transformado\n",
        "        cor = 'red' if det < 0 else 'green' if abs(det) < 1e-10 else 'orange' if abs(det) > 1 else 'purple'\n",
        "        ax.plot(transformado[0], transformado[1], color=cor, linewidth=3)\n",
        "        ax.fill(transformado[0], transformado[1], alpha=0.4, color=cor)\n",
        "        \n",
        "        ax.set_title(titulo, fontsize=12, pad=10)\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.set_xlim(-2.5, 2.5)\n",
        "        ax.set_ylim(-2.5, 2.5)\n",
        "        ax.set_aspect('equal')\n",
        "        \n",
        "        # Adicionando texto com valor do determinante\n",
        "        ax.text(0.02, 0.98, f'det = {det:.2f}', transform=ax.transAxes, \n",
        "                verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Gr√°fico de barras dos determinantes\n",
        "    fig, ax = plt.subplots(figsize=(12, 6))\n",
        "    \n",
        "    nomes = [t[1].split('\\n')[0] for t in transformacoes]\n",
        "    dets = [np.linalg.det(t[0]) for t in transformacoes]\n",
        "    cores = ['red' if d < 0 else 'gray' if abs(d) < 1e-10 else 'green' if abs(d) > 1 else 'blue' for d in dets]\n",
        "    \n",
        "    bars = ax.bar(nomes, dets, color=cores, alpha=0.7, edgecolor='black')\n",
        "    ax.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
        "    ax.axhline(y=1, color='orange', linestyle='--', alpha=0.5, label='det = 1 (preserva √°rea)')\n",
        "    ax.axhline(y=-1, color='orange', linestyle='--', alpha=0.5, label='det = -1 (inverte + preserva)')\n",
        "    \n",
        "    ax.set_ylabel('Determinante')\n",
        "    ax.set_title('üìä Compara√ß√£o de Determinantes das Transforma√ß√µes')\n",
        "    ax.legend()\n",
        "    \n",
        "    # Adicionando valores nas barras\n",
        "    for bar, det in zip(bars, dets):\n",
        "        height = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width()/2., height + (0.1 if height >= 0 else -0.2),\n",
        "                f'{det:.2f}', ha='center', va='bottom' if height >= 0 else 'top')\n",
        "    \n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Mensagem final\n",
        "def mensagem_final():\n",
        "    print(\"üéâ\" * 50)\n",
        "    print(\"üéì PARAB√âNS! Voc√™ dominou os Determinantes!\")\n",
        "    print(\"üéâ\" * 50)\n",
        "    print()\n",
        "    print(\"üìö Voc√™ agora sabe:\")\n",
        "    print(\"   ‚úÖ Calcular determinantes de diferentes tamanhos\")\n",
        "    print(\"   ‚úÖ Interpretar o significado geom√©trico\")\n",
        "    print(\"   ‚úÖ Identificar transforma√ß√µes problem√°ticas\")\n",
        "    print(\"   ‚úÖ Conectar determinantes com IA\")\n",
        "    print(\"   ‚úÖ Usar propriedades para simplificar c√°lculos\")\n",
        "    print()\n",
        "    print(\"üöÄ Pr√≥ximos passos:\")\n",
        "    print(\"   üìñ M√≥dulo 9: SVD - Decomposi√ß√£o de Valores Singulares\")\n",
        "    print(\"   üìñ M√≥dulo 10: Autovetores e Autovalores para PCA\")\n",
        "    print()\n",
        "    print(\"üí° Lembre-se: O determinante √© sua ferramenta para\")\n",
        "    print(\"    entender como transforma√ß√µes afetam o espa√ßo!\")\n",
        "    print()\n",
        "    print(\"üî• Keep learning, keep growing! - Pedro Guth\")\n",
        "    print(\"üéâ\" * 50)\n",
        "\n",
        "# Executando resumo final\n",
        "resumo_visual_completo()\n",
        "mensagem_final()"
      ]
    }
  ]
}