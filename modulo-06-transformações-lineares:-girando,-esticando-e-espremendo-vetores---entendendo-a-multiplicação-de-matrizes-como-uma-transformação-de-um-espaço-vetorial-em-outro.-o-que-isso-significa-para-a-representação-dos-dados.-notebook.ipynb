{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üé™ Transforma√ß√µes Lineares: O Circo dos Vetores\n## Girando, Esticando e Espremendo - Como as Matrizes Fazem M√°gica com os Dados\n\n### Pedro Nunes Guth - M√≥dulo 6 de 10: √Ålgebra Linear para IA\n\n---\n\nEa√≠, galera! Bora entender como as matrizes s√£o verdadeiras **m√°gicas** que transformam nossos dados? üé©‚ú®\n\nAt√© agora no nosso curso, j√° vimos:\n- **M√≥dulo 1-2**: O que s√£o vetores e como eles \"conversam\" entre si\n- **M√≥dulo 3-4**: Como multiplicar matrizes e dominar o NumPy\n- **M√≥dulo 5**: Como resolver sistemas lineares\n\nHoje vamos descobrir que **toda multiplica√ß√£o de matriz √© uma transforma√ß√£o geom√©trica**! √â como se cada matriz fosse um filtro do Instagram para vetores! üì∏\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/algebra-linear-para-ia-modulo-06_img_01.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ O Que Vamos Aprender Hoje?\n\n```mermaid\ngraph TD\n    A[Vetor Original] --> B[Matriz de Transforma√ß√£o]\n    B --> C[Vetor Transformado]\n    C --> D[Rota√ß√£o]\n    C --> E[Escala]\n    C --> F[Reflex√£o]\n    C --> G[Cisalhamento]\n```\n\n**T√°, mas o que isso significa na pr√°tica?**\n\nImagina que voc√™ tem uma foto no seu celular. Quando voc√™:\n- **Gira** a foto ‚Üí Rota√ß√£o\n- **Faz zoom** ‚Üí Escala\n- **Espelha** ‚Üí Reflex√£o\n- **Inclina** ‚Üí Cisalhamento\n\n√â exatamente isso que as transforma√ß√µes lineares fazem com vetores! E o melhor: **toda rede neural usa isso!** ü§Ø"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Bora come√ßar importando nossas bibliotecas favoritas!\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import FancyArrowPatch\n",
        "import seaborn as sns\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# Configura√ß√µes para gr√°ficos mais bonitos\n",
        "plt.style.use('seaborn-v0_8')\n",
        "plt.rcParams['figure.figsize'] = (10, 8)\n",
        "plt.rcParams['font.size'] = 12\n",
        "\n",
        "print(\"üöÄ Bibliotecas carregadas! Bora transformar alguns vetores!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß† Conceito Fundamental: O Que √â Uma Transforma√ß√£o Linear?\n\n**Defini√ß√£o Matem√°tica:**\nUma transforma√ß√£o linear $T: \\mathbb{R}^n \\rightarrow \\mathbb{R}^m$ √© uma fun√ß√£o que satisfaz:\n\n1. **Aditividade:** $T(\\vec{u} + \\vec{v}) = T(\\vec{u}) + T(\\vec{v})$\n2. **Homogeneidade:** $T(c\\vec{u}) = cT(\\vec{u})$\n\n**T√°, mas em portugu√™s claro:** Uma transforma√ß√£o linear √© qualquer opera√ß√£o que voc√™ pode representar como:\n\n$$\\vec{y} = A\\vec{x}$$\n\nOnde:\n- $\\vec{x}$ √© seu vetor original (dados de entrada)\n- $A$ √© a matriz de transforma√ß√£o (os \"filtros\")\n- $\\vec{y}$ √© o vetor transformado (resultado)\n\n**Analogia do Churrasquinho:** üçñ\n- $\\vec{x}$ = Carne crua\n- $A$ = Churrasqueira (com suas configura√ß√µes)\n- $\\vec{y}$ = Churrasquinho pronto!\n\n**üéØ Dica do Pedro:** Toda camada de uma rede neural √© uma transforma√ß√£o linear seguida de uma fun√ß√£o de ativa√ß√£o!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Vamos criar uma fun√ß√£o para visualizar transforma√ß√µes\n",
        "def plot_transformation(original_vectors, transformed_vectors, title=\"Transforma√ß√£o Linear\"):\n",
        "    \"\"\"\n",
        "    Plota vetores antes e depois da transforma√ß√£o\n",
        "    \"\"\"\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "    \n",
        "    # Configura√ß√£o dos eixos\n",
        "    for ax in [ax1, ax2]:\n",
        "        ax.set_xlim(-5, 5)\n",
        "        ax.set_ylim(-5, 5)\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.axhline(y=0, color='k', linewidth=0.5)\n",
        "        ax.axvline(x=0, color='k', linewidth=0.5)\n",
        "    \n",
        "    # Vetores originais\n",
        "    ax1.set_title(\"üîµ Vetores Originais\")\n",
        "    colors = ['red', 'blue', 'green', 'purple', 'orange']\n",
        "    \n",
        "    for i, vec in enumerate(original_vectors.T):\n",
        "        ax1.arrow(0, 0, vec[0], vec[1], \n",
        "                 head_width=0.2, head_length=0.2, \n",
        "                 fc=colors[i%len(colors)], ec=colors[i%len(colors)],\n",
        "                 linewidth=2)\n",
        "    \n",
        "    # Vetores transformados\n",
        "    ax2.set_title(\"üî¥ Vetores Transformados\")\n",
        "    for i, vec in enumerate(transformed_vectors.T):\n",
        "        ax2.arrow(0, 0, vec[0], vec[1], \n",
        "                 head_width=0.2, head_length=0.2, \n",
        "                 fc=colors[i%len(colors)], ec=colors[i%len(colors)],\n",
        "                 linewidth=2)\n",
        "    \n",
        "    plt.suptitle(title, fontsize=16, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Vamos criar alguns vetores de exemplo\n",
        "# Lembra do m√≥dulo anterior? Vamos usar a base can√¥nica!\n",
        "original_vectors = np.array([\n",
        "    [1, 0],  # Vetor base i\n",
        "    [0, 1],  # Vetor base j\n",
        "    [2, 1],  # Um vetor qualquer\n",
        "    [1, 2],  # Outro vetor qualquer\n",
        "    [-1, 1]  # Mais um vetor\n",
        "]).T\n",
        "\n",
        "print(\"Vetores originais criados!\")\n",
        "print(f\"Formato da matriz: {original_vectors.shape}\")\n",
        "print(f\"\\nVetores:\\n{original_vectors}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîÑ Tipo 1: Rota√ß√£o - Girando os Dados\n\nA rota√ß√£o √© provavelmente a transforma√ß√£o mais \"visual\" que existe! \n\n**Matriz de Rota√ß√£o 2D:**\n$$R(\\theta) = \\begin{pmatrix}\n\\cos(\\theta) & -\\sin(\\theta) \\\\\n\\sin(\\theta) & \\cos(\\theta)\n\\end{pmatrix}$$\n\nOnde $\\theta$ √© o √¢ngulo de rota√ß√£o (em radianos).\n\n**Por que isso funciona matematicamente?**\n- O cosseno e seno preservam a **dist√¢ncia** do vetor √† origem\n- A combina√ß√£o espec√≠fica garante que rotacionemos no sentido anti-hor√°rio\n- √â uma **transforma√ß√£o ortogonal** (preserva √¢ngulos e dist√¢ncias)\n\n**Aplica√ß√£o em IA:** Data Augmentation em vis√£o computacional! üì∏\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/algebra-linear-para-ia-modulo-06_img_02.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def rotation_matrix(theta_degrees):\n",
        "    \"\"\"\n",
        "    Cria uma matriz de rota√ß√£o para o √¢ngulo dado em graus\n",
        "    \"\"\"\n",
        "    theta = np.radians(theta_degrees)  # Converte para radianos\n",
        "    \n",
        "    R = np.array([\n",
        "        [np.cos(theta), -np.sin(theta)],\n",
        "        [np.sin(theta),  np.cos(theta)]\n",
        "    ])\n",
        "    \n",
        "    return R\n",
        "\n",
        "# Vamos rotacionar nossos vetores em 45 graus\n",
        "angle = 45  # graus\n",
        "R = rotation_matrix(angle)\n",
        "\n",
        "print(f\"Matriz de Rota√ß√£o ({angle}¬∞):\")\n",
        "print(R)\n",
        "print(f\"\\nFormato da matriz: {R.shape}\")\n",
        "\n",
        "# Aplicando a transforma√ß√£o (lembra do m√≥dulo 3? Multiplica√ß√£o de matrizes!)\n",
        "rotated_vectors = R @ original_vectors\n",
        "\n",
        "print(f\"\\nVetores rotacionados:\")\n",
        "print(rotated_vectors)\n",
        "\n",
        "# Visualizando a transforma√ß√£o\n",
        "plot_transformation(original_vectors, rotated_vectors, \n",
        "                   f\"üîÑ Rota√ß√£o de {angle}¬∞ - Girando os Dados!\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Vamos fazer uma anima√ß√£o mental: m√∫ltiplas rota√ß√µes!\n",
        "angles = [0, 30, 60, 90, 120, 150, 180]\n",
        "\n",
        "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, angle in enumerate(angles):\n",
        "    if i < len(axes):\n",
        "        R = rotation_matrix(angle)\n",
        "        rotated = R @ original_vectors\n",
        "        \n",
        "        ax = axes[i]\n",
        "        ax.set_xlim(-3, 3)\n",
        "        ax.set_ylim(-3, 3)\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.axhline(y=0, color='k', linewidth=0.5)\n",
        "        ax.axvline(x=0, color='k', linewidth=0.5)\n",
        "        \n",
        "        colors = ['red', 'blue', 'green', 'purple', 'orange']\n",
        "        for j, vec in enumerate(rotated.T):\n",
        "            ax.arrow(0, 0, vec[0], vec[1], \n",
        "                    head_width=0.1, head_length=0.1, \n",
        "                    fc=colors[j%len(colors)], ec=colors[j%len(colors)],\n",
        "                    linewidth=2)\n",
        "        \n",
        "        ax.set_title(f\"Rota√ß√£o: {angle}¬∞\")\n",
        "\n",
        "# Remove o √∫ltimo subplot vazio\n",
        "if len(angles) < len(axes):\n",
        "    axes[-1].remove()\n",
        "\n",
        "plt.suptitle(\"üé° Carrossel de Rota√ß√µes - Vendo os Vetores Dan√ßarem!\", \n",
        "             fontsize=16, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Liiindo! Viu como os vetores mant√™m o tamanho mas mudam dire√ß√£o? üï∫\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìè Tipo 2: Escala - Esticando e Espremendo\n\nA transforma√ß√£o de escala muda o **tamanho** dos vetores, mas mant√©m a dire√ß√£o!\n\n**Matriz de Escala 2D:**\n$$S = \\begin{pmatrix}\ns_x & 0 \\\\\n0 & s_y\n\\end{pmatrix}$$\n\nOnde:\n- $s_x$ = fator de escala no eixo X\n- $s_y$ = fator de escala no eixo Y\n\n**Casos Especiais:**\n- $s_x = s_y = k > 1$ ‚Üí **Amplia√ß√£o uniforme**\n- $s_x = s_y = k < 1$ ‚Üí **Redu√ß√£o uniforme** \n- $s_x \\neq s_y$ ‚Üí **Deforma√ß√£o** (estica mais numa dire√ß√£o)\n- $s_x$ ou $s_y$ negativos ‚Üí **Reflex√£o + escala**\n\n**Interpreta√ß√£o Geom√©trica:**\nA matriz diagonal \"puxa\" ou \"empurra\" cada componente do vetor independentemente!\n\n**üéØ Dica do Pedro:** Normaliza√ß√£o de dados usa transforma√ß√µes de escala! Quando fazemos `(x - mean)/std`, estamos aplicando uma transforma√ß√£o linear!\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/algebra-linear-para-ia-modulo-06_img_03.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def scaling_matrix(sx, sy):\n",
        "    \"\"\"\n",
        "    Cria uma matriz de escala\n",
        "    sx: fator de escala no eixo x\n",
        "    sy: fator de escala no eixo y\n",
        "    \"\"\"\n",
        "    S = np.array([\n",
        "        [sx, 0],\n",
        "        [0, sy]\n",
        "    ])\n",
        "    return S\n",
        "\n",
        "# Vamos testar diferentes tipos de escala\n",
        "transformations = [\n",
        "    (2, 2, \"Amplia√ß√£o Uniforme (2x)\"),\n",
        "    (0.5, 0.5, \"Redu√ß√£o Uniforme (0.5x)\"),\n",
        "    (3, 1, \"Estica no X (3x, 1x)\"),\n",
        "    (1, 2, \"Estica no Y (1x, 2x)\"),\n",
        "    (-1, 1, \"Reflex√£o no X (-1x, 1x)\"),\n",
        "    (1, -1, \"Reflex√£o no Y (1x, -1x)\")\n",
        "]\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, (sx, sy, title) in enumerate(transformations):\n",
        "    S = scaling_matrix(sx, sy)\n",
        "    scaled_vectors = S @ original_vectors\n",
        "    \n",
        "    ax = axes[i]\n",
        "    ax.set_xlim(-4, 4)\n",
        "    ax.set_ylim(-4, 4)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    ax.axhline(y=0, color='k', linewidth=0.5)\n",
        "    ax.axvline(x=0, color='k', linewidth=0.5)\n",
        "    \n",
        "    colors = ['red', 'blue', 'green', 'purple', 'orange']\n",
        "    \n",
        "    # Plotar vetores originais (pontilhados)\n",
        "    for j, vec in enumerate(original_vectors.T):\n",
        "        ax.arrow(0, 0, vec[0], vec[1], \n",
        "                head_width=0.1, head_length=0.1, \n",
        "                fc='lightgray', ec='lightgray',\n",
        "                linewidth=1, linestyle='--', alpha=0.5)\n",
        "    \n",
        "    # Plotar vetores transformados\n",
        "    for j, vec in enumerate(scaled_vectors.T):\n",
        "        ax.arrow(0, 0, vec[0], vec[1], \n",
        "                head_width=0.1, head_length=0.1, \n",
        "                fc=colors[j%len(colors)], ec=colors[j%len(colors)],\n",
        "                linewidth=2)\n",
        "    \n",
        "    ax.set_title(title)\n",
        "    \n",
        "    # Mostrar a matriz\n",
        "    matrix_text = f\"S = [[{sx}, 0]\\n     [0, {sy}]]\"\n",
        "    ax.text(0.02, 0.98, matrix_text, transform=ax.transAxes, \n",
        "            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "\n",
        "plt.suptitle(\"üìè Transforma√ß√µes de Escala - Esticando e Espremendo!\", \n",
        "             fontsize=16, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"ü§© Olha s√≥! Os vetores cinzas pontilhados s√£o os originais, e os coloridos s√£o os transformados!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîÄ Tipo 3: Cisalhamento - Inclinando o Espa√ßo\n\nO cisalhamento √© como \"inclinar\" o espa√ßo - imagina empurrar um deck de cartas! üÉè\n\n**Matriz de Cisalhamento Horizontal:**\n$$H_x = \\begin{pmatrix}\n1 & k \\\\\n0 & 1\n\\end{pmatrix}$$\n\n**Matriz de Cisalhamento Vertical:**\n$$H_y = \\begin{pmatrix}\n1 & 0 \\\\\nk & 1\n\\end{pmatrix}$$\n\n**O que acontece matematicamente:**\n- No cisalhamento horizontal: $x' = x + ky$, $y' = y$\n- No cisalhamento vertical: $x' = x$, $y' = kx + y$\n\n**Propriedades interessantes:**\n- **Preserva √°rea** (determinante = 1)\n- **Preserva paralelismo** (retas paralelas continuam paralelas)\n- **Muda √¢ngulos** (diferente da rota√ß√£o e escala)\n\n**Aplica√ß√£o real:** Corre√ß√£o de perspectiva em imagens!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def shear_matrix(kx=0, ky=0):\n",
        "    \"\"\"\n",
        "    Cria matriz de cisalhamento\n",
        "    kx: fator de cisalhamento horizontal\n",
        "    ky: fator de cisalhamento vertical\n",
        "    \"\"\"\n",
        "    H = np.array([\n",
        "        [1, kx],\n",
        "        [ky, 1]\n",
        "    ])\n",
        "    return H\n",
        "\n",
        "# Vamos criar uma grade para visualizar melhor o cisalhamento\n",
        "def create_grid():\n",
        "    \"\"\"\n",
        "    Cria uma grade de pontos para visualizar a deforma√ß√£o do espa√ßo\n",
        "    \"\"\"\n",
        "    x = np.linspace(-2, 2, 5)\n",
        "    y = np.linspace(-2, 2, 5)\n",
        "    X, Y = np.meshgrid(x, y)\n",
        "    \n",
        "    # Converte para formato adequado (2, n_points)\n",
        "    grid_points = np.vstack([X.ravel(), Y.ravel()])\n",
        "    return grid_points, X.shape\n",
        "\n",
        "# Testando diferentes tipos de cisalhamento\n",
        "shear_params = [\n",
        "    (0.5, 0, \"Cisalhamento Horizontal (k=0.5)\"),\n",
        "    (1.0, 0, \"Cisalhamento Horizontal (k=1.0)\"),\n",
        "    (0, 0.5, \"Cisalhamento Vertical (k=0.5)\"),\n",
        "    (0.3, 0.3, \"Cisalhamento Misto (kx=0.3, ky=0.3)\")\n",
        "]\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "grid_points, grid_shape = create_grid()\n",
        "\n",
        "for i, (kx, ky, title) in enumerate(shear_params):\n",
        "    H = shear_matrix(kx, ky)\n",
        "    \n",
        "    # Transformar vetores\n",
        "    sheared_vectors = H @ original_vectors\n",
        "    \n",
        "    # Transformar grade\n",
        "    sheared_grid = H @ grid_points\n",
        "    \n",
        "    ax = axes[i]\n",
        "    ax.set_xlim(-4, 4)\n",
        "    ax.set_ylim(-4, 4)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    ax.axhline(y=0, color='k', linewidth=0.5)\n",
        "    ax.axvline(x=0, color='k', linewidth=0.5)\n",
        "    \n",
        "    # Plotar grade original (pontos cinzas)\n",
        "    ax.scatter(grid_points[0], grid_points[1], c='lightgray', s=20, alpha=0.5)\n",
        "    \n",
        "    # Plotar grade transformada (pontos vermelhos)\n",
        "    ax.scatter(sheared_grid[0], sheared_grid[1], c='red', s=30, alpha=0.7)\n",
        "    \n",
        "    # Plotar vetores originais\n",
        "    colors = ['blue', 'green', 'purple', 'orange', 'brown']\n",
        "    for j, vec in enumerate(original_vectors.T):\n",
        "        ax.arrow(0, 0, vec[0], vec[1], \n",
        "                head_width=0.1, head_length=0.1, \n",
        "                fc='lightgray', ec='lightgray',\n",
        "                linewidth=1, linestyle='--', alpha=0.5)\n",
        "    \n",
        "    # Plotar vetores transformados\n",
        "    for j, vec in enumerate(sheared_vectors.T):\n",
        "        ax.arrow(0, 0, vec[0], vec[1], \n",
        "                head_width=0.1, head_length=0.1, \n",
        "                fc=colors[j%len(colors)], ec=colors[j%len(colors)],\n",
        "                linewidth=2)\n",
        "    \n",
        "    ax.set_title(title)\n",
        "    \n",
        "    # Mostrar determinante (√°rea preservada?)\n",
        "    det = np.linalg.det(H)\n",
        "    ax.text(0.02, 0.02, f'det(H) = {det:.2f}', transform=ax.transAxes,\n",
        "            bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.7))\n",
        "\n",
        "plt.suptitle(\"üîÄ Cisalhamento - Inclinando o Espa√ßo como um Deck de Cartas!\", \n",
        "             fontsize=16, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üÉè Olha que interessante! O determinante sempre √© 1, ou seja, a √°rea se mant√©m!\")\n",
        "print(\"Os pontos vermelhos mostram como a 'grade do espa√ßo' se deforma!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ü™û Tipo 4: Reflex√£o - Espelhando Vetores\n\nA reflex√£o √© como colocar um espelho no espa√ßo! \n\n**Reflex√µes B√°sicas:**\n\n**Reflex√£o no eixo X:**\n$$R_x = \\begin{pmatrix}\n1 & 0 \\\\\n0 & -1\n\\end{pmatrix}$$\n\n**Reflex√£o no eixo Y:**\n$$R_y = \\begin{pmatrix}\n-1 & 0 \\\\\n0 & 1\n\\end{pmatrix}$$\n\n**Reflex√£o na origem:**\n$$R_o = \\begin{pmatrix}\n-1 & 0 \\\\\n0 & -1\n\\end{pmatrix}$$\n\n**Reflex√£o numa reta qualquer:** A matem√°tica fica mais complexa, mas o conceito √© o mesmo!\n\n**Propriedades matem√°ticas importantes:**\n- **Determinante = -1** (inverte orienta√ß√£o)\n- **Preserva dist√¢ncias** (transforma√ß√£o ortogonal)\n- **Aplicar duas vezes = identidade** ($R^2 = I$)\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/algebra-linear-para-ia-modulo-06_img_04.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Matrizes de reflex√£o\n",
        "reflection_matrices = {\n",
        "    \"Eixo X\": np.array([[1, 0], [0, -1]]),\n",
        "    \"Eixo Y\": np.array([[-1, 0], [0, 1]]),\n",
        "    \"Origem\": np.array([[-1, 0], [0, -1]]),\n",
        "    \"Linha y=x\": np.array([[0, 1], [1, 0]])  # Reflex√£o na diagonal principal\n",
        "}\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, (name, R) in enumerate(reflection_matrices.items()):\n",
        "    reflected_vectors = R @ original_vectors\n",
        "    \n",
        "    ax = axes[i]\n",
        "    ax.set_xlim(-3, 3)\n",
        "    ax.set_ylim(-3, 3)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    ax.axhline(y=0, color='k', linewidth=1)\n",
        "    ax.axvline(x=0, color='k', linewidth=1)\n",
        "    \n",
        "    # Desenhar linha de reflex√£o\n",
        "    if name == \"Eixo X\":\n",
        "        ax.axhline(y=0, color='red', linewidth=3, alpha=0.7, label='Eixo de reflex√£o')\n",
        "    elif name == \"Eixo Y\":\n",
        "        ax.axvline(x=0, color='red', linewidth=3, alpha=0.7, label='Eixo de reflex√£o')\n",
        "    elif name == \"Linha y=x\":\n",
        "        x_line = np.linspace(-3, 3, 100)\n",
        "        ax.plot(x_line, x_line, 'r-', linewidth=3, alpha=0.7, label='Linha y=x')\n",
        "    \n",
        "    colors = ['blue', 'green', 'purple', 'orange', 'brown']\n",
        "    \n",
        "    # Vetores originais (pontilhados)\n",
        "    for j, vec in enumerate(original_vectors.T):\n",
        "        ax.arrow(0, 0, vec[0], vec[1], \n",
        "                head_width=0.1, head_length=0.1, \n",
        "                fc='lightgray', ec='lightgray',\n",
        "                linewidth=1, linestyle='--', alpha=0.6)\n",
        "    \n",
        "    # Vetores refletidos\n",
        "    for j, vec in enumerate(reflected_vectors.T):\n",
        "        ax.arrow(0, 0, vec[0], vec[1], \n",
        "                head_width=0.1, head_length=0.1, \n",
        "                fc=colors[j%len(colors)], ec=colors[j%len(colors)],\n",
        "                linewidth=2)\n",
        "    \n",
        "    ax.set_title(f\"Reflex√£o no {name}\")\n",
        "    \n",
        "    # Mostrar determinante\n",
        "    det = np.linalg.det(R)\n",
        "    ax.text(0.02, 0.98, f'det(R) = {det:.0f}', transform=ax.transAxes,\n",
        "            verticalalignment='top',\n",
        "            bbox=dict(boxstyle='round', facecolor='lightcoral', alpha=0.7))\n",
        "\n",
        "plt.suptitle(\"ü™û Reflex√µes - Espelhando Vetores no Espa√ßo!\", \n",
        "             fontsize=16, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"ü™û Repara que o determinante √© sempre -1!\")\n",
        "print(\"Isso significa que a reflex√£o 'inverte' a orienta√ß√£o do espa√ßo!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîÑ Composi√ß√£o de Transforma√ß√µes - Combinando Magias!\n\nAqui √© onde a coisa fica **MUITO** interessante! Podemos combinar transforma√ß√µes multiplicando matrizes!\n\n**Regra fundamental:**\n$$T_3(T_2(T_1(\\vec{x}))) = (T_3 \\cdot T_2 \\cdot T_1) \\vec{x}$$\n\n**ATEN√á√ÉO:** A ordem importa! $AB \\neq BA$ (lembra do m√≥dulo 3?)\n\n**Interpreta√ß√£o geom√©trica:**\n- A transforma√ß√£o mais √† **direita** √© aplicada **primeiro**\n- √â como vestir roupas: primeiro a camiseta, depois o casaco!\n\n**Exemplo pr√°tico:** \n1. Primeiro rotaciona 45¬∞\n2. Depois escala 2x no eixo X\n3. Finalmente reflete no eixo Y\n\n$$T_{final} = R_y \\cdot S \\cdot R_{45¬∞}$$\n\n**üéØ Dica do Pedro:** Toda rede neural profunda √© uma composi√ß√£o gigante de transforma√ß√µes lineares + ativa√ß√µes!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Vamos criar uma transforma√ß√£o complexa: Rota√ß√£o + Escala + Reflex√£o\n",
        "def complex_transformation_demo():\n",
        "    \"\"\"\n",
        "    Demonstra uma sequ√™ncia de transforma√ß√µes\n",
        "    \"\"\"\n",
        "    # Definindo as transforma√ß√µes individuais\n",
        "    R = rotation_matrix(30)  # Rota√ß√£o de 30¬∞\n",
        "    S = scaling_matrix(2, 0.5)  # Escala: 2x em X, 0.5x em Y\n",
        "    Ref = np.array([[-1, 0], [0, 1]])  # Reflex√£o no eixo Y\n",
        "    \n",
        "    print(\"üé≠ Sequ√™ncia de transforma√ß√µes:\")\n",
        "    print(\"1. Rota√ß√£o 30¬∞\")\n",
        "    print(\"2. Escala (2x, 0.5x)\")\n",
        "    print(\"3. Reflex√£o no eixo Y\\n\")\n",
        "    \n",
        "    # Aplicando passo a passo\n",
        "    step1 = R @ original_vectors\n",
        "    step2 = S @ step1  \n",
        "    step3 = Ref @ step2\n",
        "    \n",
        "    # Matriz combinada (aplicada de uma vez)\n",
        "    T_combined = Ref @ S @ R  # ATEN√á√ÉO √Ä ORDEM!\n",
        "    result_combined = T_combined @ original_vectors\n",
        "    \n",
        "    # Verificando se d√° o mesmo resultado\n",
        "    print(f\"Resultados s√£o iguais? {np.allclose(step3, result_combined)}\")\n",
        "    print(f\"Diferen√ßa m√°xima: {np.max(np.abs(step3 - result_combined)):.10f}\\n\")\n",
        "    \n",
        "    # Visualiza√ß√£o\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "    \n",
        "    steps = [\n",
        "        (original_vectors, \"üîµ Original\"),\n",
        "        (step1, \"üîÑ Ap√≥s Rota√ß√£o 30¬∞\"),\n",
        "        (step2, \"üìè Ap√≥s Escala (2x, 0.5x)\"),\n",
        "        (step3, \"ü™û Ap√≥s Reflex√£o Y\"),\n",
        "        (result_combined, \"‚ú® Transforma√ß√£o Combinada\"),\n",
        "        (original_vectors, \"üìä Compara√ß√£o Final\")\n",
        "    ]\n",
        "    \n",
        "    for i, (vectors, title) in enumerate(steps):\n",
        "        ax = axes[i//3, i%3]\n",
        "        ax.set_xlim(-4, 4)\n",
        "        ax.set_ylim(-3, 3)\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.axhline(y=0, color='k', linewidth=0.5)\n",
        "        ax.axvline(x=0, color='k', linewidth=0.5)\n",
        "        \n",
        "        colors = ['red', 'blue', 'green', 'purple', 'orange']\n",
        "        \n",
        "        if i == 5:  # Compara√ß√£o final\n",
        "            # Plotar original em cinza\n",
        "            for j, vec in enumerate(original_vectors.T):\n",
        "                ax.arrow(0, 0, vec[0], vec[1], \n",
        "                        head_width=0.1, head_length=0.1, \n",
        "                        fc='lightgray', ec='lightgray',\n",
        "                        linewidth=2, alpha=0.7)\n",
        "            # Plotar resultado final\n",
        "            for j, vec in enumerate(result_combined.T):\n",
        "                ax.arrow(0, 0, vec[0], vec[1], \n",
        "                        head_width=0.1, head_length=0.1, \n",
        "                        fc=colors[j%len(colors)], ec=colors[j%len(colors)],\n",
        "                        linewidth=2)\n",
        "        else:\n",
        "            for j, vec in enumerate(vectors.T):\n",
        "                ax.arrow(0, 0, vec[0], vec[1], \n",
        "                        head_width=0.1, head_length=0.1, \n",
        "                        fc=colors[j%len(colors)], ec=colors[j%len(colors)],\n",
        "                        linewidth=2)\n",
        "        \n",
        "        ax.set_title(title)\n",
        "    \n",
        "    plt.suptitle(\"üé™ Transforma√ß√µes Compostas - O Circo Completo!\", \n",
        "                 fontsize=16, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Mostrar as matrizes\n",
        "    print(\"\\nüìä Matrizes das transforma√ß√µes:\")\n",
        "    print(f\"\\nRota√ß√£o 30¬∞:\\n{R}\")\n",
        "    print(f\"\\nEscala (2x, 0.5x):\\n{S}\")\n",
        "    print(f\"\\nReflex√£o Y:\\n{Ref}\")\n",
        "    print(f\"\\nTransforma√ß√£o Combinada (Ref √ó S √ó R):\\n{T_combined}\")\n",
        "    \n",
        "    return T_combined\n",
        "\n",
        "# Executar a demonstra√ß√£o\n",
        "combined_matrix = complex_transformation_demo()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Aplica√ß√µes em Ci√™ncia de Dados e IA\n\nAgora vem a parte mais legal: **onde isso tudo √© usado na pr√°tica?** ü§î\n\n### 1. **Redes Neurais** üß†\n```python\n# Cada camada de uma rede neural √©:\noutput = activation(W @ input + bias)\n#                   ‚Üë Transforma√ß√£o linear!\n```\n\n### 2. **Data Augmentation** üì∏\n- Rotacionar imagens para treinar modelos mais robustos\n- Aplicar transforma√ß√µes geom√©tricas para aumentar dataset\n\n### 3. **Normaliza√ß√£o e Padroniza√ß√£o** üìè\n```python\n# StandardScaler do sklearn faz:\nx_normalized = (x - mean) / std  # Transforma√ß√£o linear!\n```\n\n### 4. **PCA (An√°lise de Componentes Principais)** üìà\n- Rotaciona os dados para encontrar dire√ß√µes de maior vari√¢ncia\n- Reduz dimensionalidade preservando informa√ß√£o\n\n### 5. **Computer Vision** üëÅÔ∏è\n- Corre√ß√£o de perspectiva\n- Detec√ß√£o de bordas (filtros s√£o transforma√ß√µes!)\n- Registro de imagens m√©dicas\n\n**üéØ Dica do Pedro:** Nos pr√≥ximos m√≥dulos vamos ver como PCA usa autovetores (m√≥dulo 10) e como SVD (m√≥dulo 9) decomp√µe essas transforma√ß√µes!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Vamos simular um caso real: Data Augmentation para ML\n",
        "from sklearn.datasets import make_blobs\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "# Criando um dataset sint√©tico (como se fossem features de imagens)\n",
        "np.random.seed(42)\n",
        "X, y = make_blobs(n_samples=100, centers=2, n_features=2, \n",
        "                  random_state=42, cluster_std=1.5)\n",
        "\n",
        "print(f\"Dataset original: {X.shape}\")\n",
        "print(f\"Classes: {np.unique(y)}\")\n",
        "\n",
        "# Vamos aplicar algumas transforma√ß√µes para \"aumentar\" nosso dataset\n",
        "transformations = {\n",
        "    'Original': np.eye(2),\n",
        "    'Rota√ß√£o 45¬∞': rotation_matrix(45),\n",
        "    'Escala 1.2x': scaling_matrix(1.2, 1.2),\n",
        "    'Reflex√£o X': np.array([[1, 0], [0, -1]]),\n",
        "    'Cisalhamento': shear_matrix(0.3, 0)\n",
        "}\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "all_transformed_data = []\n",
        "all_labels = []\n",
        "\n",
        "for i, (name, T) in enumerate(transformations.items()):\n",
        "    if i < len(axes):\n",
        "        # Aplicar transforma√ß√£o\n",
        "        X_transformed = (T @ X.T).T  # Transposta para trabalhar com formato sklearn\n",
        "        \n",
        "        # Guardar para dataset aumentado\n",
        "        all_transformed_data.append(X_transformed)\n",
        "        all_labels.append(y)\n",
        "        \n",
        "        ax = axes[i]\n",
        "        \n",
        "        # Plotar pontos por classe\n",
        "        colors = ['red', 'blue']\n",
        "        for class_idx in [0, 1]:\n",
        "            mask = y == class_idx\n",
        "            ax.scatter(X_transformed[mask, 0], X_transformed[mask, 1], \n",
        "                      c=colors[class_idx], alpha=0.7, s=50,\n",
        "                      label=f'Classe {class_idx}')\n",
        "        \n",
        "        ax.set_title(f'{name}\\n({len(X_transformed)} amostras)')\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.legend()\n",
        "        ax.set_xlim(-10, 10)\n",
        "        ax.set_ylim(-10, 10)\n",
        "\n",
        "# Dataset aumentado final\n",
        "ax = axes[-1]\n",
        "X_augmented = np.vstack(all_transformed_data)\n",
        "y_augmented = np.hstack(all_labels)\n",
        "\n",
        "for class_idx in [0, 1]:\n",
        "    mask = y_augmented == class_idx\n",
        "    ax.scatter(X_augmented[mask, 0], X_augmented[mask, 1], \n",
        "              c=colors[class_idx], alpha=0.4, s=30,\n",
        "              label=f'Classe {class_idx}')\n",
        "\n",
        "ax.set_title(f'Dataset Aumentado\\n({len(X_augmented)} amostras total!)')\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.legend()\n",
        "ax.set_xlim(-10, 10)\n",
        "ax.set_ylim(-10, 10)\n",
        "\n",
        "plt.suptitle(\"üöÄ Data Augmentation com Transforma√ß√µes Lineares!\", \n",
        "             fontsize=16, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nüìà Resumo do Data Augmentation:\")\n",
        "print(f\"Dataset original: {len(X)} amostras\")\n",
        "print(f\"Dataset aumentado: {len(X_augmented)} amostras\")\n",
        "print(f\"Aumento de: {len(X_augmented)/len(X):.1f}x mais dados!\")\n",
        "print(f\"\\nüéØ Na pr√°tica, isso ajuda o modelo a generalizar melhor!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üé® Visualizando como as Transforma√ß√µes Mudam o Espa√ßo\n\nVamos criar uma visualiza√ß√£o **interativa** para entender como diferentes transforma√ß√µes afetam todo o espa√ßo!\n\n**Conceito chave:** Toda transforma√ß√£o linear pode ser entendida observando o que acontece com a **base can√¥nica**:\n- $\\vec{e_1} = (1, 0)$ ‚Üí primeira coluna da matriz\n- $\\vec{e_2} = (0, 1)$ ‚Üí segunda coluna da matriz\n\n**Por qu√™?** Porque qualquer vetor $(x, y)$ pode ser escrito como:\n$$\\vec{v} = x\\vec{e_1} + y\\vec{e_2}$$\n\nE pela linearidade:\n$$T(\\vec{v}) = xT(\\vec{e_1}) + yT(\\vec{e_2})$$\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/algebra-linear-para-ia-modulo-06_img_05.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def visualize_space_transformation(matrix, title=\"Transforma√ß√£o do Espa√ßo\"):\n",
        "    \"\"\"\n",
        "    Visualiza como uma matriz transforma todo o espa√ßo\n",
        "    \"\"\"\n",
        "    # Criar uma grade mais densa\n",
        "    x = np.linspace(-3, 3, 7)\n",
        "    y = np.linspace(-3, 3, 7)\n",
        "    X, Y = np.meshgrid(x, y)\n",
        "    \n",
        "    # Converter para pontos\n",
        "    points = np.vstack([X.ravel(), Y.ravel()])\n",
        "    \n",
        "    # Aplicar transforma√ß√£o\n",
        "    transformed_points = matrix @ points\n",
        "    \n",
        "    # Vetores da base can√¥nica\n",
        "    e1 = np.array([[1], [0]])\n",
        "    e2 = np.array([[0], [1]])\n",
        "    \n",
        "    # Transformar vetores da base\n",
        "    t_e1 = matrix @ e1\n",
        "    t_e2 = matrix @ e2\n",
        "    \n",
        "    # Visualiza√ß√£o\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 7))\n",
        "    \n",
        "    # Espa√ßo original\n",
        "    ax1.scatter(points[0], points[1], c='lightblue', s=50, alpha=0.7)\n",
        "    \n",
        "    # Vetores da base original\n",
        "    ax1.arrow(0, 0, 1, 0, head_width=0.1, head_length=0.1, \n",
        "             fc='red', ec='red', linewidth=3, label='e‚ÇÅ = (1,0)')\n",
        "    ax1.arrow(0, 0, 0, 1, head_width=0.1, head_length=0.1, \n",
        "             fc='blue', ec='blue', linewidth=3, label='e‚ÇÇ = (0,1)')\n",
        "    \n",
        "    # Desenhar grade\n",
        "    for i in range(len(x)):\n",
        "        ax1.plot(X[i, :], Y[i, :], 'k-', alpha=0.3, linewidth=1)\n",
        "        ax1.plot(X[:, i], Y[:, i], 'k-', alpha=0.3, linewidth=1)\n",
        "    \n",
        "    ax1.set_xlim(-4, 4)\n",
        "    ax1.set_ylim(-4, 4)\n",
        "    ax1.set_title(\"üîµ Espa√ßo Original\")\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    ax1.legend()\n",
        "    ax1.set_aspect('equal')\n",
        "    \n",
        "    # Espa√ßo transformado\n",
        "    ax2.scatter(transformed_points[0], transformed_points[1], \n",
        "               c='lightcoral', s=50, alpha=0.7)\n",
        "    \n",
        "    # Vetores da base transformados\n",
        "    ax2.arrow(0, 0, t_e1[0, 0], t_e1[1, 0], head_width=0.2, head_length=0.2, \n",
        "             fc='red', ec='red', linewidth=3, \n",
        "             label=f'T(e‚ÇÅ) = ({t_e1[0,0]:.1f}, {t_e1[1,0]:.1f})')\n",
        "    ax2.arrow(0, 0, t_e2[0, 0], t_e2[1, 0], head_width=0.2, head_length=0.2, \n",
        "             fc='blue', ec='blue', linewidth=3,\n",
        "             label=f'T(e‚ÇÇ) = ({t_e2[0,0]:.1f}, {t_e2[1,0]:.1f})')\n",
        "    \n",
        "    # Desenhar grade transformada\n",
        "    X_transformed = transformed_points[0].reshape(X.shape)\n",
        "    Y_transformed = transformed_points[1].reshape(Y.shape)\n",
        "    \n",
        "    for i in range(len(x)):\n",
        "        ax2.plot(X_transformed[i, :], Y_transformed[i, :], 'k-', alpha=0.3, linewidth=1)\n",
        "        ax2.plot(X_transformed[:, i], Y_transformed[:, i], 'k-', alpha=0.3, linewidth=1)\n",
        "    \n",
        "    # Calcular limites baseados nos dados transformados\n",
        "    x_min, x_max = transformed_points[0].min() - 1, transformed_points[0].max() + 1\n",
        "    y_min, y_max = transformed_points[1].min() - 1, transformed_points[1].max() + 1\n",
        "    \n",
        "    ax2.set_xlim(x_min, x_max)\n",
        "    ax2.set_ylim(y_min, y_max)\n",
        "    ax2.set_title(\"üî¥ Espa√ßo Transformado\")\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "    ax2.legend()\n",
        "    ax2.set_aspect('equal')\n",
        "    \n",
        "    # Informa√ß√µes da matriz\n",
        "    det = np.linalg.det(matrix)\n",
        "    fig.suptitle(f\"{title}\\nDeterminante = {det:.2f} (mudan√ßa de √°rea)\", \n",
        "                fontsize=14, fontweight='bold')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    return det\n",
        "\n",
        "# Testando diferentes transforma√ß√µes\n",
        "transformations_to_test = [\n",
        "    (rotation_matrix(60), \"üîÑ Rota√ß√£o 60¬∞\"),\n",
        "    (scaling_matrix(2, 0.5), \"üìè Escala (2x, 0.5x)\"),\n",
        "    (shear_matrix(1, 0), \"üîÄ Cisalhamento kx=1\"),\n",
        "    (np.array([[1, 0], [0, -1]]), \"ü™û Reflex√£o no eixo X\")\n",
        "]\n",
        "\n",
        "for matrix, name in transformations_to_test:\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"Testando: {name}\")\n",
        "    print(f\"Matriz:\\n{matrix}\")\n",
        "    det = visualize_space_transformation(matrix, name)\n",
        "    print(f\"Determinante: {det:.3f}\")\n",
        "    if abs(det) > 1:\n",
        "        print(\"‚Üí Aumenta √°rea/volume\")\n",
        "    elif abs(det) < 1 and det != 0:\n",
        "        print(\"‚Üí Diminui √°rea/volume\")\n",
        "    elif det == 1:\n",
        "        print(\"‚Üí Preserva √°rea/volume\")\n",
        "    elif det == -1:\n",
        "        print(\"‚Üí Preserva √°rea/volume mas inverte orienta√ß√£o\")\n",
        "    else:\n",
        "        print(\"‚Üí Colapsa dimens√µes (singular!)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üí™ Exerc√≠cio 1: Criando Suas Pr√≥prias Transforma√ß√µes\n\nAgora √© sua vez de brincar com as transforma√ß√µes! üéÆ\n\n**Desafio:** Crie transforma√ß√µes para:\n\n1. **Rotacionar 90¬∞ e depois escalar 1.5x uniformemente**\n2. **Fazer uma reflex√£o no eixo Y seguida de cisalhamento horizontal**\n3. **Criar uma transforma√ß√£o que \"achata\" vetores (escala muito pequena numa dire√ß√£o)**\n4. **Inventar uma transforma√ß√£o maluca combinando tudo!**\n\n**Dicas:**\n- Use as fun√ß√µes que criamos: `rotation_matrix()`, `scaling_matrix()`, `shear_matrix()`\n- Lembre-se: a ordem da multiplica√ß√£o importa!\n- Experimente diferentes valores e veja o que acontece\n\n**Bonus:** Tente prever o que vai acontecer antes de executar o c√≥digo!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# üéØ EXERC√çCIO 1: Complete o c√≥digo abaixo!\n",
        "\n",
        "print(\"üöÄ EXERC√çCIO 1: Criando Transforma√ß√µes Pr√≥prias\\n\")\n",
        "\n",
        "# 1. Rota√ß√£o 90¬∞ + Escala 1.5x uniforme\n",
        "print(\"1. Rota√ß√£o 90¬∞ seguida de escala 1.5x:\")\n",
        "# SEU C√ìDIGO AQUI:\n",
        "R90 = rotation_matrix(90)\n",
        "S15 = scaling_matrix(1.5, 1.5)\n",
        "T1 = S15 @ R90  # Ordem: primeiro rotaciona, depois escala\n",
        "\n",
        "print(f\"Matriz resultante:\\n{T1}\")\n",
        "result1 = T1 @ original_vectors\n",
        "plot_transformation(original_vectors, result1, \"Exerc√≠cio 1.1: Rota√ß√£o + Escala\")\n",
        "\n",
        "# 2. Reflex√£o Y + Cisalhamento horizontal\n",
        "print(\"\\n2. Reflex√£o no eixo Y seguida de cisalhamento:\")\n",
        "# SEU C√ìDIGO AQUI:\n",
        "Ry = np.array([[-1, 0], [0, 1]])  # Reflex√£o no Y\n",
        "H = shear_matrix(0.8, 0)  # Cisalhamento horizontal\n",
        "T2 = H @ Ry  # Primeiro reflete, depois cisalha\n",
        "\n",
        "print(f\"Matriz resultante:\\n{T2}\")\n",
        "result2 = T2 @ original_vectors\n",
        "plot_transformation(original_vectors, result2, \"Exerc√≠cio 1.2: Reflex√£o + Cisalhamento\")\n",
        "\n",
        "# 3. Transforma√ß√£o que \"achata\" (escala pequena numa dire√ß√£o)\n",
        "print(\"\\n3. Achatando vetores:\")\n",
        "# SEU C√ìDIGO AQUI:\n",
        "T3 = scaling_matrix(1, 0.1)  # Normal em X, muito pequeno em Y\n",
        "\n",
        "print(f\"Matriz resultante:\\n{T3}\")\n",
        "result3 = T3 @ original_vectors\n",
        "plot_transformation(original_vectors, result3, \"Exerc√≠cio 1.3: Achatando Vetores\")\n",
        "\n",
        "# 4. Transforma√ß√£o maluca (seja criativo!)\n",
        "print(\"\\n4. Transforma√ß√£o maluca:\")\n",
        "# SEU C√ìDIGO AQUI - seja criativo!\n",
        "R_maluco = rotation_matrix(37)  # √Çngulo estranho\n",
        "S_maluco = scaling_matrix(2.3, 0.4)  # Escala esquisita\n",
        "H_maluco = shear_matrix(0.6, -0.3)  # Cisalhamento em ambas dire√ß√µes\n",
        "Ref_maluco = np.array([[1, 0], [0, -1]])  # Reflex√£o no X\n",
        "\n",
        "T4 = Ref_maluco @ H_maluco @ S_maluco @ R_maluco  # Sequ√™ncia maluca!\n",
        "\n",
        "print(f\"Matriz resultante:\\n{T4}\")\n",
        "print(f\"Determinante: {np.linalg.det(T4):.3f}\")\n",
        "result4 = T4 @ original_vectors\n",
        "plot_transformation(original_vectors, result4, \"Exerc√≠cio 1.4: Transforma√ß√£o Maluca!\")\n",
        "\n",
        "print(\"\\nüéâ Parab√©ns! Voc√™ criou suas pr√≥prias transforma√ß√µes!\")\n",
        "print(\"Agora voc√™ entende como as matrizes 'moldam' o espa√ßo!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üßÆ Exerc√≠cio 2: Investigando Propriedades Matem√°ticas\n\nVamos investigar algumas propriedades matem√°ticas interessantes das transforma√ß√µes!\n\n**Quest√µes para investigar:**\n\n1. **O que acontece quando aplicamos a mesma rota√ß√£o duas vezes?**\n2. **Uma matriz de escala e sua \"inversa\" se cancelam?**\n3. **Reflex√µes aplicadas duas vezes voltam ao original?**\n4. **Como o determinante se comporta em composi√ß√µes?**\n\n**Conceitos que vamos explorar:**\n- **Comutatividade:** $AB = BA$? (spoiler: geralmente n√£o!)\n- **Inversibilidade:** $AA^{-1} = I$\n- **Determinante de produtos:** $\\det(AB) = \\det(A)\\det(B)$\n\n**üéØ Dica do Pedro:** Essas propriedades s√£o fundamentais para entender o que vem nos pr√≥ximos m√≥dulos (inversa, determinante, autovalores)!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# üî¨ EXERC√çCIO 2: Investiga√ß√£o Matem√°tica!\n",
        "\n",
        "print(\"üî¨ EXERC√çCIO 2: Investigando Propriedades Matem√°ticas\\n\")\n",
        "\n",
        "# 1. Rota√ß√£o aplicada duas vezes\n",
        "print(\"1. Aplicando rota√ß√£o de 60¬∞ duas vezes:\")\n",
        "R60 = rotation_matrix(60)\n",
        "R60_twice = R60 @ R60\n",
        "R120 = rotation_matrix(120)  # Para comparar\n",
        "\n",
        "print(f\"R(60¬∞) √ó R(60¬∞) =\")\n",
        "print(R60_twice)\n",
        "print(f\"\\nR(120¬∞) =\")\n",
        "print(R120)\n",
        "print(f\"\\nS√£o iguais? {np.allclose(R60_twice, R120)}\")\n",
        "print(\"‚úÖ Conclus√£o: R(Œ±) √ó R(Œ≤) = R(Œ± + Œ≤)\")\n",
        "\n",
        "# 2. Escala e sua inversa\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"2. Escala e sua inversa:\")\n",
        "S = scaling_matrix(3, 2)\n",
        "S_inv = scaling_matrix(1/3, 1/2)  # Inversa manual\n",
        "S_times_S_inv = S @ S_inv\n",
        "identity = np.eye(2)\n",
        "\n",
        "print(f\"S (escala 3x, 2x) =\")\n",
        "print(S)\n",
        "print(f\"\\nS_inv (escala 1/3x, 1/2x) =\")\n",
        "print(S_inv)\n",
        "print(f\"\\nS √ó S_inv =\")\n",
        "print(S_times_S_inv)\n",
        "print(f\"\\n√â a identidade? {np.allclose(S_times_S_inv, identity)}\")\n",
        "print(\"‚úÖ Conclus√£o: Escalas se cancelam multiplicativamente\")\n",
        "\n",
        "# 3. Reflex√£o aplicada duas vezes\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"3. Reflex√£o aplicada duas vezes:\")\n",
        "Ref = np.array([[-1, 0], [0, 1]])  # Reflex√£o no Y\n",
        "Ref_twice = Ref @ Ref\n",
        "\n",
        "print(f\"Reflex√£o no Y:\")\n",
        "print(Ref)\n",
        "print(f\"\\nReflex√£o √ó Reflex√£o =\")\n",
        "print(Ref_twice)\n",
        "print(f\"\\n√â a identidade? {np.allclose(Ref_twice, identity)}\")\n",
        "print(\"‚úÖ Conclus√£o: Reflex√µes s√£o suas pr√≥prias inversas!\")\n",
        "\n",
        "# 4. Determinantes em composi√ß√µes\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"4. Investigando determinantes:\")\n",
        "\n",
        "# V√°rias transforma√ß√µes\n",
        "matrices = {\n",
        "    'Rota√ß√£o 45¬∞': rotation_matrix(45),\n",
        "    'Escala (2, 3)': scaling_matrix(2, 3),\n",
        "    'Cisalhamento': shear_matrix(0.5, 0),\n",
        "    'Reflex√£o Y': np.array([[-1, 0], [0, 1]])\n",
        "}\n",
        "\n",
        "print(\"Determinantes individuais:\")\n",
        "dets = {}\n",
        "for name, matrix in matrices.items():\n",
        "    det = np.linalg.det(matrix)\n",
        "    dets[name] = det\n",
        "    print(f\"{name}: {det:.3f}\")\n",
        "\n",
        "# Composi√ß√£o de todas\n",
        "print(\"\\nComposi√ß√£o de todas as transforma√ß√µes:\")\n",
        "composition = np.eye(2)\n",
        "det_product = 1\n",
        "\n",
        "for name, matrix in matrices.items():\n",
        "    composition = matrix @ composition\n",
        "    det_product *= dets[name]\n",
        "\n",
        "det_composition = np.linalg.det(composition)\n",
        "print(f\"det(composi√ß√£o) = {det_composition:.6f}\")\n",
        "print(f\"Produto dos determinantes = {det_product:.6f}\")\n",
        "print(f\"S√£o iguais? {np.allclose(det_composition, det_product)}\")\n",
        "print(\"‚úÖ Conclus√£o: det(AB) = det(A) √ó det(B)\")\n",
        "\n",
        "# Testando comutatividade\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"5. BONUS - Testando comutatividade:\")\n",
        "A = rotation_matrix(30)\n",
        "B = scaling_matrix(2, 1)\n",
        "\n",
        "AB = A @ B\n",
        "BA = B @ A\n",
        "\n",
        "print(f\"A √ó B =\")\n",
        "print(AB)\n",
        "print(f\"\\nB √ó A =\")\n",
        "print(BA)\n",
        "print(f\"\\nAB = BA? {np.allclose(AB, BA)}\")\n",
        "print(\"‚ö†Ô∏è  Conclus√£o: Matrizes geralmente N√ÉO comutam!\")\n",
        "\n",
        "print(\"\\nüéì Investiga√ß√£o completa! Essas propriedades s√£o fundamentais para IA!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîó Conectando com o Resto do Curso\n\nAgora que voc√™ domina transforma√ß√µes lineares, vamos conectar com o que vem pela frente! üöÄ\n\n```mermaid\ngraph TD\n    A[\"üìê M√≥dulo 6: Transforma√ß√µes<br/>(Voc√™ est√° aqui!)\"] --> B[\"üîÑ M√≥dulo 7: Inversa & Transposta\"]\n    A --> C[\"üìä M√≥dulo 8: Determinante\"]\n    B --> D[\"üéØ M√≥dulo 9: SVD\"]\n    C --> D\n    D --> E[\"‚ö° M√≥dulo 10: Autovalores\"]\n    E --> F[\"üß† Aplica√ß√µes em IA\"]\n```\n\n### **Pr√≥ximos M√≥dulos - Preview:**\n\n**üîÑ M√≥dulo 7 - Inversa e Transposta:**\n- Como \"desfazer\" transforma√ß√µes (matriz inversa)\n- Por que `A.T @ A` aparece em todo lugar?\n- Conex√£o com regress√£o linear!\n\n**üìä M√≥dulo 8 - Determinante:**\n- Por que algumas transforma√ß√µes \"quebram\" o espa√ßo?\n- Como medir mudan√ßa de volume\n- Quando uma matriz √© invert√≠vel?\n\n**üéØ M√≥dulo 9 - SVD:**\n- Toda matriz √© uma composi√ß√£o de 3 transforma√ß√µes simples!\n- Como comprimir imagens e fazer recomenda√ß√µes\n- O \"santo graal\" da √°lgebra linear\n\n**‚ö° M√≥dulo 10 - Autovalores:**\n- Dire√ß√µes especiais que n√£o mudam (s√≥ esticam/encolhem)\n- PCA finalmente vai fazer sentido!\n- An√°lise de redes sociais e muito mais\n\n**üéØ Dica do Pedro:** Tudo que voc√™ aprendeu hoje √© a base para entender como funcionam algoritmos como PCA, SVD, e at√© redes neurais!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Vamos dar uma \"pr√©via\" dos pr√≥ximos m√≥dulos!\n",
        "print(\"üîÆ PREVIEW DOS PR√ìXIMOS M√ìDULOS\\n\")\n",
        "\n",
        "# Exemplo de matriz inversa (M√≥dulo 7)\n",
        "print(\"üìç M√ìDULO 7 - Inversa: Como 'desfazer' transforma√ß√µes\")\n",
        "A = rotation_matrix(45)\n",
        "A_inv = np.linalg.inv(A)  # Fun√ß√£o que vamos entender no m√≥dulo 7\n",
        "should_be_identity = A @ A_inv\n",
        "\n",
        "print(f\"Matriz A (rota√ß√£o 45¬∞):\\n{A}\")\n",
        "print(f\"\\nInversa de A (rota√ß√£o -45¬∞):\\n{A_inv}\")\n",
        "print(f\"\\nA √ó A‚Åª¬π = Identidade?\\n{should_be_identity}\")\n",
        "print(f\"√â identidade? {np.allclose(should_be_identity, np.eye(2))}\")\n",
        "\n",
        "# Exemplo de determinante (M√≥dulo 8)\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üìç M√ìDULO 8 - Determinante: Medindo mudan√ßa de √°rea\")\n",
        "\n",
        "matrices_det = {\n",
        "    'Identidade': np.eye(2),\n",
        "    'Rota√ß√£o': rotation_matrix(30),\n",
        "    'Escala 2x': scaling_matrix(2, 2),\n",
        "    'Achatamento': scaling_matrix(1, 0.1),\n",
        "    'Singular': np.array([[1, 2], [2, 4]])  # Esta \"quebra\" o espa√ßo!\n",
        "}\n",
        "\n",
        "print(\"Determinantes e seus significados:\")\n",
        "for name, mat in matrices_det.items():\n",
        "    det = np.linalg.det(mat)\n",
        "    print(f\"{name:12}: det = {det:6.2f}\", end=\"\")\n",
        "    \n",
        "    if abs(det) < 1e-10:\n",
        "        print(\" ‚Üí Colapsa dimens√µes!\")\n",
        "    elif det == 1:\n",
        "        print(\" ‚Üí Preserva √°rea\")\n",
        "    elif det == -1:\n",
        "        print(\" ‚Üí Preserva √°rea, inverte orienta√ß√£o\")\n",
        "    elif abs(det) > 1:\n",
        "        print(f\" ‚Üí Aumenta √°rea {abs(det):.1f}x\")\n",
        "    else:\n",
        "        print(f\" ‚Üí Diminui √°rea para {abs(det):.1f}x\")\n",
        "\n",
        "# Preview de autovalores (M√≥dulo 10)\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üìç M√ìDULO 10 - Autovalores: Dire√ß√µes especiais\")\n",
        "\n",
        "# Matriz simples com autovalores √≥bvios\n",
        "simple_matrix = np.array([[3, 0], [0, 2]])\n",
        "eigenvals, eigenvecs = np.linalg.eig(simple_matrix)\n",
        "\n",
        "print(f\"Matriz diagonal simples:\\n{simple_matrix}\")\n",
        "print(f\"\\nAutovalores: {eigenvals}\")\n",
        "print(f\"Autovetores:\\n{eigenvecs}\")\n",
        "print(\"\\nSignificado: os eixos X e Y s√£o dire√ß√µes especiais!\")\n",
        "print(\"- Vetor (1,0) √© esticado 3x\")\n",
        "print(\"- Vetor (0,1) √© esticado 2x\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üöÄ PR√ìXIMOS PASSOS:\")\n",
        "print(\"1. M√≥dulo 7: Aprender a 'desfazer' transforma√ß√µes\")\n",
        "print(\"2. M√≥dulo 8: Entender quando transforma√ß√µes 'quebram'\")\n",
        "print(\"3. M√≥dulo 9: SVD - decompor qualquer transforma√ß√£o\")\n",
        "print(\"4. M√≥dulo 10: Encontrar dire√ß√µes especiais (PCA!)\")\n",
        "print(\"\\nüéØ Continue estudando - a jornada est√° ficando cada vez mais interessante!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéâ Resumo do M√≥dulo: O Que Aprendemos Hoje?\n\n**Liiindo!** Chegamos ao final de mais um m√≥dulo! Vamos recapitular tudo que descobrimos sobre transforma√ß√µes lineares:\n\n### üß† **Conceitos Fundamentais:**\n1. **Transforma√ß√£o Linear = Multiplica√ß√£o por Matriz** üìä\n   - Toda multiplica√ß√£o $\\vec{y} = A\\vec{x}$ √© uma transforma√ß√£o geom√©trica\n   - Preserva origem, linhas retas e paralelismo\n\n2. **Tipos de Transforma√ß√µes:**\n   - üîÑ **Rota√ß√£o:** Gira sem mudar tamanho\n   - üìè **Escala:** Estica/encolhe em cada dire√ß√£o\n   - üîÄ **Cisalhamento:** Inclina o espa√ßo\n   - ü™û **Reflex√£o:** Espelha vetores\n\n3. **Composi√ß√£o de Transforma√ß√µes:**\n   - Multiplica√ß√£o de matrizes = sequ√™ncia de transforma√ß√µes\n   - **Ordem importa:** $AB \\neq BA$\n   - Determinante mede mudan√ßa de √°rea: $\\det(AB) = \\det(A)\\det(B)$\n\n### üöÄ **Aplica√ß√µes em IA:**\n- **Redes Neurais:** Cada camada √© uma transforma√ß√£o linear + ativa√ß√£o\n- **Data Augmentation:** Rota√ß√µes, escalas para aumentar datasets\n- **Normaliza√ß√£o:** Transforma√ß√µes lineares para padronizar dados\n- **Computer Vision:** Corre√ß√£o geom√©trica, filtros\n\n### üîó **Conex√µes:**\n- **M√≥dulos anteriores:** Usamos multiplica√ß√£o de matrizes (M√≥dulo 3) e NumPy (M√≥dulo 4)\n- **Pr√≥ximos m√≥dulos:** Base para inversa, determinante, SVD e PCA\n\n### üéØ **Dica Final do Pedro:**\n> *\"Toda vez que voc√™ vir uma multiplica√ß√£o de matriz em IA, lembre-se: n√£o √© s√≥ conta, √© uma transforma√ß√£o geom√©trica acontecendo! Os dados est√£o sendo 'moldados' no espa√ßo!\"* üé®\n\n**Parab√©ns por completar o M√≥dulo 6!** Agora voc√™ v√™ matrizes n√£o como n√∫meros, mas como **transforma√ß√µes que moldam o mundo dos dados!** üåü\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/algebra-linear-para-ia-modulo-06_img_06.png)"
      ]
    }
  ]
}